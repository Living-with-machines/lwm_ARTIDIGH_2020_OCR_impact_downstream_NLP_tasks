{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "from time import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-14 11:28:34,715 : INFO : loading Word2Vec object from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\n",
      "2019-11-14 11:28:35,834 : INFO : loading wv recursively from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.wv.* with mmap=None\n",
      "2019-11-14 11:28:35,835 : INFO : loading vectors from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.wv.vectors.npy with mmap=None\n",
      "2019-11-14 11:28:36,255 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-14 11:28:36,256 : INFO : loading vocabulary recursively from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.vocabulary.* with mmap=None\n",
      "2019-11-14 11:28:36,257 : INFO : loading trainables recursively from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.trainables.* with mmap=None\n",
      "2019-11-14 11:28:36,257 : INFO : loading syn1neg from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-14 11:28:36,676 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-14 11:28:36,677 : INFO : loaded /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\n",
      "2019-11-14 11:28:37,726 : INFO : loading Word2Vec object from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model\n",
      "2019-11-14 11:28:40,309 : INFO : loading wv recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model.wv.* with mmap=None\n",
      "2019-11-14 11:28:40,309 : INFO : loading vectors from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model.wv.vectors.npy with mmap=None\n",
      "2019-11-14 11:28:41,872 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-14 11:28:41,873 : INFO : loading vocabulary recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model.vocabulary.* with mmap=None\n",
      "2019-11-14 11:28:41,873 : INFO : loading trainables recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model.trainables.* with mmap=None\n",
      "2019-11-14 11:28:41,874 : INFO : loading syn1neg from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-14 11:28:43,092 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-14 11:28:43,093 : INFO : loaded /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model\n",
      "2019-11-14 11:28:45,398 : INFO : loading Word2Vec object from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model\n",
      "2019-11-14 11:28:46,511 : INFO : loading wv recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model.wv.* with mmap=None\n",
      "2019-11-14 11:28:46,512 : INFO : loading vectors from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model.wv.vectors.npy with mmap=None\n",
      "2019-11-14 11:28:47,001 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-14 11:28:47,002 : INFO : loading vocabulary recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model.vocabulary.* with mmap=None\n",
      "2019-11-14 11:28:47,002 : INFO : loading trainables recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model.trainables.* with mmap=None\n",
      "2019-11-14 11:28:47,003 : INFO : loading syn1neg from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-14 11:28:47,709 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-14 11:28:47,710 : INFO : loaded /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model\n",
      "2019-11-14 11:28:49,001 : INFO : loading Word2Vec object from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model\n",
      "2019-11-14 11:28:51,387 : INFO : loading wv recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model.wv.* with mmap=None\n",
      "2019-11-14 11:28:51,387 : INFO : loading vectors from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model.wv.vectors.npy with mmap=None\n",
      "2019-11-14 11:28:52,412 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-14 11:28:52,413 : INFO : loading vocabulary recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model.vocabulary.* with mmap=None\n",
      "2019-11-14 11:28:52,413 : INFO : loading trainables recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model.trainables.* with mmap=None\n",
      "2019-11-14 11:28:52,414 : INFO : loading syn1neg from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-14 11:28:53,402 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-14 11:28:53,403 : INFO : loaded /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model\n",
      "2019-11-14 11:28:54,877 : INFO : loading Word2Vec object from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model\n",
      "2019-11-14 11:28:55,162 : INFO : loading wv recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model.wv.* with mmap=None\n",
      "2019-11-14 11:28:55,163 : INFO : loading vectors from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model.wv.vectors.npy with mmap=None\n",
      "2019-11-14 11:28:55,314 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-14 11:28:55,315 : INFO : loading vocabulary recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model.vocabulary.* with mmap=None\n",
      "2019-11-14 11:28:55,316 : INFO : loading trainables recursively from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model.trainables.* with mmap=None\n",
      "2019-11-14 11:28:55,316 : INFO : loading syn1neg from /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-14 11:28:55,496 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-14 11:28:55,497 : INFO : loaded /Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model\n"
     ]
    }
   ],
   "source": [
    "# embedding models, base model\n",
    "model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\"\n",
    "w2v = Word2Vec.load(model_path)\n",
    "\n",
    "# OCR model, pretrained\n",
    "model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_ocr.model\"\n",
    "w2v_em_ocr = Word2Vec.load(model_path)\n",
    "\n",
    "# corrected model, pretrained\n",
    "model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/w2v_005_embedding_model_corrected.model\"\n",
    "w2v_em_corr = Word2Vec.load(model_path)\n",
    "\n",
    "# OCR model, pretrained\n",
    "model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_ocr.model\"\n",
    "em_ocr = Word2Vec.load(model_path)\n",
    "\n",
    "# corrected model, pretrained\n",
    "model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/lwm_ocr_assessment/LMs/embedding_model_corrected.model\"\n",
    "em_corr = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of words in the corrected set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_corrected = []\n",
    "for item in em_corr.wv.vocab:\n",
    "    words_corrected.append([item, int(em_corr.wv.vocab[item].count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_words = pd.DataFrame(words_corrected, columns=['vocab', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 179735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>,</td>\n",
       "      <td>860225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>831221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>the</td>\n",
       "      <td>736361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>of</td>\n",
       "      <td>351214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>and</td>\n",
       "      <td>291173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152166</td>\n",
       "      <td>instructeded</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152167</td>\n",
       "      <td>nonfiling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152168</td>\n",
       "      <td>porformance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152155</td>\n",
       "      <td>hoiioiire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179734</td>\n",
       "      <td>auk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179735 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               vocab   count\n",
       "57                 ,  860225\n",
       "24                 .  831221\n",
       "21               the  736361\n",
       "5                 of  351214\n",
       "110              and  291173\n",
       "...              ...     ...\n",
       "152166  instructeded       1\n",
       "152167     nonfiling       1\n",
       "152168   porformance       1\n",
       "152155     hoiioiire       1\n",
       "179734           auk       1\n",
       "\n",
       "[179735 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_words = pd_words.sort_values(by=['count'], ascending=False)\n",
    "print(\"size: {}\".format(len(pd_words)))\n",
    "pd_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_neighbors(myrow, embedding, colname='vocab', topn=2):\n",
    "    try:\n",
    "        vocab_neigh = embedding.wv.most_similar([myrow['vocab']], topn=topn)\n",
    "        return list(np.array(vocab_neigh)[:, 0])\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_rows = 20\n",
    "#pd2search = pd_words.loc[pd_words.index[np.linspace(2, len(pd_words)-1, num_rows).astype(np.int)]]\n",
    "pd2search = pd_words[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pd2search['w2v_em_corr_neigh'] = pd2search.apply(found_neighbors, args=[w2v_em_corr], axis=1)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pd2search['w2v_em_ocr_neigh'] = pd2search.apply(found_neighbors, args=[w2v_em_ocr], axis=1)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pd2search['em_corr_neigh'] = pd2search.apply(found_neighbors, args=[em_corr], axis=1)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pd2search['em_ocr_neigh'] = pd2search.apply(found_neighbors, args=[em_ocr], axis=1)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2search.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_df(myrow, colname_1, colname_2, make_lowercase=True):\n",
    "    \"\"\"\n",
    "    Jaccard similarity between two documents (e.g., OCR and Human) on flattened list of words\n",
    "    \"\"\"\n",
    "    list1 = myrow[colname_1]\n",
    "    list2 = myrow[colname_2]\n",
    "    if make_lowercase:\n",
    "        list1 = [x.lower() for x in list1]\n",
    "        list2 = [x.lower() for x in list2]\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2search['jaccard_w2v_corr_w2v_ocr'] = \\\n",
    "    pd2search.apply(jaccard_similarity_df, args=['w2v_em_corr_neigh', \"w2v_em_ocr_neigh\", True], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2search['jaccard_corr_ocr'] = \\\n",
    "    pd2search.apply(jaccard_similarity_df, args=['em_corr_neigh', \"em_ocr_neigh\", True], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2search.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pd2search['count'], pd2search['jaccard_w2v_corr_w2v_ocr'], 'ko', alpha=0.1)\n",
    "plt.xlim(0, 20000)\n",
    "print(pd2search['jaccard_w2v_corr_w2v_ocr'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
