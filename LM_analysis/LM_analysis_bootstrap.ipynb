{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-21 10:58:57,626 : INFO : loading Word2Vec object from ./LMs/embedding_model_scratch_corrected.model\n",
      "2019-11-21 10:58:58,094 : INFO : loading wv recursively from ./LMs/embedding_model_scratch_corrected.model.wv.* with mmap=None\n",
      "2019-11-21 10:58:58,094 : INFO : loading vectors from ./LMs/embedding_model_scratch_corrected.model.wv.vectors.npy with mmap=None\n",
      "2019-11-21 10:58:58,223 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-21 10:58:58,225 : INFO : loading vocabulary recursively from ./LMs/embedding_model_scratch_corrected.model.vocabulary.* with mmap=None\n",
      "2019-11-21 10:58:58,225 : INFO : loading trainables recursively from ./LMs/embedding_model_scratch_corrected.model.trainables.* with mmap=None\n",
      "2019-11-21 10:58:58,226 : INFO : loading syn1neg from ./LMs/embedding_model_scratch_corrected.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-21 10:58:58,347 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-21 10:58:58,348 : INFO : loaded ./LMs/embedding_model_scratch_corrected.model\n"
     ]
    }
   ],
   "source": [
    "# embedding models, base model\n",
    "#model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\"\n",
    "model_path = \"./LMs/embedding_model_scratch_corrected.model\"\n",
    "w2v_corrected = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_neighbors(myrow, embedding, colname='vocab', topn=1):\n",
    "    try:\n",
    "        vocab_neigh = embedding.wv.most_similar([myrow['vocab']], topn=topn)\n",
    "        return list(np.array(vocab_neigh)[:, 0])\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_df(myrow, colname_1, colname_2, num_items=False, make_lowercase=True):\n",
    "    \"\"\"\n",
    "    Jaccard similarity between two documents (e.g., OCR and Human) on flattened list of words\n",
    "    \"\"\"\n",
    "    if not num_items:\n",
    "        list1 = myrow[colname_1]\n",
    "        list2 = myrow[colname_2]\n",
    "    else:\n",
    "        list1 = myrow[colname_1][:num_items]\n",
    "        list2 = myrow[colname_2][:num_items]\n",
    "    if make_lowercase:\n",
    "        list1 = [x.lower() for x in list1]\n",
    "        list2 = [x.lower() for x in list2]\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_corrected = []\n",
    "for item in w2v_corrected.wv.vocab:\n",
    "    words_corrected.append([item, int(w2v_corrected.wv.vocab[item].count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_words = pd.DataFrame(words_corrected, columns=['vocab', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 179735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>,</td>\n",
       "      <td>860225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>831221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>the</td>\n",
       "      <td>736361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>of</td>\n",
       "      <td>351214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>and</td>\n",
       "      <td>291173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vocab   count\n",
       "57      ,  860225\n",
       "24      .  831221\n",
       "21    the  736361\n",
       "5      of  351214\n",
       "110   and  291173"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_words = pd_words.sort_values(by=['count'], ascending=False)\n",
    "print(\"size: {}\".format(len(pd_words)))\n",
    "pd_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4058</td>\n",
       "      <td>captain</td>\n",
       "      <td>10023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>10014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1673</td>\n",
       "      <td>any</td>\n",
       "      <td>9719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>into</td>\n",
       "      <td>9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>we</td>\n",
       "      <td>9673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>971</td>\n",
       "      <td>court</td>\n",
       "      <td>9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>o</td>\n",
       "      <td>9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>9648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>men</td>\n",
       "      <td>9638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>if</td>\n",
       "      <td>9424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>771</td>\n",
       "      <td>man</td>\n",
       "      <td>9321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>t</td>\n",
       "      <td>9314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>9184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>over</td>\n",
       "      <td>9125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>only</td>\n",
       "      <td>9125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>b</td>\n",
       "      <td>9124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>having</td>\n",
       "      <td>8985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>then</td>\n",
       "      <td>8953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>should</td>\n",
       "      <td>8882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>present</td>\n",
       "      <td>8866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1889</td>\n",
       "      <td>now</td>\n",
       "      <td>8702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>found</td>\n",
       "      <td>8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1043</td>\n",
       "      <td>william</td>\n",
       "      <td>8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1143</td>\n",
       "      <td>may</td>\n",
       "      <td>8374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>work</td>\n",
       "      <td>8349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>police</td>\n",
       "      <td>8102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>george</td>\n",
       "      <td>8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4945</td>\n",
       "      <td>meeting</td>\n",
       "      <td>8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>night</td>\n",
       "      <td>7977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>its</td>\n",
       "      <td>7972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>more</td>\n",
       "      <td>7959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>could</td>\n",
       "      <td>7831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>re</td>\n",
       "      <td>7820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>james</td>\n",
       "      <td>7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1695</td>\n",
       "      <td>place</td>\n",
       "      <td>7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>upon</td>\n",
       "      <td>7743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>held</td>\n",
       "      <td>7661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3315</td>\n",
       "      <td>our</td>\n",
       "      <td>7621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>dr</td>\n",
       "      <td>7582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1736</td>\n",
       "      <td>great</td>\n",
       "      <td>7450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>well</td>\n",
       "      <td>7397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>council</td>\n",
       "      <td>7244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>government</td>\n",
       "      <td>7234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>co</td>\n",
       "      <td>7214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>many</td>\n",
       "      <td>7198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1839</td>\n",
       "      <td>public</td>\n",
       "      <td>7196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>during</td>\n",
       "      <td>7136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3134</td>\n",
       "      <td>water</td>\n",
       "      <td>7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>than</td>\n",
       "      <td>7017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>where</td>\n",
       "      <td>6882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>p</td>\n",
       "      <td>6835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vocab  count\n",
       "4058     captain  10023\n",
       "189            1  10014\n",
       "1673         any   9719\n",
       "13          into   9699\n",
       "827           we   9673\n",
       "971        court   9670\n",
       "491            o   9650\n",
       "205            2   9648\n",
       "933          men   9638\n",
       "384           if   9424\n",
       "771          man   9321\n",
       "502            t   9314\n",
       "66     yesterday   9184\n",
       "536         over   9125\n",
       "139         only   9125\n",
       "356            b   9124\n",
       "270       having   8985\n",
       "931         then   8953\n",
       "135       should   8882\n",
       "216      present   8866\n",
       "1889         now   8702\n",
       "1219       found   8408\n",
       "1043     william   8393\n",
       "1143         may   8374\n",
       "420         work   8349\n",
       "213       police   8102\n",
       "303       george   8065\n",
       "4945     meeting   8018\n",
       "322        night   7977\n",
       "557          its   7972\n",
       "412         more   7959\n",
       "396        could   7831\n",
       "373           re   7820\n",
       "972        james   7813\n",
       "1695       place   7758\n",
       "2140        upon   7743\n",
       "180         held   7661\n",
       "3315         our   7621\n",
       "285           dr   7582\n",
       "1736       great   7450\n",
       "747         well   7397\n",
       "886      council   7244\n",
       "353   government   7234\n",
       "480           co   7214\n",
       "104         many   7198\n",
       "1839      public   7196\n",
       "20        during   7136\n",
       "3134       water   7119\n",
       "413         than   7017\n",
       "583        where   6882\n",
       "467            p   6835"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd2search = pd_words[100:151]\n",
    "pd2search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality bands 3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of words and their frequencies in the corrected set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-21 10:58:59,143 : INFO : loading Word2Vec object from ./LMs/w2v_005_EM_corr_qual_3_4.model\n",
      "2019-11-21 10:59:00,039 : INFO : loading wv recursively from ./LMs/w2v_005_EM_corr_qual_3_4.model.wv.* with mmap=None\n",
      "2019-11-21 10:59:00,040 : INFO : loading vectors from ./LMs/w2v_005_EM_corr_qual_3_4.model.wv.vectors.npy with mmap=None\n",
      "2019-11-21 10:59:00,331 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-21 10:59:00,332 : INFO : loading vocabulary recursively from ./LMs/w2v_005_EM_corr_qual_3_4.model.vocabulary.* with mmap=None\n",
      "2019-11-21 10:59:00,332 : INFO : loading trainables recursively from ./LMs/w2v_005_EM_corr_qual_3_4.model.trainables.* with mmap=None\n",
      "2019-11-21 10:59:00,333 : INFO : loading syn1neg from ./LMs/w2v_005_EM_corr_qual_3_4.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-21 10:59:00,635 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-21 10:59:00,636 : INFO : loaded ./LMs/w2v_005_EM_corr_qual_3_4.model\n",
      "2019-11-21 10:59:01,748 : INFO : loading Word2Vec object from ./LMs/w2v_005_EM_ocr_qual_3_4.model\n",
      "2019-11-21 10:59:02,748 : INFO : loading wv recursively from ./LMs/w2v_005_EM_ocr_qual_3_4.model.wv.* with mmap=None\n",
      "2019-11-21 10:59:02,749 : INFO : loading vectors from ./LMs/w2v_005_EM_ocr_qual_3_4.model.wv.vectors.npy with mmap=None\n",
      "2019-11-21 10:59:03,077 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-21 10:59:03,078 : INFO : loading vocabulary recursively from ./LMs/w2v_005_EM_ocr_qual_3_4.model.vocabulary.* with mmap=None\n",
      "2019-11-21 10:59:03,078 : INFO : loading trainables recursively from ./LMs/w2v_005_EM_ocr_qual_3_4.model.trainables.* with mmap=None\n",
      "2019-11-21 10:59:03,079 : INFO : loading syn1neg from ./LMs/w2v_005_EM_ocr_qual_3_4.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-21 10:59:03,395 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-21 10:59:03,396 : INFO : loaded ./LMs/w2v_005_EM_ocr_qual_3_4.model\n",
      "2019-11-21 10:59:04,505 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topn: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "2019-11-21 11:02:32,846 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr: 208.3446500301361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocr: 420.53262519836426\n",
      "total: 472.8203191757202\n"
     ]
    }
   ],
   "source": [
    "neigh_jaccard_bands_3_4 = []\n",
    "\n",
    "for i_model in [0]:\n",
    "\n",
    "    w2v_em_corr_qual_3_4 = Word2Vec.load('./LMs/w2v_005_EM_corr_qual_3_4.model')\n",
    "    w2v_em_ocr_qual_3_4 = Word2Vec.load('./LMs/w2v_005_EM_ocr_qual_3_4.model')\n",
    "\n",
    "    #for topn in [1, 2, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000]:\n",
    "    for topn in [50000]:\n",
    "        print(\"topn: {}\".format(topn))\n",
    "        t1 = time.time()\n",
    "\n",
    "        pd2search = pd_words[0:1000]\n",
    "        pd2search['w2v_em_corr_qual_3_4'] = pd2search.apply(found_neighbors, args=[w2v_em_corr_qual_3_4, \n",
    "                                                                                   'vocab', \n",
    "                                                                                   topn], axis=1)\n",
    "        print(\"corr: {}\".format(time.time() - t1))\n",
    "        pd2search['w2v_em_ocr_qual_3_4'] = pd2search.apply(found_neighbors, args=[w2v_em_ocr_qual_3_4,\n",
    "                                                                                  'vocab', \n",
    "                                                                                  topn], axis=1)\n",
    "        print(\"ocr: {}\".format(time.time() - t1))\n",
    "\n",
    "    mytopn_range = [1, 2, 5, \n",
    "                    10, 20, 50, \n",
    "                    100, 200, 500, \n",
    "                    1000, 2000, 5000, \n",
    "                    10000, 20000, 50000]\n",
    "    for mytopn in mytopn_range:\n",
    "        pd2search['jaccard_qual_3_4'] = \\\n",
    "            pd2search.apply(jaccard_similarity_df, \n",
    "                            args=['w2v_em_corr_qual_3_4', \"w2v_em_ocr_qual_3_4\", mytopn], \n",
    "                            axis=1)\n",
    "\n",
    "        neigh_jaccard_bands_3_4.append(\n",
    "            [mytopn, \n",
    "             pd2search['jaccard_qual_3_4'].mean(), \n",
    "             pd2search['jaccard_qual_3_4'].std(),\n",
    "             i_model\n",
    "            ])\n",
    "    print(\"total: {}\".format(time.time() - t1))\n",
    "    #np.save(\"neigh_jaccard_bands_3_4.npy\", np.array(neigh_jaccard_bands_3_4))\n",
    "\n",
    "neigh_jaccard_bands_3_4 = np.array(neigh_jaccard_bands_3_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"neigh_jaccard_bands_3_4.npy\", neigh_jaccard_bands_3_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
