{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataFrame from the Trove dataset\n",
    "\n",
    "### Obtaining the data\n",
    "\n",
    "You can download the whole Trove dataset using:\n",
    "\n",
    "`wget --recursive --no-parent http://overproof.projectcomputing.com/datasets/`\n",
    "\n",
    "Change the parent directory `overproof.projectcomputing.com` to a friendlier name `trove_overproof`.\n",
    "\n",
    "### Preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with the following structure:\n",
    "# arbitrary_dirname: path_to_txt_files\n",
    "# dirname is an arbitrary name which can be used to filter the DB in later steps\n",
    "\n",
    "dict_dirnames = {\n",
    "    \"trove_dataset_1\": './trove_overproof/datasets/dataset1/rawTextAndHumanCorrectionPairs',\n",
    "    \"trove_dataset_2\": './trove_overproof/datasets/dataset2/rawTextAndHumanCorrectionAndOverproofCorrectionTriples',\n",
    "    \"trove_dataset_3\": './trove_overproof/datasets/dataset3/rawTextAndHumanCorrectionAndOverproofCorrectionTriples'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"filePath\", \"articleId\", \"articleType\", \"year\", \n",
    "                           \"ocrText\", \"humanText\", \"corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_header(line):\n",
    "    re_header = r'^\\*\\$\\*OVERPROOF\\*\\$\\*\\s*([0-9]+)\\s+year\\s+([0-9]{4})\\s+type\\s(.+)\\s+title\\s+.+$'\n",
    "    if re.match(re_header, line):\n",
    "        articleId, year, articleType = re.match(re_header, line).groups()\n",
    "        return articleId, year, articleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content(article_content):\n",
    "    ocr_line = []\n",
    "    human_line = []\n",
    "    hcorr_line = []\n",
    "    for line in article_content:\n",
    "        line = line.split(\"||@@||\")\n",
    "        if (not line[0].strip() == '') or (not line[1].strip() == ''):\n",
    "            if len(line) == 3:\n",
    "                ocr_line.append(line[0].strip())\n",
    "                human_line.append(line[1].strip())\n",
    "                hcorr_line.append(line[2].strip())\n",
    "            if len(line) == 2:\n",
    "                ocr_line.append(line[0].strip())\n",
    "                human_line.append(line[1].strip())\n",
    "\n",
    "    return \" \".join(ocr_line), \" \".join(human_line), \" \".join(hcorr_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_content = []\n",
    "year = \"\"\n",
    "file_path = \"\"\n",
    "articleId = \"\"\n",
    "articleType = \"\"\n",
    "processed_content = \"\"\n",
    "article_counter = 0\n",
    "for ldir in dict_dirnames.keys():\n",
    "    list_files = glob(os.path.join(dict_dirnames[ldir], \"*.txt\"))\n",
    "    for lfile in list_files:\n",
    "        file_path = lfile\n",
    "        fio = open(lfile, \"r\")\n",
    "        flines = fio.readlines()\n",
    "        for iline in range(len(flines)):\n",
    "            if flines[iline].startswith('*$*OVERPROOF*$*'):\n",
    "                articleId, year, articleType = process_header(flines[iline])\n",
    "                article_counter += 1\n",
    "            else:\n",
    "                article_content.append(flines[iline])\n",
    "                if ((len(flines) -1 == iline) or (flines[iline + 1].startswith('*$*OVERPROOF*$*'))):\n",
    "                    processed_content = process_content(article_content)\n",
    "\n",
    "                    # Insert into dataframe:\n",
    "                    df.loc[article_counter] = [file_path, \n",
    "                                               articleId,\n",
    "                                               articleType,\n",
    "                                               year,\n",
    "                                               processed_content[0],\n",
    "                                               processed_content[1],\n",
    "                                               processed_content[2]\n",
    "                                              ] \n",
    "                    \n",
    "                    # Clean variables:\n",
    "                    year = \"\"\n",
    "                    articleId = \"\"\n",
    "                    articleType = \"\"\n",
    "                    processed_content = \"\"\n",
    "                    article_content = []\n",
    "\n",
    "print(article_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add string similarity and length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "# Initialization\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_via_levenshtein(gs_clean, ocr_clean):\n",
    "    gs_clean = gs_clean.lower()\n",
    "    ocr_clean = ocr_clean.lower()\n",
    "    max_sentlength = max(len(gs_clean), len(ocr_clean))\n",
    "    lev_distance = jellyfish.levenshtein_distance(gs_clean, ocr_clean)\n",
    "    dist_similarity = (max_sentlength - lev_distance) / float(max_sentlength)\n",
    "    return dist_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['str_similarity'] = df.parallel_apply(lambda row: distance_via_levenshtein(row['ocrText'], row['humanText']), axis=1)\n",
    "df['str_length_humanText'] = df.parallel_apply(lambda row: len(row['humanText']), axis=1)\n",
    "df['str_length_ocrText'] = df.parallel_apply(lambda row: len(row['ocrText']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents that have at least one article with string similarity lower than 0.8:\n",
    "len(df[df['str_similarity'] < 0.8]['articleId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(similarity):\n",
    "    if similarity > 0.9:\n",
    "        return 1 # good\n",
    "    elif similarity > 0.8:\n",
    "        return 2 # soso\n",
    "    elif similarity > 0.7:\n",
    "        return 3 # bad\n",
    "    return 4 # ugly\n",
    "\n",
    "df['quality_band'] = df[\"str_similarity\"].apply(quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality_band'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR and GS string similarity distribution\n",
    "\n",
    "Plot the distribution of sentences according to string similarity between OCR and GS text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['str_similarity']].plot(kind='hist',bins=np.arange(0, 1.1, 0.1),rwidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some examples from each bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['str_similarity'] > 0.7) & (df['str_similarity'] <= 0.8)].sample(6).loc[:, ['ocrText', 'humanText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"db_trove.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trovedf = df\n",
    "\n",
    "dExamples = dict()\n",
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "    tempdf = trovedf[(trovedf['str_similarity'] > (i - 0.1)) & (trovedf['str_similarity'] <= i) & (abs(trovedf['ocrText'].str.len() - trovedf['humanText'].str.len()) <= 100)]\n",
    "    if tempdf.shape[0] >= 1:\n",
    "        dExamples[((i - 0.1, i))] = (tempdf.shape[0], tempdf.iloc[0].filePath, tempdf.iloc[0].ocrText, tempdf.iloc[0].humanText)\n",
    "\n",
    "for example in dExamples:\n",
    "    print(\"Range:\", example)\n",
    "    print(\"Number of articles:\", dExamples[example][0])\n",
    "    print(\"Example: ./\" + dExamples[example][1])\n",
    "    print(\"\\nOCR text:\")\n",
    "    print(dExamples[example][2])\n",
    "    print(\"\\nHuman-corrected text:\")\n",
    "    print(dExamples[example][3])\n",
    "    print()\n",
    "    print('==========')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import syntok.segmenter as segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"db_trove.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_cond = (df[\"corrected\"] == '')# & (df[\"str_length_humanText\"] > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"use_corrected\"] = 1\n",
    "df.loc[corrected_cond, 'corrected'] = df.loc[corrected_cond, 'humanText']\n",
    "df.loc[corrected_cond, 'use_corrected'] = 0\n",
    "df['use_corrected'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_corr_diff = abs(df['ocrText'].str.len() - df['corrected'].str.len())\n",
    "ocr_corr_diff /= np.maximum(df['ocrText'].str.len().values, df['corrected'].str.len().values)\n",
    "ocr_corr_diff *= 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(ocr_corr_diff, c='k')\n",
    "plt.grid()\n",
    "plt.xticks(size=24)\n",
    "plt.yticks(size=24)\n",
    "plt.xlabel(\"ArticleID\", size=32)\n",
    "plt.ylabel(\"|#ocrText - #corrected| (%)\", size=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "perc_diff = 10.\n",
    "\n",
    "plt.plot(np.sort(ocr_corr_diff), c='k', lw=3)\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(size=24)\n",
    "plt.yticks(size=24)\n",
    "plt.xlabel(\"#Articles (sorted)\", size=32)\n",
    "plt.ylabel(\"|#ocrText - #corrected| (%)\", size=32)\n",
    "plt.axhline(perc_diff, 0, 1, color='r', ls='--', lw=3)\n",
    "print(\"#Articles with character difference lower than %.2f%%: %i, percentage: %.2f%%\" % (perc_diff, len(ocr_corr_diff[ocr_corr_diff <= perc_diff]), len(ocr_corr_diff[ocr_corr_diff <= perc_diff])/len(ocr_corr_diff)*100.))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy to do most of the pre-processing\n",
    "import spacy\n",
    "# see: https://spacy.io/universe/project/spacy-langdetect\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "# preprocessing\n",
    "# Load a spacy model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# spacy_dict will be later used for the \"Dictionary lookup\" evaluation\n",
    "spacy_dict = list(nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_lookup(myrow, colname=\"corrected\"):\n",
    "    #print(myrow.name, end=\" \")\n",
    "    \n",
    "    sent_list = []\n",
    "    found_dict = []\n",
    "    \n",
    "    for paragraph in segmenter.analyze(myrow[colname]):\n",
    "        for sentence in paragraph:\n",
    "            all_tokens = []\n",
    "            all_txt_dict = []\n",
    "            for token in sentence:\n",
    "                # exactly reproduce the input\n",
    "                # and do not remove \"imperfections\"\n",
    "                # print(token.spacing, token.value, sep='', end='')\n",
    "                all_tokens.append(token.value)\n",
    "                if token.value.lower() in spacy_dict:\n",
    "                    all_txt_dict.append(str(len(token.value)))\n",
    "                else:\n",
    "                    all_txt_dict.append(str(-len(token.value)))\n",
    "            sent_list.append(all_tokens)\n",
    "            found_dict.append(all_txt_dict)\n",
    "            #found_dict.append([])\n",
    "    return sent_list, found_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"db_trove_before_sentencizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "# Initialization\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corrected_sentencizer'] = ''\n",
    "df['corrected_dict_lookup'] = ''\n",
    "\n",
    "df['ocr_sentencizer'] = ''\n",
    "df['ocr_dict_lookup'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corrected_sentencizer'], df['corrected_dict_lookup'] = zip(*df.apply(dictionary_lookup, args=[\"corrected\"], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ocr_sentencizer'], df['ocr_dict_lookup'] = zip(*df.parallel_apply(dictionary_lookup, args=[\"ocrText\"], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"db_trove_sentence_with_lookup.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corrected_sentencizer'] = ''\n",
    "df['corrected_dict_lookup'] = ''\n",
    "\n",
    "df['ocr_sentencizer'] = ''\n",
    "df['ocr_dict_lookup'] = ''\n",
    "\n",
    "counter = 0\n",
    "for i_row, myrow in df.iterrows():\n",
    "    counter += 1\n",
    "    print(counter, end=\" \")\n",
    "    \n",
    "    corrected_sent_list = []\n",
    "    corrected_found_dict = []\n",
    "    ocr_sent_list = []\n",
    "    ocr_found_dict = []\n",
    "    \n",
    "    for paragraph in segmenter.analyze(myrow[\"corrected\"]):\n",
    "        for sentence in paragraph:\n",
    "            all_tokens = []\n",
    "            all_txt_dict = []\n",
    "            for token in sentence:\n",
    "                # exactly reproduce the input\n",
    "                # and do not remove \"imperfections\"\n",
    "                # print(token.spacing, token.value, sep='', end='')\n",
    "                all_tokens.append(token.value)\n",
    "                if token.value.lower() in spacy_dict:\n",
    "                    all_txt_dict.append(str(len(token.value)))\n",
    "                else:\n",
    "                    all_txt_dict.append(str(-len(token.value)))\n",
    "            corrected_sent_list.append(all_tokens)\n",
    "            corrected_found_dict.append(all_txt_dict)\n",
    "    \n",
    "    for paragraph in segmenter.analyze(myrow[\"ocrText\"]):\n",
    "        for sentence in paragraph:\n",
    "            all_tokens = []\n",
    "            all_txt_dict = []\n",
    "            for token in sentence:\n",
    "                # exactly reproduce the input\n",
    "                # and do not remove \"imperfections\"\n",
    "                # print(token.spacing, token.value, sep='', end='')\n",
    "                all_tokens.append(token.value)\n",
    "                if token.value.lower() in spacy_dict:\n",
    "                    all_txt_dict.append(str(len(token.value)))\n",
    "                else:\n",
    "                    all_txt_dict.append(str(-len(token.value)))\n",
    "            ocr_sent_list.append(all_tokens)\n",
    "            ocr_found_dict.append(all_txt_dict)\n",
    "    df.at[i_row, 'corrected_sentencizer'] = corrected_sent_list\n",
    "    df.at[i_row, 'corrected_dict_lookup'] = corrected_found_dict    \n",
    "    df.at[i_row, 'ocr_sentencizer'] = ocr_sent_list  \n",
    "    df.at[i_row, 'ocr_dict_lookup'] = ocr_found_dict    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
