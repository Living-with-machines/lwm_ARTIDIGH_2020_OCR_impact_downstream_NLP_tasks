{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 19:51:23,147 : INFO : loading Word2Vec object from ./LMs/embedding_model_scratch_corrected.model\n",
      "2019-11-20 19:51:24,385 : INFO : loading wv recursively from ./LMs/embedding_model_scratch_corrected.model.wv.* with mmap=None\n",
      "2019-11-20 19:51:24,399 : INFO : loading vectors from ./LMs/embedding_model_scratch_corrected.model.wv.vectors.npy with mmap=None\n",
      "2019-11-20 19:51:24,844 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-20 19:51:24,852 : INFO : loading vocabulary recursively from ./LMs/embedding_model_scratch_corrected.model.vocabulary.* with mmap=None\n",
      "2019-11-20 19:51:24,868 : INFO : loading trainables recursively from ./LMs/embedding_model_scratch_corrected.model.trainables.* with mmap=None\n",
      "2019-11-20 19:51:24,870 : INFO : loading syn1neg from ./LMs/embedding_model_scratch_corrected.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-20 19:51:25,191 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-20 19:51:25,269 : INFO : loaded ./LMs/embedding_model_scratch_corrected.model\n"
     ]
    }
   ],
   "source": [
    "# embedding models, base model\n",
    "#model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\"\n",
    "model_path = \"./LMs/embedding_model_scratch_corrected.model\"\n",
    "w2v_corrected = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_neighbors(myrow, embedding, colname='vocab', topn=1):\n",
    "    try:\n",
    "        vocab_neigh = embedding.wv.most_similar([myrow['vocab']], topn=topn)\n",
    "        return list(np.array(vocab_neigh)[:, 0])\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_df(myrow, colname_1, colname_2, make_lowercase=True):\n",
    "    \"\"\"\n",
    "    Jaccard similarity between two documents (e.g., OCR and Human) on flattened list of words\n",
    "    \"\"\"\n",
    "    list1 = myrow[colname_1]\n",
    "    list2 = myrow[colname_2]\n",
    "    if make_lowercase:\n",
    "        list1 = [x.lower() for x in list1]\n",
    "        list2 = [x.lower() for x in list2]\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_corrected = []\n",
    "for item in w2v_corrected.wv.vocab:\n",
    "    words_corrected.append([item, int(w2v_corrected.wv.vocab[item].count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_words = pd.DataFrame(words_corrected, columns=['vocab', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 179735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>,</td>\n",
       "      <td>860225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>831221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>the</td>\n",
       "      <td>736361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>of</td>\n",
       "      <td>351214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>and</td>\n",
       "      <td>291173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vocab   count\n",
       "57      ,  860225\n",
       "24      .  831221\n",
       "21    the  736361\n",
       "5      of  351214\n",
       "110   and  291173"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_words = pd_words.sort_values(by=['count'], ascending=False)\n",
    "print(\"size: {}\".format(len(pd_words)))\n",
    "pd_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>,</td>\n",
       "      <td>860225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>831221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>the</td>\n",
       "      <td>736361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>of</td>\n",
       "      <td>351214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>and</td>\n",
       "      <td>291173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2483</td>\n",
       "      <td>matches</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8638</td>\n",
       "      <td>cape</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2883</td>\n",
       "      <td>matters</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>prince</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3304</td>\n",
       "      <td>conditions</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           vocab   count\n",
       "57             ,  860225\n",
       "24             .  831221\n",
       "21           the  736361\n",
       "5             of  351214\n",
       "110          and  291173\n",
       "...          ...     ...\n",
       "2483     matches    1142\n",
       "8638        cape    1140\n",
       "2883     matters    1139\n",
       "265       prince    1139\n",
       "3304  conditions    1139\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd2search = pd_words[0:1000]\n",
    "pd2search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality bands 3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of words and their frequencies in the corrected set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 19:56:34,324 : INFO : loading Word2Vec object from ./LMs/w2v_005_EM_ocr_qual_3_4.model\n",
      "2019-11-20 19:56:37,538 : INFO : loading wv recursively from ./LMs/w2v_005_EM_ocr_qual_3_4.model.wv.* with mmap=None\n",
      "2019-11-20 19:56:37,540 : INFO : loading vectors from ./LMs/w2v_005_EM_ocr_qual_3_4.model.wv.vectors.npy with mmap=None\n",
      "2019-11-20 19:56:38,971 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-20 19:56:38,993 : INFO : loading vocabulary recursively from ./LMs/w2v_005_EM_ocr_qual_3_4.model.vocabulary.* with mmap=None\n",
      "2019-11-20 19:56:38,996 : INFO : loading trainables recursively from ./LMs/w2v_005_EM_ocr_qual_3_4.model.trainables.* with mmap=None\n",
      "2019-11-20 19:56:38,997 : INFO : loading syn1neg from ./LMs/w2v_005_EM_ocr_qual_3_4.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-20 19:56:40,004 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-20 19:56:40,015 : INFO : loaded ./LMs/w2v_005_EM_ocr_qual_3_4.model\n",
      "2019-11-20 19:56:42,957 : INFO : loading Word2Vec object from ./LMs/w2v_005_EM_corr_qual_3_4.model\n",
      "2019-11-20 19:56:47,456 : INFO : loading wv recursively from ./LMs/w2v_005_EM_corr_qual_3_4.model.wv.* with mmap=None\n",
      "2019-11-20 19:56:47,459 : INFO : loading vectors from ./LMs/w2v_005_EM_corr_qual_3_4.model.wv.vectors.npy with mmap=None\n",
      "2019-11-20 19:56:48,503 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-20 19:56:48,524 : INFO : loading vocabulary recursively from ./LMs/w2v_005_EM_corr_qual_3_4.model.vocabulary.* with mmap=None\n",
      "2019-11-20 19:56:48,526 : INFO : loading trainables recursively from ./LMs/w2v_005_EM_corr_qual_3_4.model.trainables.* with mmap=None\n",
      "2019-11-20 19:56:48,527 : INFO : loading syn1neg from ./LMs/w2v_005_EM_corr_qual_3_4.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-20 19:56:49,406 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-20 19:56:49,416 : INFO : loaded ./LMs/w2v_005_EM_corr_qual_3_4.model\n",
      "2019-11-20 19:56:52,356 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topn: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "2019-11-20 19:57:37,729 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr: 45.38017201423645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 91.93899583816528\n",
      "topn: 2\n",
      "corr: 57.73870491981506\n",
      "total: 111.64461183547974\n",
      "topn: 5\n",
      "corr: 36.83208179473877\n",
      "total: 94.78911685943604\n",
      "topn: 10\n",
      "corr: 69.45237493515015\n",
      "total: 140.63996291160583\n",
      "topn: 50\n",
      "corr: 82.52211117744446\n",
      "total: 160.23693799972534\n",
      "topn: 100\n",
      "corr: 67.58274292945862\n",
      "total: 124.30753517150879\n",
      "topn: 500\n",
      "corr: 72.02198934555054\n",
      "total: 141.812833070755\n",
      "topn: 1000\n",
      "corr: 58.17880296707153\n",
      "total: 135.97059512138367\n",
      "topn: 5000\n",
      "corr: 118.19587993621826\n",
      "total: 257.04857087135315\n",
      "topn: 10000\n",
      "corr: 174.63330507278442\n",
      "total: 388.95017409324646\n",
      "topn: 50000\n",
      "corr: 391.7289128303528\n",
      "total: 806.5877659320831\n"
     ]
    }
   ],
   "source": [
    "neigh_jaccard_bands_3_4 = []\n",
    "\n",
    "w2v_em_ocr_qual_3_4 = Word2Vec.load('./LMs/w2v_005_EM_ocr_qual_3_4.model')\n",
    "w2v_em_corr_qual_3_4 = Word2Vec.load('./LMs/w2v_005_EM_corr_qual_3_4.model')\n",
    "\n",
    "for topn in [1, 2, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000]:\n",
    "    print(\"topn: {}\".format(topn))\n",
    "    t1 = time.time()\n",
    "    \n",
    "    pd2search = pd_words[0:1000]\n",
    "    pd2search['w2v_em_corr_qual_3_4'] = pd2search.apply(found_neighbors, args=[w2v_em_corr_qual_3_4, \n",
    "                                                                               'vocab', \n",
    "                                                                               topn], axis=1)\n",
    "    print(\"corr: {}\".format(time.time() - t1))\n",
    "    pd2search['w2v_em_ocr_qual_3_4'] = pd2search.apply(found_neighbors, args=[w2v_em_ocr_qual_3_4, \n",
    "                                                                             'vocab', \n",
    "                                                                              topn], axis=1)\n",
    "    pd2search['jaccard_qual_3_4'] = \\\n",
    "        pd2search.apply(jaccard_similarity_df, args=['w2v_em_corr_qual_3_4', \n",
    "                                                     \"w2v_em_ocr_qual_3_4\", \n",
    "                                                     True], \n",
    "                        axis=1)\n",
    "    \n",
    "    neigh_jaccard_bands_3_4.append(\n",
    "        [topn, \n",
    "         pd2search['jaccard_qual_3_4'].mean(), \n",
    "         pd2search['jaccard_qual_3_4'].std(), \n",
    "         0\n",
    "        ])\n",
    "    \n",
    "    print(\"total: {}\".format(time.time() - t1))\n",
    "\n",
    "neigh_jaccard_bands_3_4 = np.array(neigh_jaccard_bands_3_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"neigh_jaccard_bands_3_4.npy\", neigh_jaccard_bands_3_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
