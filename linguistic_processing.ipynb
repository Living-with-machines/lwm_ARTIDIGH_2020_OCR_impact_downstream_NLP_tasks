{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of OCR in linguistic processing\n",
    "\n",
    "Tasks in this notebook:\n",
    "- [ ] Part-of-speech tagging\n",
    "- [ ] Named entity recognition\n",
    "- [ ] Dependency parsing\n",
    "- [ ] Semantic role labelling\n",
    "\n",
    "Not considered here:\n",
    "- Sentence splitting\n",
    "- Tokenisation\n",
    "- Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import glob\n",
    "import syntok.segmenter as segmenter\n",
    "from spacy.tokens import Doc\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_preprocessing(doc):\n",
    "    with open(doc) as fr:\n",
    "        lines = fr.readlines()\n",
    "        ocr_toinput = lines[0].replace('[OCR_toInput]', '')\n",
    "        ocr_aligned = lines[1].replace('[OCR_aligned]', '')\n",
    "        gs_aligned = lines[2].replace('[ GS_aligned]', '')\n",
    "        return ocr_aligned, gs_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligned sentence splitting using Syntok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aligned_sentence_splitting(ocr_aligned, gs_aligned):\n",
    "    \"\"\"\n",
    "    Sentence splitting with syntok.segmenter.\n",
    "    \"\"\"\n",
    "    list_sentence_offsets = []\n",
    "    sentenceTuples = []\n",
    "\n",
    "    for paragraph in segmenter.process(gs_aligned):\n",
    "        for sentence in paragraph:\n",
    "            list_sentence_offsets.append(sentence[0].offset)\n",
    "\n",
    "    for x in range(len(list_sentence_offsets)):\n",
    "        begSentence = list_sentence_offsets[x]\n",
    "        try:\n",
    "            endSentence = list_sentence_offsets[x+1]\n",
    "        except IndexError:\n",
    "            endSentence = len(gs_aligned)\n",
    "        ocr_sentence = ocr_aligned[begSentence - 1 : endSentence - 1]\n",
    "        gs_sentence = gs_aligned[begSentence - 1 : endSentence - 1]\n",
    "        sentenceTuples.append((begSentence, endSentence, ocr_sentence, gs_sentence))\n",
    "        \n",
    "    return sentenceTuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_aligned, gs_aligned = generic_preprocessing('example.txt')\n",
    "alignedSentences = aligned_sentence_splitting(ocr_aligned, gs_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate part-of-speech tagging\n",
    "\n",
    "[In progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pos(ocr_sentence, gs_sentence):\n",
    "    ocr_pos_sequence = dict()\n",
    "    gs_pos_sequence = dict()\n",
    "    for token in ocr_sentence:\n",
    "        ocr_pos_sequence[token.idx] = (token.text, token.pos_)\n",
    "    for token in gs_sentence:\n",
    "        gs_pos_sequence[token.idx] = (token.text, token.pos_)\n",
    "    \n",
    "    for k, v in gs_pos_sequence.items():\n",
    "        if k in ocr_pos_sequence:\n",
    "            print(k, ocr_pos_sequence[k], v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate named entity recognition\n",
    "\n",
    "[In progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ner(ocr_sentence, gs_sentence):\n",
    "    ocr_ner_sequence = dict()\n",
    "    gs_ner_sequence = dict()\n",
    "    for token in ocr_sentence:\n",
    "        ocr_ner_sequence[token.idx] = (token.text, token.ent_type_, token.ent_iob_)\n",
    "    for token in gs_sentence:\n",
    "        gs_ner_sequence[token.idx] = (token.text, token.ent_type_, token.ent_iob_)\n",
    "    \n",
    "    for k, v in gs_ner_sequence.items():\n",
    "        if k in ocr_ner_sequence:\n",
    "            print(k, ocr_ner_sequence[k], v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare OCR aligned with GS aligned\n",
    "\n",
    "[In progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in alignedSentences:\n",
    "    st_boundaries = (st[0], st[1])\n",
    "    ocr_sentence = nlp(st[2])\n",
    "    gs_sentence = nlp(st[3])\n",
    "    \n",
    "    evaluate_pos(ocr_sentence, gs_sentence)\n",
    "    evaluate_ner(ocr_sentence, gs_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for token in nlp(ocr_sentence):\n",
    "#         print(token.idx, token.text, token.lemma_, token.pos_, token.dep_, token.head, token.left_edge, token.right_edge, token.ent_type_, token.ent_iob_, token.is_oov)\n",
    "#     print()\n",
    "#     for token in nlp(gs_sentence):\n",
    "#         print(token.idx, token.text, token.lemma_, token.pos_, token.dep_, token.head, token.left_edge, token.right_edge, token.ent_type_, token.ent_iob_, token.is_oov)\n",
    "#     print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allennlp]",
   "language": "python",
   "name": "conda-env-allennlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
