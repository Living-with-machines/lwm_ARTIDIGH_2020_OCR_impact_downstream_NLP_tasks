{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import copy\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a pre-trained language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:22:44,514 : INFO : loading Word2Vec object from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\n",
      "2019-11-20 18:22:45,462 : INFO : loading wv recursively from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.wv.* with mmap=None\n",
      "2019-11-20 18:22:45,463 : INFO : loading vectors from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.wv.vectors.npy with mmap=None\n",
      "2019-11-20 18:22:45,797 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-11-20 18:22:45,798 : INFO : loading vocabulary recursively from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.vocabulary.* with mmap=None\n",
      "2019-11-20 18:22:45,799 : INFO : loading trainables recursively from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.trainables.* with mmap=None\n",
      "2019-11-20 18:22:45,800 : INFO : loading syn1neg from /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-11-20 18:22:46,224 : INFO : setting ignored attribute cum_table to None\n",
      "2019-11-20 18:22:46,225 : INFO : loaded /Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=434049, size=300, alpha=0.03)\n"
     ]
    }
   ],
   "source": [
    "# model types\n",
    "# w2v: word2vec\n",
    "# ft: fasttext\n",
    "model_type = \"w2v\"   \n",
    "model_path = \"/Users/khosseini/myJobs/ATI/Projects/2019/Living-with-Machines-code/language-lab-mro/lexicon_expansion/interactive_expansion/models/all_books/w2v_005/w2v_words.model\"\n",
    "\n",
    "if model_type.lower() in [\"w2v\", \"word2vec\"]:\n",
    "    # Word2Vec\n",
    "    embedding_model_orig = Word2Vec.load(model_path)\n",
    "elif model_type.lower() in [\"ft\", \"fasttext\"]:\n",
    "    # FastText\n",
    "    embedding_model_orig = FastText.load(model_path)\n",
    "print(embedding_model_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007000009816451012"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_alpha_yet_reached = embedding_model_orig.min_alpha_yet_reached\n",
    "min_alpha_yet_reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_sentence_orig = pd.read_pickle(\"./db_trove_v002.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality bands 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3600\n",
       "4    1495\n",
       "Name: quality_band, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_sentence = db_sentence_orig[(db_sentence_orig['quality_band'] == 3) | \n",
    "                               (db_sentence_orig['quality_band'] == 4)]\n",
    "db_sentence['quality_band'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef cleanup(myrow, colname=\"corrected\"):\\n    # remove all # and @§\\n    \\n    corpus = [re.sub(r\\'#\\', \\'\\', element, flags=re.IGNORECASE) for element in corpus]\\n    corpus = [re.sub(r\\'@\\', \\'\\', element, flags=re.IGNORECASE) for element in corpus]\\n    \\n    # --- remove 2 or more .\\n    corpus = [re.sub(\\'[.]{2,}\\', \\'.\\', element) for element in corpus]\\n    # --- add a space before and after a list of punctuations\\n    corpus = [re.sub(r\"([.,!?:;\"\\'])\", r\" \\x01 \", element) for element in corpus]\\n    # --- remove everything except:\\n    #corpus = [re.sub(r\"([^a-zA-Z\\\\-.:;,!?\\\\d+]+)\", r\" \", element) for element in corpus]\\n    corpus = [re.sub(r\"([^a-zA-Z\\\\d+]+)\", r\" \", element) for element in corpus]\\n    # --- replace numbers with <NUM>\\n    corpus = [re.sub(r\\'\\x08\\\\d+\\x08\\', \\'<NUM>\\', element) for element in corpus]\\n    corpus = [re.sub(\\'--\\', \\'\\', element) for element in corpus]\\n    # --- normalize white spaces\\n    corpus = [re.sub(\\'\\\\s+\\', \\' \\', element) for element in corpus]\\n    \\n    # remove multiple spaces\\n    corpus = [re.sub(r\\'\\\\s+\\', \\' \\', element, flags=re.IGNORECASE) for element in corpus]\\n    corpus = [element.strip() for element in corpus]\\n    #corpus = [element.lower() for element in corpus]\\n    return corpus\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def cleanup(myrow, colname=\"corrected\"):\n",
    "    # remove all # and @§\n",
    "    \n",
    "    corpus = [re.sub(r'#', '', element, flags=re.IGNORECASE) for element in corpus]\n",
    "    corpus = [re.sub(r'@', '', element, flags=re.IGNORECASE) for element in corpus]\n",
    "    \n",
    "    # --- remove 2 or more .\n",
    "    corpus = [re.sub('[.]{2,}', '.', element) for element in corpus]\n",
    "    # --- add a space before and after a list of punctuations\n",
    "    corpus = [re.sub(r\"([.,!?:;\\\"\\'])\", r\" \\1 \", element) for element in corpus]\n",
    "    # --- remove everything except:\n",
    "    #corpus = [re.sub(r\"([^a-zA-Z\\-.:;,!?\\d+]+)\", r\" \", element) for element in corpus]\n",
    "    corpus = [re.sub(r\"([^a-zA-Z\\d+]+)\", r\" \", element) for element in corpus]\n",
    "    # --- replace numbers with <NUM>\n",
    "    corpus = [re.sub(r'\\b\\d+\\b', '<NUM>', element) for element in corpus]\n",
    "    corpus = [re.sub('--', '', element) for element in corpus]\n",
    "    # --- normalize white spaces\n",
    "    corpus = [re.sub('\\s+', ' ', element) for element in corpus]\n",
    "    \n",
    "    # remove multiple spaces\n",
    "    corpus = [re.sub(r'\\s+', ' ', element, flags=re.IGNORECASE) for element in corpus]\n",
    "    corpus = [element.strip() for element in corpus]\n",
    "    #corpus = [element.lower() for element in corpus]\n",
    "    return corpus\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(myrow, col_name):\n",
    "    all_clean_rows = []\n",
    "    for sent in myrow[col_name]:\n",
    "        one_clean_row = []\n",
    "        for token in sent:\n",
    "            one_clean_row.append(token.lower())\n",
    "        all_clean_rows.append(one_clean_row)\n",
    "    return all_clean_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "db_sentence[\"ocr_sentencizer_cleaned\"] = db_sentence.apply(cleanup, args=[\"ocr_sentencizer\"], axis=1)\n",
    "db_sentence[\"corrected_sentencizer_cleaned\"] = db_sentence.apply(cleanup, args=[\"corrected_sentencizer\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5095, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>articleId</th>\n",
       "      <th>articleType</th>\n",
       "      <th>year</th>\n",
       "      <th>ocrText</th>\n",
       "      <th>humanText</th>\n",
       "      <th>corrected</th>\n",
       "      <th>str_similarity</th>\n",
       "      <th>str_length_humanText</th>\n",
       "      <th>str_length_ocrText</th>\n",
       "      <th>...</th>\n",
       "      <th>ocr_dict_lookup</th>\n",
       "      <th>ocr_dict_lookup_list</th>\n",
       "      <th>ocr_dict_perc</th>\n",
       "      <th>corrected_dict_lookup_list</th>\n",
       "      <th>corr_dict_perc</th>\n",
       "      <th>corrected_sentencizer_list</th>\n",
       "      <th>ocr_sentencizer_list</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>ocr_sentencizer_cleaned</th>\n",
       "      <th>corrected_sentencizer_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18366055</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>FIRST CHURCH I SERVICE 1 Presbyterian I ' Anni...</td>\n",
       "      <td>FIRST CHURCH SERVICE Presbyterian Anniversary ...</td>\n",
       "      <td>FIRST CHURCH SERVICE Presbyterian Anniversary ...</td>\n",
       "      <td>0.738901</td>\n",
       "      <td>946</td>\n",
       "      <td>832</td>\n",
       "      <td>...</td>\n",
       "      <td>[[5, 6, 1, 7, 1, 12, 1, 1, 11, 1, 3, 5, -12, 3...</td>\n",
       "      <td>[5, 6, 1, 7, 1, 12, 1, 1, 11, 1, 3, 5, -12, 3,...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>[5, 6, 7, 12, 11, 3, 5, 11, 2, 3, 5, 12, 6, 7,...</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>[FIRST, CHURCH, SERVICE, Presbyterian, Anniver...</td>\n",
       "      <td>[FIRST, CHURCH, I, SERVICE, 1, Presbyterian, I...</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>[[first, church, i, service, 1, presbyterian, ...</td>\n",
       "      <td>[[first, church, service, presbyterian, annive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18386137</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>\"Bob\" Lulham's Fight Against Thallium District...</td>\n",
       "      <td>\"Bob\" Lulham's Fight Against Thallium  Arthur ...</td>\n",
       "      <td>\"Bob\" Lulham's Fight Against Thallium  Arthur ...</td>\n",
       "      <td>0.493898</td>\n",
       "      <td>2950</td>\n",
       "      <td>2740</td>\n",
       "      <td>...</td>\n",
       "      <td>[[1, 3, 1, -6, 2, 5, 7, 8, 8, 8, 1], [4, 5, 6,...</td>\n",
       "      <td>[1, 3, 1, -6, 2, 5, 7, 8, 8, 8, 1, 4, 5, 6, 6,...</td>\n",
       "      <td>95.580110</td>\n",
       "      <td>[1, 3, 1, -6, 2, 5, 7, 8, 6, 6, 1, 1, 3, 1, 1,...</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>[\", Bob, \", Lulham, 's, Fight, Against, Thalli...</td>\n",
       "      <td>[\", Bob, \", Lulham, 's, Fight, Against, Thalli...</td>\n",
       "      <td>0.282682</td>\n",
       "      <td>[[\", bob, \", lulham, 's, fight, against, thall...</td>\n",
       "      <td>[[\", bob, \", lulham, 's, fight, against, thall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18391223</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>rchitect For lympics aid £31,665 - ?? MELBOURN...</td>\n",
       "      <td>Architect For Olympics paid £31,665  MELBOURNE...</td>\n",
       "      <td>Architect For Olympics paid £31,665  MELBOURNE...</td>\n",
       "      <td>0.793510</td>\n",
       "      <td>678</td>\n",
       "      <td>585</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-8, 3, 7, 3, 1, -6, 1, 2, 9, 1, 6], [1, 1, 5...</td>\n",
       "      <td>[-8, 3, 7, 3, 1, -6, 1, 2, 9, 1, 6, 1, 1, 5, 5...</td>\n",
       "      <td>88.607595</td>\n",
       "      <td>[9, 3, 8, 4, 1, -6, 9, 1, 6, 2, 5, 5, 1, 3, 9,...</td>\n",
       "      <td>94.680851</td>\n",
       "      <td>[Architect, For, Olympics, paid, £, 31,665, ME...</td>\n",
       "      <td>[rchitect, For, lympics, aid, £, 31,665, -, ??...</td>\n",
       "      <td>0.302885</td>\n",
       "      <td>[[rchitect, for, lympics, aid, £, 31,665, -, ?...</td>\n",
       "      <td>[[architect, for, olympics, paid, £, 31,665, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18392087</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>Mint Building i Sur,--Tb* cía .\\-fint Build- i...</td>\n",
       "      <td>Mint Building Sir, - The old Mint Build- ing i...</td>\n",
       "      <td>Mint Building Sir, - The old Mint Build- ing i...</td>\n",
       "      <td>0.687574</td>\n",
       "      <td>813</td>\n",
       "      <td>845</td>\n",
       "      <td>...</td>\n",
       "      <td>[[4, 8, 1, -8, 1, 3, 1, 1, 1, 4, 5, 1, 3, 2, 9...</td>\n",
       "      <td>[4, 8, 1, -8, 1, 3, 1, 1, 1, 4, 5, 1, 3, 2, 9,...</td>\n",
       "      <td>64.347826</td>\n",
       "      <td>[4, 8, 3, 1, 1, 3, 3, 4, 5, 1, 3, 2, 9, 6, 1, ...</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>[Mint, Building, Sir, ,, -, The, old, Mint, Bu...</td>\n",
       "      <td>[Mint, Building, i, Sur,--Tb, *, cía, ., \\, -,...</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>[[mint, building, i, sur,--tb, *, cía, ., \\, -...</td>\n",
       "      <td>[[mint, building, sir, ,, -, the, old, mint, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>27904257</td>\n",
       "      <td>Article ILLUSTRATED</td>\n",
       "      <td>1947</td>\n",
       "      <td>PEARL TOWN PAINTED BY ELIZABETH DURACK \"The st...</td>\n",
       "      <td>PEARL TOWN PAINTED BY ELIZABETH DURACK \"The st...</td>\n",
       "      <td>PEARL TOWN PAINTED BY ELIZABETH DURACK \"The st...</td>\n",
       "      <td>0.744510</td>\n",
       "      <td>2732</td>\n",
       "      <td>2722</td>\n",
       "      <td>...</td>\n",
       "      <td>[[5, 4, 7, 2, 9, 6, 1, 3, 5, 2, 3, 5, 4, 8, 4,...</td>\n",
       "      <td>[5, 4, 7, 2, 9, 6, 1, 3, 5, 2, 3, 5, 4, 8, 4, ...</td>\n",
       "      <td>96.800000</td>\n",
       "      <td>[5, 4, 7, 2, 9, 6, 1, 3, 5, 2, 3, 5, 4, 8, 4, ...</td>\n",
       "      <td>99.726776</td>\n",
       "      <td>[PEARL, TOWN, PAINTED, BY, ELIZABETH, DURACK, ...</td>\n",
       "      <td>[PEARL, TOWN, PAINTED, BY, ELIZABETH, DURACK, ...</td>\n",
       "      <td>0.236032</td>\n",
       "      <td>[[pearl, town, painted, by, elizabeth, durack,...</td>\n",
       "      <td>[[pearl, town, painted, by, elizabeth, durack,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filePath articleId  \\\n",
       "3   ./trove_overproof/datasets/dataset1/rawTextAnd...  18366055   \n",
       "4   ./trove_overproof/datasets/dataset1/rawTextAnd...  18386137   \n",
       "10  ./trove_overproof/datasets/dataset1/rawTextAnd...  18391223   \n",
       "21  ./trove_overproof/datasets/dataset1/rawTextAnd...  18392087   \n",
       "25  ./trove_overproof/datasets/dataset1/rawTextAnd...  27904257   \n",
       "\n",
       "             articleType  year  \\\n",
       "3                Article  1953   \n",
       "4                Article  1953   \n",
       "10               Article  1953   \n",
       "21               Article  1953   \n",
       "25  Article ILLUSTRATED   1947   \n",
       "\n",
       "                                              ocrText  \\\n",
       "3   FIRST CHURCH I SERVICE 1 Presbyterian I ' Anni...   \n",
       "4   \"Bob\" Lulham's Fight Against Thallium District...   \n",
       "10  rchitect For lympics aid £31,665 - ?? MELBOURN...   \n",
       "21  Mint Building i Sur,--Tb* cía .\\-fint Build- i...   \n",
       "25  PEARL TOWN PAINTED BY ELIZABETH DURACK \"The st...   \n",
       "\n",
       "                                            humanText  \\\n",
       "3   FIRST CHURCH SERVICE Presbyterian Anniversary ...   \n",
       "4   \"Bob\" Lulham's Fight Against Thallium  Arthur ...   \n",
       "10  Architect For Olympics paid £31,665  MELBOURNE...   \n",
       "21  Mint Building Sir, - The old Mint Build- ing i...   \n",
       "25  PEARL TOWN PAINTED BY ELIZABETH DURACK \"The st...   \n",
       "\n",
       "                                            corrected  str_similarity  \\\n",
       "3   FIRST CHURCH SERVICE Presbyterian Anniversary ...        0.738901   \n",
       "4   \"Bob\" Lulham's Fight Against Thallium  Arthur ...        0.493898   \n",
       "10  Architect For Olympics paid £31,665  MELBOURNE...        0.793510   \n",
       "21  Mint Building Sir, - The old Mint Build- ing i...        0.687574   \n",
       "25  PEARL TOWN PAINTED BY ELIZABETH DURACK \"The st...        0.744510   \n",
       "\n",
       "    str_length_humanText  str_length_ocrText  ...  \\\n",
       "3                    946                 832  ...   \n",
       "4                   2950                2740  ...   \n",
       "10                   678                 585  ...   \n",
       "21                   813                 845  ...   \n",
       "25                  2732                2722  ...   \n",
       "\n",
       "                                      ocr_dict_lookup  \\\n",
       "3   [[5, 6, 1, 7, 1, 12, 1, 1, 11, 1, 3, 5, -12, 3...   \n",
       "4   [[1, 3, 1, -6, 2, 5, 7, 8, 8, 8, 1], [4, 5, 6,...   \n",
       "10  [[-8, 3, 7, 3, 1, -6, 1, 2, 9, 1, 6], [1, 1, 5...   \n",
       "21  [[4, 8, 1, -8, 1, 3, 1, 1, 1, 4, 5, 1, 3, 2, 9...   \n",
       "25  [[5, 4, 7, 2, 9, 6, 1, 3, 5, 2, 3, 5, 4, 8, 4,...   \n",
       "\n",
       "                                 ocr_dict_lookup_list ocr_dict_perc  \\\n",
       "3   [5, 6, 1, 7, 1, 12, 1, 1, 11, 1, 3, 5, -12, 3,...     82.000000   \n",
       "4   [1, 3, 1, -6, 2, 5, 7, 8, 8, 8, 1, 4, 5, 6, 6,...     95.580110   \n",
       "10  [-8, 3, 7, 3, 1, -6, 1, 2, 9, 1, 6, 1, 1, 5, 5...     88.607595   \n",
       "21  [4, 8, 1, -8, 1, 3, 1, 1, 1, 4, 5, 1, 3, 2, 9,...     64.347826   \n",
       "25  [5, 4, 7, 2, 9, 6, 1, 3, 5, 2, 3, 5, 4, 8, 4, ...     96.800000   \n",
       "\n",
       "                           corrected_dict_lookup_list corr_dict_perc  \\\n",
       "3   [5, 6, 7, 12, 11, 3, 5, 11, 2, 3, 5, 12, 6, 7,...      99.206349   \n",
       "4   [1, 3, 1, -6, 2, 5, 7, 8, 6, 6, 1, 1, 3, 1, 1,...      95.652174   \n",
       "10  [9, 3, 8, 4, 1, -6, 9, 1, 6, 2, 5, 5, 1, 3, 9,...      94.680851   \n",
       "21  [4, 8, 3, 1, 1, 3, 3, 4, 5, 1, 3, 2, 9, 6, 1, ...      98.333333   \n",
       "25  [5, 4, 7, 2, 9, 6, 1, 3, 5, 2, 3, 5, 4, 8, 4, ...      99.726776   \n",
       "\n",
       "                           corrected_sentencizer_list  \\\n",
       "3   [FIRST, CHURCH, SERVICE, Presbyterian, Anniver...   \n",
       "4   [\", Bob, \", Lulham, 's, Fight, Against, Thalli...   \n",
       "10  [Architect, For, Olympics, paid, £, 31,665, ME...   \n",
       "21  [Mint, Building, Sir, ,, -, The, old, Mint, Bu...   \n",
       "25  [PEARL, TOWN, PAINTED, BY, ELIZABETH, DURACK, ...   \n",
       "\n",
       "                                 ocr_sentencizer_list  jaccard_similarity  \\\n",
       "3   [FIRST, CHURCH, I, SERVICE, 1, Presbyterian, I...            0.191919   \n",
       "4   [\", Bob, \", Lulham, 's, Fight, Against, Thalli...            0.282682   \n",
       "10  [rchitect, For, lympics, aid, £, 31,665, -, ??...            0.302885   \n",
       "21  [Mint, Building, i, Sur,--Tb, *, cía, ., \\, -,...            0.163399   \n",
       "25  [PEARL, TOWN, PAINTED, BY, ELIZABETH, DURACK, ...            0.236032   \n",
       "\n",
       "                              ocr_sentencizer_cleaned  \\\n",
       "3   [[first, church, i, service, 1, presbyterian, ...   \n",
       "4   [[\", bob, \", lulham, 's, fight, against, thall...   \n",
       "10  [[rchitect, for, lympics, aid, £, 31,665, -, ?...   \n",
       "21  [[mint, building, i, sur,--tb, *, cía, ., \\, -...   \n",
       "25  [[pearl, town, painted, by, elizabeth, durack,...   \n",
       "\n",
       "                        corrected_sentencizer_cleaned  \n",
       "3   [[first, church, service, presbyterian, annive...  \n",
       "4   [[\", bob, \", lulham, 's, fight, against, thall...  \n",
       "10  [[architect, for, olympics, paid, £, 31,665, m...  \n",
       "21  [[mint, building, sir, ,, -, the, old, mint, b...  \n",
       "25  [[pearl, town, painted, by, elizabeth, durack,...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(db_sentence.shape)\n",
    "db_sentence.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update a pre-trained LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args for Word2Vec\n",
    "w2v_args = Namespace(\n",
    "    epochs=5, \n",
    "    # only for Word2Vec\n",
    "    compute_loss=True,                               # If True, computes and stores loss value which can be retrieved using get_latest_training_loss().\n",
    "\n",
    "#     size=100,                                        # Dimensionality of the word vectors.\n",
    "#     alpha=0.03,                                      # The initial learning rate.\n",
    "#     min_alpha=0.0007,                                # Learning rate will linearly drop to min_alpha as training progresses.\n",
    "#     sg=1,                                            # Training algorithm: skip-gram if sg=1, otherwise CBOW.\n",
    "#     hs=0,                                            # If 1, hierarchical softmax will be used for model training. If set to 0, and negative is non-zero, negative sampling will be used.\n",
    "#     negative=20,                                     # If > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). If set to 0, no negative sampling is used. \n",
    "#     min_count=5,                                    # The model ignores all words with total frequency lower than this.\n",
    "#     window=5,                                        # The maximum distance between the current and predicted word within a sentence.\n",
    "#     sample=1e-3,                                     # The threshold for configuring which higher-frequency words are randomly downsampled, useful range is (0, 1e-5).\n",
    "#     workers=8, \n",
    "#     cbow_mean=1,                                     # If 0, use the sum of the context word vectors. If 1, use the mean, only applies when cbow is used.\n",
    "#     null_word=0,                                     # \n",
    "#     trim_rule=None,                                  # \n",
    "#     sorted_vocab=1,                                  # If 1, sort the vocabulary by descending frequency before assigning word indices.\n",
    "#     batch_words=10000,                               # Target size (in words) for batches of examples passed to worker threads (and thus cython routines).(Larger batches will be passed if individual texts are longer than 10000 words, but the standard cython code truncates to that maximum.)\n",
    "    \n",
    "#     seed=1364,                                       # Seed for the random number generator.\n",
    "#     # only for FastText (compare to word2vec)\n",
    "#     #word_ngrams=1,                                   # If 1, uses enriches word vectors with subword(n-grams) information. If 0, this is equivalent to Word2Vec. \n",
    "#     #min_n=2,                                         # Minimum length of char n-grams to be used for training word representations.\n",
    "#     #max_n=15,                                        # Max length of char ngrams to be used for training word representations. Set max_n to be lesser than min_n to avoid char ngrams being used.\n",
    "#     #bucket=2000000                                  # Character ngrams are hashed into a fixed number of buckets, in order to limit the memory usage of the model. This option specifies the number of buckets used by the model.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess before creating/updating LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef preprocess4LM(myrow, col_name=\"ocrText_cleaned_tokenize\"):\\n    txt = [token.lemma_ for token in nlp(myrow[col_name].lower())]\\n    return txt\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def preprocess4LM(myrow, col_name=\"ocrText_cleaned_tokenize\"):\n",
    "    txt = [token.lemma_ for token in nlp(myrow[col_name].lower())]\n",
    "    return txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndb_sentence[\"ocrText_cleaned_tokenize\"] = db_sentence[0:10].apply(preprocess4LM, args=[\"ocrText_cleaned\"], axis=1)\\ndb_sentence[\"corrected_cleaned_tokenize\"] = db_sentence[0:10].apply(preprocess4LM, args=[\"corrected_cleaned\"], axis=1)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "db_sentence[\"ocrText_cleaned_tokenize\"] = db_sentence[0:10].apply(preprocess4LM, args=[\"ocrText_cleaned\"], axis=1)\n",
    "db_sentence[\"corrected_cleaned_tokenize\"] = db_sentence[0:10].apply(preprocess4LM, args=[\"corrected_cleaned\"], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n"
     ]
    }
   ],
   "source": [
    "list_sentences = db_sentence[\"ocr_sentencizer_cleaned\"].to_list()\n",
    "print('#sentences: {}'.format(len(list_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42059"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_list_sentences = [val for sublist in list_sentences for val in sublist]\n",
    "len(flattened_list_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'church',\n",
       " 'i',\n",
       " 'service',\n",
       " '1',\n",
       " 'presbyterian',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'anniversary',\n",
       " '1',\n",
       " 'the',\n",
       " '150th',\n",
       " 'anniveisarjj',\n",
       " 'the',\n",
       " 'first',\n",
       " 'presb',\n",
       " '>',\n",
       " 'terian',\n",
       " 'chad',\n",
       " 'service',\n",
       " 'm',\n",
       " 'australia',\n",
       " 'will',\n",
       " 'k',\n",
       " 'celebrated',\n",
       " 'to',\n",
       " 'morrow',\n",
       " 'special',\n",
       " 'services',\n",
       " 'will',\n",
       " 'be',\n",
       " 'be',\n",
       " 'at',\n",
       " 'the',\n",
       " 'ebenezer',\n",
       " 'p«sbjt«j',\n",
       " 'church',\n",
       " ',',\n",
       " 'six',\n",
       " 'miles',\n",
       " 'from',\n",
       " 'wmdso',\n",
       " 'the',\n",
       " 'ebenezer',\n",
       " 'church',\n",
       " 'is',\n",
       " '»',\n",
       " 'oldest',\n",
       " 'church',\n",
       " 'in',\n",
       " 'australia',\n",
       " '?',\n",
       " 'which',\n",
       " 'services',\n",
       " 'are',\n",
       " 'still',\n",
       " '«',\n",
       " 'ia',\n",
       " 'the',\n",
       " 'sen',\n",
       " 'ice',\n",
       " 'v',\n",
       " '.',\n",
       " '.',\n",
       " '11',\n",
       " 'start',\n",
       " 'at',\n",
       " 'lp',\n",
       " '£',\n",
       " 'with',\n",
       " 'sacred',\n",
       " 'mus.c',\n",
       " 'ttajjl',\n",
       " '*',\n",
       " 'followed',\n",
       " 'at',\n",
       " '130',\n",
       " 'p',\n",
       " 'm',\n",
       " '«*£',\n",
       " 'dedication',\n",
       " 'of',\n",
       " 'commemorate',\n",
       " 'g',\n",
       " 'tue',\n",
       " 'moderator',\n",
       " 'general',\n",
       " 'of',\n",
       " 'j',\n",
       " '«',\n",
       " 'presbyterian',\n",
       " 'church',\n",
       " 'of',\n",
       " 'au',\n",
       " '»',\n",
       " 'the',\n",
       " 'right',\n",
       " 'rev',\n",
       " '^',\n",
       " '¿',\n",
       " 'bz',\n",
       " 'will',\n",
       " 'conduct',\n",
       " 'a',\n",
       " 'special',\n",
       " 'atfhe',\n",
       " 'pä',\n",
       " 'ws«.llbe^r',\n",
       " 'the',\n",
       " 'modentor',\n",
       " 'of',\n",
       " 'the',\n",
       " 'general',\n",
       " 'assemblv',\n",
       " 'the',\n",
       " 'rig',\n",
       " '«',\n",
       " \"'\",\n",
       " 'frank',\n",
       " 'hinlin',\n",
       " 'of',\n",
       " 'manly',\n",
       " 'the',\n",
       " 'police',\n",
       " 'p',\n",
       " \"'p\",\n",
       " '=',\n",
       " 'ft',\n",
       " 'se',\n",
       " '«',\n",
       " '?',\n",
       " 'present',\n",
       " 'at',\n",
       " 'the',\n",
       " 'churc',\n",
       " '«',\n",
       " ',',\n",
       " 'and',\n",
       " 'm',\n",
       " 'college',\n",
       " 'and',\n",
       " 'knox',\n",
       " 'ui',\n",
       " 'y',\n",
       " '_',\n",
       " 'school',\n",
       " 'students',\n",
       " 'will',\n",
       " 'prouo',\n",
       " '?',\n",
       " 'guard',\n",
       " 'of',\n",
       " 'hçnour',\n",
       " 'fm',\n",
       " 'm',\n",
       " 'special',\n",
       " 'trains',\n",
       " '»',\n",
       " \"'\",\n",
       " '»',\n",
       " '¿',\n",
       " 't«»,tl',\n",
       " 'h',\n",
       " 'central',\n",
       " 'to',\n",
       " 'windsor',\n",
       " 'bu',\n",
       " '«',\n",
       " 'h',\n",
       " 'take',\n",
       " 'people',\n",
       " 'on',\n",
       " 'to',\n",
       " 'the',\n",
       " 'wen',\n",
       " '?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_list_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_ocr = copy.deepcopy(embedding_model_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_ocr.workers = 8\n",
    "embedding_model_ocr.vocabulary.min_count = 5\n",
    "embedding_model_ocr.alpha = min_alpha_yet_reached*10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:26:26,901 : INFO : collecting all words and their counts\n",
      "2019-11-20 18:26:26,903 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 18:26:27,015 : INFO : PROGRESS: at sentence #10000, processed 434822 words, keeping 90410 word types\n",
      "2019-11-20 18:26:27,110 : INFO : PROGRESS: at sentence #20000, processed 886062 words, keeping 160063 word types\n",
      "2019-11-20 18:26:27,235 : INFO : PROGRESS: at sentence #30000, processed 1366349 words, keeping 227866 word types\n",
      "2019-11-20 18:26:27,328 : INFO : PROGRESS: at sentence #40000, processed 1789264 words, keeping 284758 word types\n",
      "2019-11-20 18:26:27,351 : INFO : collected 298566 word types from a corpus of 1896341 raw words and 42059 sentences\n",
      "2019-11-20 18:26:27,352 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 18:26:27,498 : INFO : New added 19776 unique words (6% of original 318342) and increased the count of 19776 pre-existing words (6% of original 318342)\n",
      "2019-11-20 18:26:27,636 : INFO : deleting the raw counts dictionary of 298566 items\n",
      "2019-11-20 18:26:27,642 : INFO : sample=0.001 downsamples 100 most-common words\n",
      "2019-11-20 18:26:27,643 : INFO : downsampling leaves estimated 2218004 word corpus (141.6% of prior 1566450)\n",
      "2019-11-20 18:26:28,750 : INFO : estimated required memory for 39552 words and 300 dimensions: 114700800 bytes\n",
      "2019-11-20 18:26:28,750 : INFO : updating layer weights\n",
      "2019-11-20 18:26:29,901 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 18:26:29,902 : INFO : training model with 8 workers on 436964 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 18:26:31,028 : INFO : EPOCH 1 - PROGRESS: at 8.15% examples, 95585 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:32,125 : INFO : EPOCH 1 - PROGRESS: at 22.32% examples, 114030 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:33,140 : INFO : EPOCH 1 - PROGRESS: at 34.73% examples, 121530 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:34,169 : INFO : EPOCH 1 - PROGRESS: at 45.75% examples, 122348 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:35,207 : INFO : EPOCH 1 - PROGRESS: at 55.80% examples, 124178 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:36,232 : INFO : EPOCH 1 - PROGRESS: at 66.68% examples, 125682 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:37,277 : INFO : EPOCH 1 - PROGRESS: at 77.58% examples, 124602 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:38,300 : INFO : EPOCH 1 - PROGRESS: at 89.28% examples, 124753 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:39,105 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:26:39,197 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:26:39,254 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:26:39,255 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:26:39,320 : INFO : EPOCH 1 - PROGRESS: at 98.62% examples, 123125 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 18:26:39,321 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:26:39,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:26:39,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:26:39,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:26:39,431 : INFO : EPOCH - 1 : training on 1896341 raw words (1177598 effective words) took 9.5s, 123672 effective words/s\n",
      "2019-11-20 18:26:40,707 : INFO : EPOCH 2 - PROGRESS: at 8.15% examples, 84424 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:41,801 : INFO : EPOCH 2 - PROGRESS: at 22.32% examples, 106880 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:42,900 : INFO : EPOCH 2 - PROGRESS: at 35.02% examples, 115086 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:43,931 : INFO : EPOCH 2 - PROGRESS: at 46.47% examples, 118621 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:44,944 : INFO : EPOCH 2 - PROGRESS: at 55.80% examples, 119426 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:46,019 : INFO : EPOCH 2 - PROGRESS: at 67.26% examples, 121632 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:26:47,045 : INFO : EPOCH 2 - PROGRESS: at 80.34% examples, 124711 words/s, in_qsize 16, out_qsize 2\n",
      "2019-11-20 18:26:48,072 : INFO : EPOCH 2 - PROGRESS: at 94.23% examples, 126877 words/s, in_qsize 14, out_qsize 0\n",
      "2019-11-20 18:26:48,319 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:26:48,395 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:26:48,453 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:26:48,497 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:26:48,499 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:26:48,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:26:48,593 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:26:48,602 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:26:48,603 : INFO : EPOCH - 2 : training on 1896341 raw words (1177599 effective words) took 9.2s, 128488 effective words/s\n",
      "2019-11-20 18:26:49,773 : INFO : EPOCH 3 - PROGRESS: at 8.15% examples, 92176 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:50,835 : INFO : EPOCH 3 - PROGRESS: at 22.32% examples, 113617 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:51,885 : INFO : EPOCH 3 - PROGRESS: at 35.23% examples, 121678 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:26:52,934 : INFO : EPOCH 3 - PROGRESS: at 47.35% examples, 126013 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:54,017 : INFO : EPOCH 3 - PROGRESS: at 59.15% examples, 128373 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:55,170 : INFO : EPOCH 3 - PROGRESS: at 70.88% examples, 128620 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:26:56,278 : INFO : EPOCH 3 - PROGRESS: at 83.61% examples, 129448 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:26:57,295 : INFO : EPOCH 3 - PROGRESS: at 95.42% examples, 128303 words/s, in_qsize 11, out_qsize 0\n",
      "2019-11-20 18:26:57,417 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:26:57,527 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:26:57,544 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:26:57,564 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:26:57,612 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:26:57,651 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:26:57,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:26:57,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:26:57,680 : INFO : EPOCH - 3 : training on 1896341 raw words (1177798 effective words) took 9.1s, 129866 effective words/s\n",
      "2019-11-20 18:26:58,878 : INFO : EPOCH 4 - PROGRESS: at 8.15% examples, 89981 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:00,009 : INFO : EPOCH 4 - PROGRESS: at 22.32% examples, 108820 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:27:01,056 : INFO : EPOCH 4 - PROGRESS: at 35.23% examples, 118319 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:02,133 : INFO : EPOCH 4 - PROGRESS: at 47.42% examples, 122599 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:03,143 : INFO : EPOCH 4 - PROGRESS: at 56.93% examples, 122853 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:27:04,288 : INFO : EPOCH 4 - PROGRESS: at 66.68% examples, 120388 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:05,289 : INFO : EPOCH 4 - PROGRESS: at 78.55% examples, 122421 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:06,358 : INFO : EPOCH 4 - PROGRESS: at 88.36% examples, 120116 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:07,207 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:27:07,250 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:27:07,271 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:27:07,287 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:27:07,307 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:27:07,361 : INFO : EPOCH 4 - PROGRESS: at 99.09% examples, 120453 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 18:27:07,362 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:27:07,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:27:07,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:27:07,438 : INFO : EPOCH - 4 : training on 1896341 raw words (1177915 effective words) took 9.8s, 120801 effective words/s\n",
      "2019-11-20 18:27:08,594 : INFO : EPOCH 5 - PROGRESS: at 8.29% examples, 93158 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:09,605 : INFO : EPOCH 5 - PROGRESS: at 22.32% examples, 116975 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:10,721 : INFO : EPOCH 5 - PROGRESS: at 35.23% examples, 121625 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-20 18:27:11,893 : INFO : EPOCH 5 - PROGRESS: at 47.42% examples, 122457 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:12,902 : INFO : EPOCH 5 - PROGRESS: at 56.93% examples, 122783 words/s, in_qsize 15, out_qsize 2\n",
      "2019-11-20 18:27:14,060 : INFO : EPOCH 5 - PROGRESS: at 66.68% examples, 120134 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:15,081 : INFO : EPOCH 5 - PROGRESS: at 79.01% examples, 122658 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:16,112 : INFO : EPOCH 5 - PROGRESS: at 88.36% examples, 120127 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:27:16,902 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:27:17,029 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:27:17,032 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:27:17,041 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:27:17,112 : INFO : EPOCH 5 - PROGRESS: at 98.62% examples, 119865 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 18:27:17,113 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:27:17,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:27:17,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:27:17,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:27:17,212 : INFO : EPOCH - 5 : training on 1896341 raw words (1177584 effective words) took 9.8s, 120563 effective words/s\n",
      "2019-11-20 18:27:17,213 : INFO : training on a 9481705 raw words (5888494 effective words) took 47.3s, 124466 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5888494, 9481705)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model_ocr.build_vocab(flattened_list_sentences, update=True)\n",
    "embedding_model_ocr.train(flattened_list_sentences, \n",
    "                          total_examples=embedding_model_ocr.corpus_count,\n",
    "                          epochs=w2v_args.epochs,  \n",
    "                          compute_loss=w2v_args.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:27:17,221 : INFO : saving Word2Vec object under ./w2v_005_EM_ocr_qual_3_4.model, separately None\n",
      "2019-11-20 18:27:17,222 : INFO : storing np array 'vectors' to ./w2v_005_EM_ocr_qual_3_4.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:27:18,512 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 18:27:18,513 : INFO : storing np array 'syn1neg' to ./w2v_005_EM_ocr_qual_3_4.model.trainables.syn1neg.npy\n",
      "2019-11-20 18:27:19,753 : INFO : not storing attribute cum_table\n",
      "2019-11-20 18:27:20,718 : INFO : saved ./w2v_005_EM_ocr_qual_3_4.model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n[INFO] Save the model\")\n",
    "embedding_model_ocr.save(\"./w2v_005_EM_ocr_qual_3_4.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n"
     ]
    }
   ],
   "source": [
    "list_sentences = db_sentence[\"corrected_sentencizer_cleaned\"].to_list()\n",
    "print('#sentences: {}'.format(len(list_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_list_sentences = [val for sublist in list_sentences for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'church',\n",
       " 'service',\n",
       " 'presbyterian',\n",
       " 'anniversary',\n",
       " 'the',\n",
       " '150th',\n",
       " 'anniversary',\n",
       " 'of',\n",
       " 'the',\n",
       " 'first',\n",
       " 'presbyterian',\n",
       " 'church',\n",
       " 'service',\n",
       " 'in',\n",
       " 'australia',\n",
       " 'will',\n",
       " 'be',\n",
       " 'celebrated',\n",
       " 'to',\n",
       " 'morrow',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_list_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_corrected = copy.deepcopy(embedding_model_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_corrected.workers = 8\n",
    "embedding_model_corrected.vocabulary.min_count = 5\n",
    "embedding_model_corrected.alpha = min_alpha_yet_reached*10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:27:26,978 : INFO : collecting all words and their counts\n",
      "2019-11-20 18:27:26,979 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 18:27:27,023 : INFO : PROGRESS: at sentence #10000, processed 217550 words, keeping 21037 word types\n",
      "2019-11-20 18:27:27,064 : INFO : PROGRESS: at sentence #20000, processed 455085 words, keeping 31368 word types\n",
      "2019-11-20 18:27:27,106 : INFO : PROGRESS: at sentence #30000, processed 695671 words, keeping 40549 word types\n",
      "2019-11-20 18:27:27,147 : INFO : PROGRESS: at sentence #40000, processed 923693 words, keeping 47531 word types\n",
      "2019-11-20 18:27:27,183 : INFO : PROGRESS: at sentence #50000, processed 1136699 words, keeping 53209 word types\n",
      "2019-11-20 18:27:27,220 : INFO : PROGRESS: at sentence #60000, processed 1361413 words, keeping 58750 word types\n",
      "2019-11-20 18:27:27,258 : INFO : PROGRESS: at sentence #70000, processed 1582999 words, keeping 63795 word types\n",
      "2019-11-20 18:27:27,296 : INFO : collected 68578 word types from a corpus of 1807730 raw words and 79187 sentences\n",
      "2019-11-20 18:27:27,297 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 18:27:27,364 : INFO : New added 16933 unique words (19% of original 85511) and increased the count of 16933 pre-existing words (19% of original 85511)\n",
      "2019-11-20 18:27:27,476 : INFO : deleting the raw counts dictionary of 68578 items\n",
      "2019-11-20 18:27:27,477 : INFO : sample=0.001 downsamples 72 most-common words\n",
      "2019-11-20 18:27:27,478 : INFO : downsampling leaves estimated 2333759 word corpus (134.9% of prior 1730412)\n",
      "2019-11-20 18:27:28,648 : INFO : estimated required memory for 33866 words and 300 dimensions: 98211400 bytes\n",
      "2019-11-20 18:27:28,649 : INFO : updating layer weights\n",
      "2019-11-20 18:27:29,804 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 18:27:29,805 : INFO : training model with 8 workers on 435768 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 18:27:31,009 : INFO : EPOCH 1 - PROGRESS: at 9.82% examples, 97479 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:32,122 : INFO : EPOCH 1 - PROGRESS: at 23.02% examples, 119835 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:33,169 : INFO : EPOCH 1 - PROGRESS: at 35.38% examples, 130094 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:34,182 : INFO : EPOCH 1 - PROGRESS: at 48.57% examples, 136133 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:35,287 : INFO : EPOCH 1 - PROGRESS: at 62.60% examples, 138443 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:36,391 : INFO : EPOCH 1 - PROGRESS: at 76.20% examples, 139634 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:37,398 : INFO : EPOCH 1 - PROGRESS: at 89.16% examples, 141495 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:38,452 : INFO : EPOCH 1 - PROGRESS: at 96.97% examples, 135972 words/s, in_qsize 7, out_qsize 1\n",
      "2019-11-20 18:27:38,454 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:27:38,463 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:27:38,478 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:27:38,579 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:27:38,612 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:27:38,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:27:38,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:27:38,740 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:27:38,741 : INFO : EPOCH - 1 : training on 1807730 raw words (1215372 effective words) took 8.9s, 136255 effective words/s\n",
      "2019-11-20 18:27:39,872 : INFO : EPOCH 2 - PROGRESS: at 9.82% examples, 103623 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:41,031 : INFO : EPOCH 2 - PROGRESS: at 23.02% examples, 121197 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:27:42,218 : INFO : EPOCH 2 - PROGRESS: at 35.48% examples, 125890 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 18:27:43,356 : INFO : EPOCH 2 - PROGRESS: at 48.57% examples, 129037 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 18:27:44,372 : INFO : EPOCH 2 - PROGRESS: at 58.62% examples, 126282 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 18:27:45,373 : INFO : EPOCH 2 - PROGRESS: at 71.38% examples, 129569 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:46,386 : INFO : EPOCH 2 - PROGRESS: at 81.38% examples, 128138 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:27:47,388 : INFO : EPOCH 2 - PROGRESS: at 93.40% examples, 130364 words/s, in_qsize 14, out_qsize 0\n",
      "2019-11-20 18:27:47,782 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:27:47,805 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:27:47,807 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:27:47,920 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:27:47,962 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:27:48,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:27:48,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:27:48,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:27:48,073 : INFO : EPOCH - 2 : training on 1807730 raw words (1215251 effective words) took 9.3s, 130415 effective words/s\n",
      "2019-11-20 18:27:49,197 : INFO : EPOCH 3 - PROGRESS: at 9.82% examples, 104215 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:27:50,260 : INFO : EPOCH 3 - PROGRESS: at 23.02% examples, 126772 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:51,398 : INFO : EPOCH 3 - PROGRESS: at 35.38% examples, 131552 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:52,458 : INFO : EPOCH 3 - PROGRESS: at 48.57% examples, 135762 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:27:53,570 : INFO : EPOCH 3 - PROGRESS: at 62.66% examples, 137940 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:54,778 : INFO : EPOCH 3 - PROGRESS: at 76.20% examples, 137030 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 18:27:55,888 : INFO : EPOCH 3 - PROGRESS: at 89.66% examples, 138226 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:27:56,453 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:27:56,480 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:27:56,511 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:27:56,640 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:27:56,704 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:27:56,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:27:56,770 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:27:56,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:27:56,783 : INFO : EPOCH - 3 : training on 1807730 raw words (1215592 effective words) took 8.7s, 139712 effective words/s\n",
      "2019-11-20 18:27:58,007 : INFO : EPOCH 4 - PROGRESS: at 9.82% examples, 95753 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 18:27:59,033 : INFO : EPOCH 4 - PROGRESS: at 20.29% examples, 108519 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:00,090 : INFO : EPOCH 4 - PROGRESS: at 31.29% examples, 116250 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:01,108 : INFO : EPOCH 4 - PROGRESS: at 43.94% examples, 123823 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:28:02,112 : INFO : EPOCH 4 - PROGRESS: at 55.20% examples, 125903 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 18:28:03,158 : INFO : EPOCH 4 - PROGRESS: at 67.25% examples, 127529 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:04,179 : INFO : EPOCH 4 - PROGRESS: at 80.13% examples, 130741 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:05,250 : INFO : EPOCH 4 - PROGRESS: at 93.40% examples, 133189 words/s, in_qsize 14, out_qsize 0\n",
      "2019-11-20 18:28:05,546 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:28:05,572 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:28:05,630 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:28:05,715 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:28:05,747 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:28:05,831 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:28:05,832 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:28:05,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:28:05,836 : INFO : EPOCH - 4 : training on 1807730 raw words (1216159 effective words) took 9.0s, 134484 effective words/s\n",
      "2019-11-20 18:28:06,890 : INFO : EPOCH 5 - PROGRESS: at 9.82% examples, 111998 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:07,932 : INFO : EPOCH 5 - PROGRESS: at 23.02% examples, 132840 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:28:09,044 : INFO : EPOCH 5 - PROGRESS: at 35.48% examples, 136725 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 18:28:10,104 : INFO : EPOCH 5 - PROGRESS: at 48.57% examples, 139777 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:11,200 : INFO : EPOCH 5 - PROGRESS: at 62.60% examples, 141623 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:12,269 : INFO : EPOCH 5 - PROGRESS: at 76.09% examples, 142986 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:13,284 : INFO : EPOCH 5 - PROGRESS: at 89.66% examples, 145171 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 18:28:13,808 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 18:28:13,810 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 18:28:13,865 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 18:28:13,968 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 18:28:14,007 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 18:28:14,061 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 18:28:14,067 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 18:28:14,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 18:28:14,116 : INFO : EPOCH - 5 : training on 1807730 raw words (1215432 effective words) took 8.3s, 147097 effective words/s\n",
      "2019-11-20 18:28:14,116 : INFO : training on a 9038650 raw words (6077806 effective words) took 44.3s, 137165 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6077806, 9038650)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model_corrected.build_vocab(flattened_list_sentences, update=True)\n",
    "embedding_model_corrected.train(flattened_list_sentences, \n",
    "                                total_examples=embedding_model_corrected.corpus_count,\n",
    "                                epochs=w2v_args.epochs,  \n",
    "                                compute_loss=w2v_args.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:28:14,124 : INFO : saving Word2Vec object under ./w2v_005_EM_corr_qual_3_4.model, separately None\n",
      "2019-11-20 18:28:14,125 : INFO : storing np array 'vectors' to ./w2v_005_EM_corr_qual_3_4.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 18:28:15,393 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 18:28:15,393 : INFO : storing np array 'syn1neg' to ./w2v_005_EM_corr_qual_3_4.model.trainables.syn1neg.npy\n",
      "2019-11-20 18:28:16,587 : INFO : not storing attribute cum_table\n",
      "2019-11-20 18:28:17,600 : INFO : saved ./w2v_005_EM_corr_qual_3_4.model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n[INFO] Save the model\")\n",
    "embedding_model_corrected.save(\"./w2v_005_EM_corr_qual_3_4.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality bands 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(myrow, col_name):\n",
    "    all_clean_rows = []\n",
    "    for sent in myrow[col_name]:\n",
    "        one_clean_row = []\n",
    "        for token in sent:\n",
    "            one_clean_row.append(token.lower())\n",
    "        all_clean_rows.append(one_clean_row)\n",
    "    return all_clean_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    13953\n",
       "1    11461\n",
       "Name: quality_band, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_sentence = db_sentence_orig[(db_sentence_orig['quality_band'] == 1) | \n",
    "                               (db_sentence_orig['quality_band'] == 2)]\n",
    "db_sentence['quality_band'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/khosseini/anaconda3/envs/py37torch/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "db_sentence[\"ocr_sentencizer_cleaned\"] = db_sentence.apply(cleanup, args=[\"ocr_sentencizer\"], axis=1)\n",
    "db_sentence[\"corrected_sentencizer_cleaned\"] = db_sentence.apply(cleanup, args=[\"corrected_sentencizer\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25414, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>articleId</th>\n",
       "      <th>articleType</th>\n",
       "      <th>year</th>\n",
       "      <th>ocrText</th>\n",
       "      <th>humanText</th>\n",
       "      <th>corrected</th>\n",
       "      <th>str_similarity</th>\n",
       "      <th>str_length_humanText</th>\n",
       "      <th>str_length_ocrText</th>\n",
       "      <th>...</th>\n",
       "      <th>ocr_dict_lookup</th>\n",
       "      <th>ocr_dict_lookup_list</th>\n",
       "      <th>ocr_dict_perc</th>\n",
       "      <th>corrected_dict_lookup_list</th>\n",
       "      <th>corr_dict_perc</th>\n",
       "      <th>corrected_sentencizer_list</th>\n",
       "      <th>ocr_sentencizer_list</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>ocr_sentencizer_cleaned</th>\n",
       "      <th>corrected_sentencizer_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18378453</td>\n",
       "      <td>Article ILLUSTRATED</td>\n",
       "      <td>1953</td>\n",
       "      <td>FROM RIVER CROSSING TO END OF TRIÄÜ I ^PI A^H\"...</td>\n",
       "      <td>FROM RIVER CROSSING TO END OF TRIAL SPLASH: Pe...</td>\n",
       "      <td>FROM RIVER CROSSING TO END OF TRIAL SPLASH: Pe...</td>\n",
       "      <td>0.847561</td>\n",
       "      <td>746</td>\n",
       "      <td>820</td>\n",
       "      <td>...</td>\n",
       "      <td>[[4, 5, 8, 2, 3, 2, -5, 1, 1, 2, -3, 1, -5, -6...</td>\n",
       "      <td>[4, 5, 8, 2, 3, 2, -5, 1, 1, 2, -3, 1, -5, -6,...</td>\n",
       "      <td>79.439252</td>\n",
       "      <td>[4, 5, 8, 2, 3, 2, 5, 6, 1, -5, -6, 8, 4, 4, 5...</td>\n",
       "      <td>92.079208</td>\n",
       "      <td>[FROM, RIVER, CROSSING, TO, END, OF, TRIAL, SP...</td>\n",
       "      <td>[FROM, RIVER, CROSSING, TO, END, OF, TRIÄÜ, I,...</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>[[from, river, crossing, to, end, of, triäü, i...</td>\n",
       "      <td>[[from, river, crossing, to, end, of, trial, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18363627</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>Natural Childbirth Sir,-We nurses have seen fa...</td>\n",
       "      <td>Natural Childbirth Sir,-We nurses have seen fa...</td>\n",
       "      <td>Natural Childbirth Sir,-We nurses have seen fa...</td>\n",
       "      <td>0.964119</td>\n",
       "      <td>641</td>\n",
       "      <td>630</td>\n",
       "      <td>...</td>\n",
       "      <td>[[7, 10, -7, 6, 4, 4, 3, 3, 4, 5, 6, 4, 6, 5, ...</td>\n",
       "      <td>[7, 10, -7, 6, 4, 4, 3, 3, 4, 5, 6, 4, 6, 5, 2...</td>\n",
       "      <td>96.590909</td>\n",
       "      <td>[7, 10, -7, 6, 4, 4, 3, 3, 4, 5, 6, 4, 6, 5, 2...</td>\n",
       "      <td>98.876404</td>\n",
       "      <td>[Natural, Childbirth, Sir,-We, nurses, have, s...</td>\n",
       "      <td>[Natural, Childbirth, Sir,-We, nurses, have, s...</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>[[natural, childbirth, sir,-we, nurses, have, ...</td>\n",
       "      <td>[[natural, childbirth, sir,-we, nurses, have, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18368961</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>DIVORCE Before The Judge In Divorce, Mr Justic...</td>\n",
       "      <td>DIVORCE Before The Judge In Divorce, Mr. Justi...</td>\n",
       "      <td>DIVORCE Before The Judge In Divorce, Mr. Justi...</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>1219</td>\n",
       "      <td>1121</td>\n",
       "      <td>...</td>\n",
       "      <td>[[7, 6, 3, 5, 2, 7, 1, 2, 7, -5, 7, 4, 1, 1, -...</td>\n",
       "      <td>[7, 6, 3, 5, 2, 7, 1, 2, 7, -5, 7, 4, 1, 1, -6...</td>\n",
       "      <td>82.882883</td>\n",
       "      <td>[7, 6, 3, 5, 2, 7, 1, 2, 1, 7, -5, 7, 4, 1, 1,...</td>\n",
       "      <td>86.486486</td>\n",
       "      <td>[DIVORCE, Before, The, Judge, In, Divorce, ,, ...</td>\n",
       "      <td>[DIVORCE, Before, The, Judge, In, Divorce, ,, ...</td>\n",
       "      <td>0.147513</td>\n",
       "      <td>[[divorce, before, the, judge, in, divorce, ,,...</td>\n",
       "      <td>[[divorce, before, the, judge, in, divorce, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18355541</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>BRITISH AIRLINER I MISSING ¡HALIFAX, Feb. 2 M....</td>\n",
       "      <td>BRITISH AIRLINER MISSING HALIFAX, Feb. 2 (A.A....</td>\n",
       "      <td>BRITISH AIRLINER MISSING HALIFAX, Feb. 2 (A.A....</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>1274</td>\n",
       "      <td>1139</td>\n",
       "      <td>...</td>\n",
       "      <td>[[7, 8, 1, 7, 1, 7, 1, 3, 1, 1, 4, 1, -3, 7, 3...</td>\n",
       "      <td>[7, 8, 1, 7, 1, 7, 1, 3, 1, 1, 4, 1, -3, 7, 3,...</td>\n",
       "      <td>88.194444</td>\n",
       "      <td>[7, 8, 7, 7, 1, 3, 1, 1, 1, -6, 1, -3, 7, 3, 1...</td>\n",
       "      <td>95.731707</td>\n",
       "      <td>[BRITISH, AIRLINER, MISSING, HALIFAX, ,, Feb, ...</td>\n",
       "      <td>[BRITISH, AIRLINER, I, MISSING, ¡, HALIFAX, ,,...</td>\n",
       "      <td>0.240449</td>\n",
       "      <td>[[british, airliner, i, missing, ¡, halifax, ,...</td>\n",
       "      <td>[[british, airliner, missing, halifax, ,, feb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18381450</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>I SCHOOL CHESS * Homebush Increased Ils lead o...</td>\n",
       "      <td>SCHOOL CHESS  Homebush increased its lead over...</td>\n",
       "      <td>SCHOOL CHESS  Homebush increased its lead over...</td>\n",
       "      <td>0.918264</td>\n",
       "      <td>991</td>\n",
       "      <td>955</td>\n",
       "      <td>...</td>\n",
       "      <td>[[1, 6, 5, 1, 8, 9, 3, 4, 4, 8, 2, 3, 5, 5, 2,...</td>\n",
       "      <td>[1, 6, 5, 1, 8, 9, 3, 4, 4, 8, 2, 3, 5, 5, 2, ...</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>[6, 5, 8, 9, 3, 4, 4, 8, 2, 3, 5, 5, 2, 3, 1, ...</td>\n",
       "      <td>96.598639</td>\n",
       "      <td>[SCHOOL, CHESS, Homebush, increased, its, lead...</td>\n",
       "      <td>[I, SCHOOL, CHESS, *, Homebush, Increased, Ils...</td>\n",
       "      <td>0.277612</td>\n",
       "      <td>[[i, school, chess, *, homebush, increased, il...</td>\n",
       "      <td>[[school, chess, homebush, increased, its, lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath articleId  \\\n",
       "1  ./trove_overproof/datasets/dataset1/rawTextAnd...  18378453   \n",
       "2  ./trove_overproof/datasets/dataset1/rawTextAnd...  18363627   \n",
       "5  ./trove_overproof/datasets/dataset1/rawTextAnd...  18368961   \n",
       "6  ./trove_overproof/datasets/dataset1/rawTextAnd...  18355541   \n",
       "7  ./trove_overproof/datasets/dataset1/rawTextAnd...  18381450   \n",
       "\n",
       "            articleType  year  \\\n",
       "1  Article ILLUSTRATED   1953   \n",
       "2               Article  1953   \n",
       "5               Article  1953   \n",
       "6               Article  1953   \n",
       "7               Article  1953   \n",
       "\n",
       "                                             ocrText  \\\n",
       "1  FROM RIVER CROSSING TO END OF TRIÄÜ I ^PI A^H\"...   \n",
       "2  Natural Childbirth Sir,-We nurses have seen fa...   \n",
       "5  DIVORCE Before The Judge In Divorce, Mr Justic...   \n",
       "6  BRITISH AIRLINER I MISSING ¡HALIFAX, Feb. 2 M....   \n",
       "7  I SCHOOL CHESS * Homebush Increased Ils lead o...   \n",
       "\n",
       "                                           humanText  \\\n",
       "1  FROM RIVER CROSSING TO END OF TRIAL SPLASH: Pe...   \n",
       "2  Natural Childbirth Sir,-We nurses have seen fa...   \n",
       "5  DIVORCE Before The Judge In Divorce, Mr. Justi...   \n",
       "6  BRITISH AIRLINER MISSING HALIFAX, Feb. 2 (A.A....   \n",
       "7  SCHOOL CHESS  Homebush increased its lead over...   \n",
       "\n",
       "                                           corrected  str_similarity  \\\n",
       "1  FROM RIVER CROSSING TO END OF TRIAL SPLASH: Pe...        0.847561   \n",
       "2  Natural Childbirth Sir,-We nurses have seen fa...        0.964119   \n",
       "5  DIVORCE Before The Judge In Divorce, Mr. Justi...        0.894176   \n",
       "6  BRITISH AIRLINER MISSING HALIFAX, Feb. 2 (A.A....        0.829670   \n",
       "7  SCHOOL CHESS  Homebush increased its lead over...        0.918264   \n",
       "\n",
       "   str_length_humanText  str_length_ocrText  ...  \\\n",
       "1                   746                 820  ...   \n",
       "2                   641                 630  ...   \n",
       "5                  1219                1121  ...   \n",
       "6                  1274                1139  ...   \n",
       "7                   991                 955  ...   \n",
       "\n",
       "                                     ocr_dict_lookup  \\\n",
       "1  [[4, 5, 8, 2, 3, 2, -5, 1, 1, 2, -3, 1, -5, -6...   \n",
       "2  [[7, 10, -7, 6, 4, 4, 3, 3, 4, 5, 6, 4, 6, 5, ...   \n",
       "5  [[7, 6, 3, 5, 2, 7, 1, 2, 7, -5, 7, 4, 1, 1, -...   \n",
       "6  [[7, 8, 1, 7, 1, 7, 1, 3, 1, 1, 4, 1, -3, 7, 3...   \n",
       "7  [[1, 6, 5, 1, 8, 9, 3, 4, 4, 8, 2, 3, 5, 5, 2,...   \n",
       "\n",
       "                                ocr_dict_lookup_list ocr_dict_perc  \\\n",
       "1  [4, 5, 8, 2, 3, 2, -5, 1, 1, 2, -3, 1, -5, -6,...     79.439252   \n",
       "2  [7, 10, -7, 6, 4, 4, 3, 3, 4, 5, 6, 4, 6, 5, 2...     96.590909   \n",
       "5  [7, 6, 3, 5, 2, 7, 1, 2, 7, -5, 7, 4, 1, 1, -6...     82.882883   \n",
       "6  [7, 8, 1, 7, 1, 7, 1, 3, 1, 1, 4, 1, -3, 7, 3,...     88.194444   \n",
       "7  [1, 6, 5, 1, 8, 9, 3, 4, 4, 8, 2, 3, 5, 5, 2, ...     92.307692   \n",
       "\n",
       "                          corrected_dict_lookup_list corr_dict_perc  \\\n",
       "1  [4, 5, 8, 2, 3, 2, 5, 6, 1, -5, -6, 8, 4, 4, 5...      92.079208   \n",
       "2  [7, 10, -7, 6, 4, 4, 3, 3, 4, 5, 6, 4, 6, 5, 2...      98.876404   \n",
       "5  [7, 6, 3, 5, 2, 7, 1, 2, 1, 7, -5, 7, 4, 1, 1,...      86.486486   \n",
       "6  [7, 8, 7, 7, 1, 3, 1, 1, 1, -6, 1, -3, 7, 3, 1...      95.731707   \n",
       "7  [6, 5, 8, 9, 3, 4, 4, 8, 2, 3, 5, 5, 2, 3, 1, ...      96.598639   \n",
       "\n",
       "                          corrected_sentencizer_list  \\\n",
       "1  [FROM, RIVER, CROSSING, TO, END, OF, TRIAL, SP...   \n",
       "2  [Natural, Childbirth, Sir,-We, nurses, have, s...   \n",
       "5  [DIVORCE, Before, The, Judge, In, Divorce, ,, ...   \n",
       "6  [BRITISH, AIRLINER, MISSING, HALIFAX, ,, Feb, ...   \n",
       "7  [SCHOOL, CHESS, Homebush, increased, its, lead...   \n",
       "\n",
       "                                ocr_sentencizer_list  jaccard_similarity  \\\n",
       "1  [FROM, RIVER, CROSSING, TO, END, OF, TRIÄÜ, I,...            0.305882   \n",
       "2  [Natural, Childbirth, Sir,-We, nurses, have, s...            0.523810   \n",
       "5  [DIVORCE, Before, The, Judge, In, Divorce, ,, ...            0.147513   \n",
       "6  [BRITISH, AIRLINER, I, MISSING, ¡, HALIFAX, ,,...            0.240449   \n",
       "7  [I, SCHOOL, CHESS, *, Homebush, Increased, Ils...            0.277612   \n",
       "\n",
       "                             ocr_sentencizer_cleaned  \\\n",
       "1  [[from, river, crossing, to, end, of, triäü, i...   \n",
       "2  [[natural, childbirth, sir,-we, nurses, have, ...   \n",
       "5  [[divorce, before, the, judge, in, divorce, ,,...   \n",
       "6  [[british, airliner, i, missing, ¡, halifax, ,...   \n",
       "7  [[i, school, chess, *, homebush, increased, il...   \n",
       "\n",
       "                       corrected_sentencizer_cleaned  \n",
       "1  [[from, river, crossing, to, end, of, trial, s...  \n",
       "2  [[natural, childbirth, sir,-we, nurses, have, ...  \n",
       "5  [[divorce, before, the, judge, in, divorce, ,,...  \n",
       "6  [[british, airliner, missing, halifax, ,, feb,...  \n",
       "7  [[school, chess, homebush, increased, its, lea...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(db_sentence.shape)\n",
    "db_sentence.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update a pre-trained LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args for Word2Vec\n",
    "w2v_args = Namespace(\n",
    "    epochs=5, \n",
    "    # only for Word2Vec\n",
    "    compute_loss=True,                               # If True, computes and stores loss value which can be retrieved using get_latest_training_loss().\n",
    "\n",
    "#     size=100,                                        # Dimensionality of the word vectors.\n",
    "#     alpha=0.03,                                      # The initial learning rate.\n",
    "#     min_alpha=0.0007,                                # Learning rate will linearly drop to min_alpha as training progresses.\n",
    "#     sg=1,                                            # Training algorithm: skip-gram if sg=1, otherwise CBOW.\n",
    "#     hs=0,                                            # If 1, hierarchical softmax will be used for model training. If set to 0, and negative is non-zero, negative sampling will be used.\n",
    "#     negative=20,                                     # If > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). If set to 0, no negative sampling is used. \n",
    "#     min_count=5,                                    # The model ignores all words with total frequency lower than this.\n",
    "#     window=5,                                        # The maximum distance between the current and predicted word within a sentence.\n",
    "#     sample=1e-3,                                     # The threshold for configuring which higher-frequency words are randomly downsampled, useful range is (0, 1e-5).\n",
    "#     workers=8, \n",
    "#     cbow_mean=1,                                     # If 0, use the sum of the context word vectors. If 1, use the mean, only applies when cbow is used.\n",
    "#     null_word=0,                                     # \n",
    "#     trim_rule=None,                                  # \n",
    "#     sorted_vocab=1,                                  # If 1, sort the vocabulary by descending frequency before assigning word indices.\n",
    "#     batch_words=10000,                               # Target size (in words) for batches of examples passed to worker threads (and thus cython routines).(Larger batches will be passed if individual texts are longer than 10000 words, but the standard cython code truncates to that maximum.)\n",
    "    \n",
    "#     seed=1364,                                       # Seed for the random number generator.\n",
    "#     # only for FastText (compare to word2vec)\n",
    "#     #word_ngrams=1,                                   # If 1, uses enriches word vectors with subword(n-grams) information. If 0, this is equivalent to Word2Vec. \n",
    "#     #min_n=2,                                         # Minimum length of char n-grams to be used for training word representations.\n",
    "#     #max_n=15,                                        # Max length of char ngrams to be used for training word representations. Set max_n to be lesser than min_n to avoid char ngrams being used.\n",
    "#     #bucket=2000000                                  # Character ngrams are hashed into a fixed number of buckets, in order to limit the memory usage of the model. This option specifies the number of buckets used by the model.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess before creating/updating LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def preprocess4LM(myrow, col_name=\"ocrText_cleaned_tokenize\"):\n",
    "    txt = [token.lemma_ for token in nlp(myrow[col_name].lower())]\n",
    "    return txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "db_sentence[\"ocrText_cleaned_tokenize\"] = db_sentence[0:10].apply(preprocess4LM, args=[\"ocrText_cleaned\"], axis=1)\n",
    "db_sentence[\"corrected_cleaned_tokenize\"] = db_sentence[0:10].apply(preprocess4LM, args=[\"corrected_cleaned\"], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:16:35,247 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:16:35,248 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:16:35,342 : INFO : PROGRESS: at sentence #10000, processed 390636 words, keeping 56739 word types\n",
      "2019-11-20 21:16:35,427 : INFO : PROGRESS: at sentence #20000, processed 819811 words, keeping 97237 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "40 51229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:16:35,509 : INFO : PROGRESS: at sentence #30000, processed 1211406 words, keeping 128411 word types\n",
      "2019-11-20 21:16:35,598 : INFO : PROGRESS: at sentence #40000, processed 1593420 words, keeping 156189 word types\n",
      "2019-11-20 21:16:35,695 : INFO : PROGRESS: at sentence #50000, processed 1991585 words, keeping 181801 word types\n",
      "2019-11-20 21:16:35,707 : INFO : collected 185097 word types from a corpus of 2042938 raw words and 51229 sentences\n",
      "2019-11-20 21:16:35,707 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:16:35,834 : INFO : New added 21544 unique words (10% of original 206641) and increased the count of 21544 pre-existing words (10% of original 206641)\n",
      "2019-11-20 21:16:35,978 : INFO : deleting the raw counts dictionary of 185097 items\n",
      "2019-11-20 21:16:35,982 : INFO : sample=0.001 downsamples 84 most-common words\n",
      "2019-11-20 21:16:35,983 : INFO : downsampling leaves estimated 2619874 word corpus (143.8% of prior 1822450)\n",
      "2019-11-20 21:16:37,137 : INFO : estimated required memory for 43088 words and 300 dimensions: 124955200 bytes\n",
      "2019-11-20 21:16:37,138 : INFO : updating layer weights\n",
      "2019-11-20 21:16:38,279 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:16:38,280 : INFO : training model with 8 workers on 437059 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:16:39,453 : INFO : EPOCH 1 - PROGRESS: at 8.87% examples, 96756 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:16:40,614 : INFO : EPOCH 1 - PROGRESS: at 20.13% examples, 117905 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:41,741 : INFO : EPOCH 1 - PROGRESS: at 31.09% examples, 125891 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:16:42,843 : INFO : EPOCH 1 - PROGRESS: at 41.87% examples, 130648 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:43,938 : INFO : EPOCH 1 - PROGRESS: at 54.21% examples, 133511 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:45,043 : INFO : EPOCH 1 - PROGRESS: at 65.85% examples, 135212 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:46,170 : INFO : EPOCH 1 - PROGRESS: at 78.06% examples, 136187 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:47,256 : INFO : EPOCH 1 - PROGRESS: at 89.63% examples, 137529 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:47,869 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:16:47,978 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:16:47,990 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:16:48,052 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:16:48,070 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:16:48,114 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:16:48,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:16:48,216 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:16:48,217 : INFO : EPOCH - 1 : training on 2042938 raw words (1375452 effective words) took 9.9s, 138537 effective words/s\n",
      "2019-11-20 21:16:49,345 : INFO : EPOCH 2 - PROGRESS: at 8.87% examples, 100734 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:50,463 : INFO : EPOCH 2 - PROGRESS: at 20.13% examples, 122552 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:16:51,554 : INFO : EPOCH 2 - PROGRESS: at 31.09% examples, 130674 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:52,659 : INFO : EPOCH 2 - PROGRESS: at 41.87% examples, 134246 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:53,724 : INFO : EPOCH 2 - PROGRESS: at 54.21% examples, 137203 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:54,797 : INFO : EPOCH 2 - PROGRESS: at 65.85% examples, 139022 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:55,908 : INFO : EPOCH 2 - PROGRESS: at 78.06% examples, 139740 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:16:56,917 : INFO : EPOCH 2 - PROGRESS: at 88.84% examples, 140431 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:16:57,729 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:16:57,826 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:16:57,831 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:16:57,922 : INFO : EPOCH 2 - PROGRESS: at 98.17% examples, 139153 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-20 21:16:57,923 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:16:57,943 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:16:57,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:16:57,985 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:16:58,057 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:16:58,058 : INFO : EPOCH - 2 : training on 2042938 raw words (1375898 effective words) took 9.8s, 139941 effective words/s\n",
      "2019-11-20 21:16:59,218 : INFO : EPOCH 3 - PROGRESS: at 8.75% examples, 98048 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:17:00,357 : INFO : EPOCH 3 - PROGRESS: at 20.13% examples, 119744 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:01,467 : INFO : EPOCH 3 - PROGRESS: at 31.09% examples, 127943 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:02,669 : INFO : EPOCH 3 - PROGRESS: at 41.87% examples, 129416 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:03,717 : INFO : EPOCH 3 - PROGRESS: at 53.54% examples, 132444 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:04,772 : INFO : EPOCH 3 - PROGRESS: at 61.99% examples, 128351 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:05,781 : INFO : EPOCH 3 - PROGRESS: at 71.75% examples, 128017 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:17:06,879 : INFO : EPOCH 3 - PROGRESS: at 81.41% examples, 127218 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:07,884 : INFO : EPOCH 3 - PROGRESS: at 91.12% examples, 127747 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:08,471 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:17:08,538 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:17:08,544 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:17:08,598 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:17:08,628 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:17:08,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:17:08,660 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:17:08,709 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:17:08,709 : INFO : EPOCH - 3 : training on 2042938 raw words (1376528 effective words) took 10.6s, 129337 effective words/s\n",
      "2019-11-20 21:17:09,815 : INFO : EPOCH 4 - PROGRESS: at 8.87% examples, 102662 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:10,986 : INFO : EPOCH 4 - PROGRESS: at 20.13% examples, 120896 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:12,085 : INFO : EPOCH 4 - PROGRESS: at 31.09% examples, 129167 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:13,216 : INFO : EPOCH 4 - PROGRESS: at 41.87% examples, 132346 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:14,262 : INFO : EPOCH 4 - PROGRESS: at 53.54% examples, 134922 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:15,313 : INFO : EPOCH 4 - PROGRESS: at 63.50% examples, 133546 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:17:16,347 : INFO : EPOCH 4 - PROGRESS: at 74.49% examples, 134672 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:17,467 : INFO : EPOCH 4 - PROGRESS: at 85.95% examples, 134991 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:18,447 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:17:18,567 : INFO : EPOCH 4 - PROGRESS: at 97.05% examples, 135674 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-20 21:17:18,568 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:17:18,580 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:17:18,650 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:17:18,656 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:17:18,716 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:17:18,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:17:18,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:17:18,771 : INFO : EPOCH - 4 : training on 2042938 raw words (1376214 effective words) took 10.1s, 136901 effective words/s\n",
      "2019-11-20 21:17:19,866 : INFO : EPOCH 5 - PROGRESS: at 8.87% examples, 103704 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:21,002 : INFO : EPOCH 5 - PROGRESS: at 20.13% examples, 123304 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:22,130 : INFO : EPOCH 5 - PROGRESS: at 31.09% examples, 129795 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:23,268 : INFO : EPOCH 5 - PROGRESS: at 41.87% examples, 132636 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:24,377 : INFO : EPOCH 5 - PROGRESS: at 54.21% examples, 134759 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:25,514 : INFO : EPOCH 5 - PROGRESS: at 65.85% examples, 135600 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:26,673 : INFO : EPOCH 5 - PROGRESS: at 78.06% examples, 135971 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:27,792 : INFO : EPOCH 5 - PROGRESS: at 89.63% examples, 136849 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:28,417 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:17:28,543 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:17:28,546 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:17:28,620 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:17:28,637 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:17:28,649 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:17:28,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:17:28,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:17:28,773 : INFO : EPOCH - 5 : training on 2042938 raw words (1375759 effective words) took 10.0s, 137661 effective words/s\n",
      "2019-11-20 21:17:28,774 : INFO : training on a 10214690 raw words (6879851 effective words) took 50.5s, 136255 effective words/s\n",
      "2019-11-20 21:17:28,774 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00040.model, separately None\n",
      "2019-11-20 21:17:28,775 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00040.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:17:29,976 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:17:29,977 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00040.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:17:31,144 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:17:32,159 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00040.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 67.17850494384766\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:17:37,966 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:17:37,967 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:17:38,051 : INFO : PROGRESS: at sentence #10000, processed 395727 words, keeping 56514 word types\n",
      "2019-11-20 21:17:38,125 : INFO : PROGRESS: at sentence #20000, processed 806880 words, keeping 95075 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "41 51245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:17:38,201 : INFO : PROGRESS: at sentence #30000, processed 1217196 words, keeping 129195 word types\n",
      "2019-11-20 21:17:38,284 : INFO : PROGRESS: at sentence #40000, processed 1623381 words, keeping 158277 word types\n",
      "2019-11-20 21:17:38,373 : INFO : PROGRESS: at sentence #50000, processed 2044458 words, keeping 186472 word types\n",
      "2019-11-20 21:17:38,383 : INFO : collected 189172 word types from a corpus of 2090423 raw words and 51245 sentences\n",
      "2019-11-20 21:17:38,384 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:17:38,528 : INFO : New added 21978 unique words (10% of original 211150) and increased the count of 21978 pre-existing words (10% of original 211150)\n",
      "2019-11-20 21:17:38,668 : INFO : deleting the raw counts dictionary of 189172 items\n",
      "2019-11-20 21:17:38,673 : INFO : sample=0.001 downsamples 82 most-common words\n",
      "2019-11-20 21:17:38,674 : INFO : downsampling leaves estimated 2681117 word corpus (143.7% of prior 1866132)\n",
      "2019-11-20 21:17:39,840 : INFO : estimated required memory for 43956 words and 300 dimensions: 127472400 bytes\n",
      "2019-11-20 21:17:39,840 : INFO : updating layer weights\n",
      "2019-11-20 21:17:40,976 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:17:40,977 : INFO : training model with 8 workers on 437042 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:17:42,096 : INFO : EPOCH 1 - PROGRESS: at 8.52% examples, 102307 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:43,182 : INFO : EPOCH 1 - PROGRESS: at 19.97% examples, 124845 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:44,214 : INFO : EPOCH 1 - PROGRESS: at 31.36% examples, 134389 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:45,286 : INFO : EPOCH 1 - PROGRESS: at 42.55% examples, 138097 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:46,357 : INFO : EPOCH 1 - PROGRESS: at 53.71% examples, 140529 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:47,441 : INFO : EPOCH 1 - PROGRESS: at 65.20% examples, 141564 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:48,445 : INFO : EPOCH 1 - PROGRESS: at 75.24% examples, 141274 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:49,466 : INFO : EPOCH 1 - PROGRESS: at 84.33% examples, 139254 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:50,472 : INFO : EPOCH 1 - PROGRESS: at 92.16% examples, 137193 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:50,891 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:17:50,905 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:17:50,915 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:17:50,932 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:17:50,935 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:17:51,060 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:17:51,094 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:17:51,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:17:51,126 : INFO : EPOCH - 1 : training on 2090423 raw words (1406577 effective words) took 10.1s, 138765 effective words/s\n",
      "2019-11-20 21:17:52,302 : INFO : EPOCH 2 - PROGRESS: at 8.52% examples, 96828 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:53,461 : INFO : EPOCH 2 - PROGRESS: at 19.97% examples, 117570 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:54,572 : INFO : EPOCH 2 - PROGRESS: at 31.36% examples, 126056 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:55,791 : INFO : EPOCH 2 - PROGRESS: at 42.55% examples, 127390 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:56,967 : INFO : EPOCH 2 - PROGRESS: at 53.71% examples, 129304 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:17:58,015 : INFO : EPOCH 2 - PROGRESS: at 64.77% examples, 131720 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:17:59,061 : INFO : EPOCH 2 - PROGRESS: at 73.47% examples, 129569 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:18:00,132 : INFO : EPOCH 2 - PROGRESS: at 84.33% examples, 131211 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:01,299 : INFO : EPOCH 2 - PROGRESS: at 95.20% examples, 131928 words/s, in_qsize 10, out_qsize 0\n",
      "2019-11-20 21:18:01,425 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:18:01,448 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:18:01,468 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:18:01,489 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:18:01,515 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:18:01,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:18:01,673 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:18:01,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:18:01,700 : INFO : EPOCH - 2 : training on 2090423 raw words (1406622 effective words) took 10.6s, 133128 effective words/s\n",
      "2019-11-20 21:18:02,841 : INFO : EPOCH 3 - PROGRESS: at 8.79% examples, 99851 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:03,994 : INFO : EPOCH 3 - PROGRESS: at 20.15% examples, 119831 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:05,094 : INFO : EPOCH 3 - PROGRESS: at 31.36% examples, 128137 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:18:06,262 : INFO : EPOCH 3 - PROGRESS: at 42.55% examples, 130298 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:07,433 : INFO : EPOCH 3 - PROGRESS: at 53.71% examples, 131735 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:08,443 : INFO : EPOCH 3 - PROGRESS: at 64.30% examples, 133579 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:09,493 : INFO : EPOCH 3 - PROGRESS: at 73.03% examples, 131046 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:10,507 : INFO : EPOCH 3 - PROGRESS: at 82.73% examples, 131919 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:18:11,610 : INFO : EPOCH 3 - PROGRESS: at 91.34% examples, 130027 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:18:12,063 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:18:12,110 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:18:12,124 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:18:12,213 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:18:12,257 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:18:12,313 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:18:12,365 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:18:12,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:18:12,388 : INFO : EPOCH - 3 : training on 2090423 raw words (1406733 effective words) took 10.7s, 131722 effective words/s\n",
      "2019-11-20 21:18:13,644 : INFO : EPOCH 4 - PROGRESS: at 8.79% examples, 90609 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:14,849 : INFO : EPOCH 4 - PROGRESS: at 20.15% examples, 111683 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:15,915 : INFO : EPOCH 4 - PROGRESS: at 31.36% examples, 123241 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:17,004 : INFO : EPOCH 4 - PROGRESS: at 41.97% examples, 127306 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:18,048 : INFO : EPOCH 4 - PROGRESS: at 52.33% examples, 129803 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:19,084 : INFO : EPOCH 4 - PROGRESS: at 61.90% examples, 129575 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:20,137 : INFO : EPOCH 4 - PROGRESS: at 72.55% examples, 130895 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:21,254 : INFO : EPOCH 4 - PROGRESS: at 83.81% examples, 132480 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:22,255 : INFO : EPOCH 4 - PROGRESS: at 94.10% examples, 134630 words/s, in_qsize 12, out_qsize 0\n",
      "2019-11-20 21:18:22,616 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:18:22,627 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:18:22,641 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:18:22,650 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:18:22,745 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:18:22,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:18:22,851 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:18:22,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:18:22,881 : INFO : EPOCH - 4 : training on 2090423 raw words (1406336 effective words) took 10.5s, 134147 effective words/s\n",
      "2019-11-20 21:18:23,995 : INFO : EPOCH 5 - PROGRESS: at 8.79% examples, 102089 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:25,131 : INFO : EPOCH 5 - PROGRESS: at 19.97% examples, 121999 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:18:26,204 : INFO : EPOCH 5 - PROGRESS: at 31.36% examples, 130690 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:18:27,343 : INFO : EPOCH 5 - PROGRESS: at 42.55% examples, 133135 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:18:28,352 : INFO : EPOCH 5 - PROGRESS: at 53.34% examples, 136775 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:29,393 : INFO : EPOCH 5 - PROGRESS: at 62.32% examples, 134259 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:30,432 : INFO : EPOCH 5 - PROGRESS: at 73.03% examples, 135245 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:31,601 : INFO : EPOCH 5 - PROGRESS: at 84.33% examples, 135473 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:32,760 : INFO : EPOCH 5 - PROGRESS: at 95.20% examples, 135820 words/s, in_qsize 10, out_qsize 0\n",
      "2019-11-20 21:18:32,883 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:18:32,889 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:18:32,899 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:18:32,904 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:18:32,910 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:18:33,093 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:18:33,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:18:33,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:18:33,109 : INFO : EPOCH - 5 : training on 2090423 raw words (1406329 effective words) took 10.2s, 137605 effective words/s\n",
      "2019-11-20 21:18:33,110 : INFO : training on a 10452115 raw words (7032597 effective words) took 52.1s, 134901 effective words/s\n",
      "2019-11-20 21:18:33,110 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00041.model, separately None\n",
      "2019-11-20 21:18:33,111 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00041.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:18:34,292 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:18:34,293 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00041.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:18:35,503 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:18:36,409 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00041.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 64.25094389915466\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:18:42,421 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:18:42,422 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:18:42,498 : INFO : PROGRESS: at sentence #10000, processed 437220 words, keeping 62332 word types\n",
      "2019-11-20 21:18:42,570 : INFO : PROGRESS: at sentence #20000, processed 848050 words, keeping 99657 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "42 50180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:18:42,640 : INFO : PROGRESS: at sentence #30000, processed 1251735 words, keeping 131869 word types\n",
      "2019-11-20 21:18:42,721 : INFO : PROGRESS: at sentence #40000, processed 1661703 words, keeping 160817 word types\n",
      "2019-11-20 21:18:42,809 : INFO : PROGRESS: at sentence #50000, processed 2089053 words, keeping 188752 word types\n",
      "2019-11-20 21:18:42,811 : INFO : collected 189620 word types from a corpus of 2099031 raw words and 50180 sentences\n",
      "2019-11-20 21:18:42,812 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:18:42,943 : INFO : New added 22043 unique words (10% of original 211663) and increased the count of 22043 pre-existing words (10% of original 211663)\n",
      "2019-11-20 21:18:43,109 : INFO : deleting the raw counts dictionary of 189620 items\n",
      "2019-11-20 21:18:43,114 : INFO : sample=0.001 downsamples 86 most-common words\n",
      "2019-11-20 21:18:43,115 : INFO : downsampling leaves estimated 2704463 word corpus (144.3% of prior 1873932)\n",
      "2019-11-20 21:18:44,336 : INFO : estimated required memory for 44086 words and 300 dimensions: 127849400 bytes\n",
      "2019-11-20 21:18:44,337 : INFO : updating layer weights\n",
      "2019-11-20 21:18:45,454 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:18:45,455 : INFO : training model with 8 workers on 437025 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:18:46,554 : INFO : EPOCH 1 - PROGRESS: at 7.48% examples, 104059 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:47,677 : INFO : EPOCH 1 - PROGRESS: at 18.46% examples, 123610 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:48,773 : INFO : EPOCH 1 - PROGRESS: at 29.75% examples, 130924 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:49,874 : INFO : EPOCH 1 - PROGRESS: at 41.77% examples, 134735 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:18:50,960 : INFO : EPOCH 1 - PROGRESS: at 53.20% examples, 137328 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:52,052 : INFO : EPOCH 1 - PROGRESS: at 64.38% examples, 138889 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:53,135 : INFO : EPOCH 1 - PROGRESS: at 76.38% examples, 140252 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:54,233 : INFO : EPOCH 1 - PROGRESS: at 87.53% examples, 141075 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:18:55,174 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:18:55,183 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:18:55,197 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:18:55,207 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:18:55,342 : INFO : EPOCH 1 - PROGRESS: at 98.66% examples, 141550 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:18:55,343 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:18:55,373 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:18:55,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:18:55,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:18:55,467 : INFO : EPOCH - 1 : training on 2099031 raw words (1418451 effective words) took 10.0s, 141783 effective words/s\n",
      "2019-11-20 21:18:56,635 : INFO : EPOCH 2 - PROGRESS: at 7.48% examples, 97831 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:57,788 : INFO : EPOCH 2 - PROGRESS: at 18.46% examples, 118403 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:18:58,939 : INFO : EPOCH 2 - PROGRESS: at 29.75% examples, 125119 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:19:00,090 : INFO : EPOCH 2 - PROGRESS: at 41.77% examples, 128816 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:01,278 : INFO : EPOCH 2 - PROGRESS: at 53.20% examples, 130097 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:02,446 : INFO : EPOCH 2 - PROGRESS: at 64.38% examples, 131270 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:19:03,572 : INFO : EPOCH 2 - PROGRESS: at 76.38% examples, 132884 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:04,635 : INFO : EPOCH 2 - PROGRESS: at 87.07% examples, 134309 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:05,674 : INFO : EPOCH 2 - PROGRESS: at 96.76% examples, 134429 words/s, in_qsize 8, out_qsize 0\n",
      "2019-11-20 21:19:05,696 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:19:05,713 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:19:05,723 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:19:05,752 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:19:05,820 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:19:05,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:19:05,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:19:05,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:19:05,954 : INFO : EPOCH - 2 : training on 2099031 raw words (1418356 effective words) took 10.5s, 135351 effective words/s\n",
      "2019-11-20 21:19:07,039 : INFO : EPOCH 3 - PROGRESS: at 7.48% examples, 105297 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:08,172 : INFO : EPOCH 3 - PROGRESS: at 18.46% examples, 123747 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:09,300 : INFO : EPOCH 3 - PROGRESS: at 29.75% examples, 129704 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:10,462 : INFO : EPOCH 3 - PROGRESS: at 41.79% examples, 131997 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:11,618 : INFO : EPOCH 3 - PROGRESS: at 53.20% examples, 133455 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:12,767 : INFO : EPOCH 3 - PROGRESS: at 64.38% examples, 134425 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:13,908 : INFO : EPOCH 3 - PROGRESS: at 76.38% examples, 135403 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:19:14,918 : INFO : EPOCH 3 - PROGRESS: at 87.07% examples, 137368 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:15,923 : INFO : EPOCH 3 - PROGRESS: at 95.73% examples, 136284 words/s, in_qsize 10, out_qsize 0\n",
      "2019-11-20 21:19:15,993 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:19:16,009 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:19:16,012 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:19:16,051 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:19:16,156 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:19:16,175 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:19:16,256 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:19:16,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:19:16,264 : INFO : EPOCH - 3 : training on 2099031 raw words (1418456 effective words) took 10.3s, 137675 effective words/s\n",
      "2019-11-20 21:19:17,379 : INFO : EPOCH 4 - PROGRESS: at 7.48% examples, 102656 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:18,490 : INFO : EPOCH 4 - PROGRESS: at 18.46% examples, 123429 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:19,633 : INFO : EPOCH 4 - PROGRESS: at 29.75% examples, 128952 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:20,765 : INFO : EPOCH 4 - PROGRESS: at 41.77% examples, 132313 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:21,769 : INFO : EPOCH 4 - PROGRESS: at 52.73% examples, 136177 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:22,774 : INFO : EPOCH 4 - PROGRESS: at 61.26% examples, 133571 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:19:23,917 : INFO : EPOCH 4 - PROGRESS: at 72.18% examples, 133750 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:24,932 : INFO : EPOCH 4 - PROGRESS: at 83.56% examples, 135886 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:25,941 : INFO : EPOCH 4 - PROGRESS: at 92.33% examples, 135630 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:26,400 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:19:26,412 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:19:26,413 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:19:26,466 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:19:26,568 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:19:26,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:19:26,615 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:19:26,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:19:26,665 : INFO : EPOCH - 4 : training on 2099031 raw words (1418942 effective words) took 10.4s, 136524 effective words/s\n",
      "2019-11-20 21:19:27,779 : INFO : EPOCH 5 - PROGRESS: at 7.48% examples, 102809 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:28,898 : INFO : EPOCH 5 - PROGRESS: at 18.46% examples, 123140 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:30,026 : INFO : EPOCH 5 - PROGRESS: at 29.75% examples, 129230 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:31,164 : INFO : EPOCH 5 - PROGRESS: at 41.77% examples, 132390 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:32,322 : INFO : EPOCH 5 - PROGRESS: at 53.20% examples, 133619 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:33,454 : INFO : EPOCH 5 - PROGRESS: at 64.38% examples, 134948 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:34,607 : INFO : EPOCH 5 - PROGRESS: at 76.38% examples, 135642 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:19:35,644 : INFO : EPOCH 5 - PROGRESS: at 87.07% examples, 137149 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:19:36,686 : INFO : EPOCH 5 - PROGRESS: at 96.76% examples, 136927 words/s, in_qsize 8, out_qsize 0\n",
      "2019-11-20 21:19:36,707 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:19:36,708 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:19:36,709 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:19:36,760 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:19:36,856 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:19:36,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:19:36,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:19:36,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:19:36,951 : INFO : EPOCH - 5 : training on 2099031 raw words (1418438 effective words) took 10.3s, 138011 effective words/s\n",
      "2019-11-20 21:19:36,951 : INFO : training on a 10495155 raw words (7092643 effective words) took 51.5s, 137735 effective words/s\n",
      "2019-11-20 21:19:36,952 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00042.model, separately None\n",
      "2019-11-20 21:19:36,953 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00042.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:19:38,140 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:19:38,141 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00042.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:19:39,287 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:19:40,302 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00042.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 63.89203405380249\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:19:48,945 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:19:48,946 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:19:49,015 : INFO : PROGRESS: at sentence #10000, processed 412727 words, keeping 58917 word types\n",
      "2019-11-20 21:19:49,084 : INFO : PROGRESS: at sentence #20000, processed 820524 words, keeping 96947 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "43 51701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:19:49,148 : INFO : PROGRESS: at sentence #30000, processed 1216420 words, keeping 127848 word types\n",
      "2019-11-20 21:19:49,227 : INFO : PROGRESS: at sentence #40000, processed 1609710 words, keeping 155255 word types\n",
      "2019-11-20 21:19:49,312 : INFO : PROGRESS: at sentence #50000, processed 2036645 words, keeping 184186 word types\n",
      "2019-11-20 21:19:49,326 : INFO : collected 188389 word types from a corpus of 2108012 raw words and 51701 sentences\n",
      "2019-11-20 21:19:49,327 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:19:49,477 : INFO : New added 22037 unique words (10% of original 210426) and increased the count of 22037 pre-existing words (10% of original 210426)\n",
      "2019-11-20 21:19:49,632 : INFO : deleting the raw counts dictionary of 188389 items\n",
      "2019-11-20 21:19:49,637 : INFO : sample=0.001 downsamples 82 most-common words\n",
      "2019-11-20 21:19:49,638 : INFO : downsampling leaves estimated 2707369 word corpus (143.8% of prior 1883210)\n",
      "2019-11-20 21:19:50,820 : INFO : estimated required memory for 44074 words and 300 dimensions: 127814600 bytes\n",
      "2019-11-20 21:19:50,821 : INFO : updating layer weights\n",
      "2019-11-20 21:19:51,900 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:19:51,901 : INFO : training model with 8 workers on 437045 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:19:53,057 : INFO : EPOCH 1 - PROGRESS: at 8.02% examples, 98644 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:54,155 : INFO : EPOCH 1 - PROGRESS: at 19.09% examples, 121920 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:55,280 : INFO : EPOCH 1 - PROGRESS: at 29.77% examples, 128886 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:56,376 : INFO : EPOCH 1 - PROGRESS: at 41.49% examples, 132916 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:57,485 : INFO : EPOCH 1 - PROGRESS: at 53.82% examples, 135218 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:19:58,591 : INFO : EPOCH 1 - PROGRESS: at 65.53% examples, 136903 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:19:59,679 : INFO : EPOCH 1 - PROGRESS: at 76.63% examples, 138335 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:00,755 : INFO : EPOCH 1 - PROGRESS: at 87.46% examples, 139683 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:01,702 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:20:01,708 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:20:01,765 : INFO : EPOCH 1 - PROGRESS: at 97.79% examples, 140882 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-20 21:20:01,766 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:20:01,854 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:20:01,858 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:20:01,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:20:01,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:20:01,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:20:01,980 : INFO : EPOCH - 1 : training on 2108012 raw words (1419856 effective words) took 10.1s, 140980 effective words/s\n",
      "2019-11-20 21:20:03,108 : INFO : EPOCH 2 - PROGRESS: at 8.02% examples, 101160 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:04,293 : INFO : EPOCH 2 - PROGRESS: at 19.06% examples, 118726 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:05,487 : INFO : EPOCH 2 - PROGRESS: at 29.77% examples, 124231 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:06,643 : INFO : EPOCH 2 - PROGRESS: at 41.49% examples, 127595 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:07,784 : INFO : EPOCH 2 - PROGRESS: at 53.82% examples, 130125 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:08,935 : INFO : EPOCH 2 - PROGRESS: at 65.34% examples, 131702 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:10,080 : INFO : EPOCH 2 - PROGRESS: at 76.63% examples, 132880 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:11,093 : INFO : EPOCH 2 - PROGRESS: at 86.86% examples, 135049 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:12,105 : INFO : EPOCH 2 - PROGRESS: at 95.42% examples, 133963 words/s, in_qsize 10, out_qsize 0\n",
      "2019-11-20 21:20:12,167 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:20:12,177 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:20:12,264 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:20:12,375 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:20:12,383 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:20:12,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:20:12,463 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:20:12,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:20:12,512 : INFO : EPOCH - 2 : training on 2108012 raw words (1420391 effective words) took 10.5s, 134972 effective words/s\n",
      "2019-11-20 21:20:13,621 : INFO : EPOCH 3 - PROGRESS: at 8.02% examples, 102472 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:20:14,750 : INFO : EPOCH 3 - PROGRESS: at 19.06% examples, 122624 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:15,913 : INFO : EPOCH 3 - PROGRESS: at 29.77% examples, 128067 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:20:17,033 : INFO : EPOCH 3 - PROGRESS: at 41.49% examples, 131630 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:18,173 : INFO : EPOCH 3 - PROGRESS: at 53.82% examples, 133407 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:19,329 : INFO : EPOCH 3 - PROGRESS: at 65.53% examples, 134373 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:20,461 : INFO : EPOCH 3 - PROGRESS: at 76.63% examples, 135396 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:21,600 : INFO : EPOCH 3 - PROGRESS: at 87.46% examples, 136097 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:22,534 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:20:22,562 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:20:22,584 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:20:22,711 : INFO : EPOCH 3 - PROGRESS: at 98.38% examples, 136894 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-20 21:20:22,712 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:20:22,732 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:20:22,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:20:22,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:20:22,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:20:22,852 : INFO : EPOCH - 3 : training on 2108012 raw words (1419945 effective words) took 10.3s, 137439 effective words/s\n",
      "2019-11-20 21:20:23,978 : INFO : EPOCH 4 - PROGRESS: at 8.02% examples, 101283 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:25,128 : INFO : EPOCH 4 - PROGRESS: at 19.06% examples, 120695 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:20:26,265 : INFO : EPOCH 4 - PROGRESS: at 29.89% examples, 127484 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:27,392 : INFO : EPOCH 4 - PROGRESS: at 41.49% examples, 131055 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:28,535 : INFO : EPOCH 4 - PROGRESS: at 53.82% examples, 132851 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:29,697 : INFO : EPOCH 4 - PROGRESS: at 65.53% examples, 133768 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:20:30,835 : INFO : EPOCH 4 - PROGRESS: at 76.63% examples, 134782 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:31,980 : INFO : EPOCH 4 - PROGRESS: at 87.46% examples, 135463 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:32,909 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:20:32,912 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:20:32,959 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:20:33,118 : INFO : EPOCH 4 - PROGRESS: at 98.15% examples, 135811 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-20 21:20:33,118 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:20:33,129 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:20:33,148 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:20:33,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:20:33,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:20:33,190 : INFO : EPOCH - 4 : training on 2108012 raw words (1419938 effective words) took 10.3s, 137457 effective words/s\n",
      "2019-11-20 21:20:34,316 : INFO : EPOCH 5 - PROGRESS: at 8.02% examples, 100986 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:20:35,488 : INFO : EPOCH 5 - PROGRESS: at 19.06% examples, 119415 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:36,757 : INFO : EPOCH 5 - PROGRESS: at 29.89% examples, 121928 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:20:37,874 : INFO : EPOCH 5 - PROGRESS: at 41.49% examples, 126985 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:39,036 : INFO : EPOCH 5 - PROGRESS: at 53.79% examples, 129160 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:20:40,153 : INFO : EPOCH 5 - PROGRESS: at 65.34% examples, 131488 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:41,172 : INFO : EPOCH 5 - PROGRESS: at 76.12% examples, 133934 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:42,184 : INFO : EPOCH 5 - PROGRESS: at 85.31% examples, 133744 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:20:43,203 : INFO : EPOCH 5 - PROGRESS: at 94.50% examples, 134053 words/s, in_qsize 12, out_qsize 0\n",
      "2019-11-20 21:20:43,378 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:20:43,405 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:20:43,472 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:20:43,566 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:20:43,567 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:20:43,601 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:20:43,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:20:43,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:20:43,681 : INFO : EPOCH - 5 : training on 2108012 raw words (1419446 effective words) took 10.5s, 135420 effective words/s\n",
      "2019-11-20 21:20:43,681 : INFO : training on a 10540060 raw words (7099576 effective words) took 51.8s, 137113 effective words/s\n",
      "2019-11-20 21:20:43,682 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00043.model, separately None\n",
      "2019-11-20 21:20:43,683 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00043.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:20:44,867 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:20:44,868 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00043.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:20:46,006 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:20:47,020 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00043.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 66.71826887130737\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:20:52,816 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:20:52,817 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:20:52,893 : INFO : PROGRESS: at sentence #10000, processed 406301 words, keeping 58993 word types\n",
      "2019-11-20 21:20:52,961 : INFO : PROGRESS: at sentence #20000, processed 797362 words, keeping 95150 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "44 51055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:20:53,044 : INFO : PROGRESS: at sentence #30000, processed 1214285 words, keeping 128827 word types\n",
      "2019-11-20 21:20:53,121 : INFO : PROGRESS: at sentence #40000, processed 1627168 words, keeping 157843 word types\n",
      "2019-11-20 21:20:53,200 : INFO : PROGRESS: at sentence #50000, processed 2032302 words, keeping 183573 word types\n",
      "2019-11-20 21:20:53,211 : INFO : collected 186576 word types from a corpus of 2079307 raw words and 51055 sentences\n",
      "2019-11-20 21:20:53,212 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:20:53,357 : INFO : New added 21946 unique words (10% of original 208522) and increased the count of 21946 pre-existing words (10% of original 208522)\n",
      "2019-11-20 21:20:53,507 : INFO : deleting the raw counts dictionary of 186576 items\n",
      "2019-11-20 21:20:53,511 : INFO : sample=0.001 downsamples 80 most-common words\n",
      "2019-11-20 21:20:53,511 : INFO : downsampling leaves estimated 2666233 word corpus (143.6% of prior 1856382)\n",
      "2019-11-20 21:20:54,678 : INFO : estimated required memory for 43892 words and 300 dimensions: 127286800 bytes\n",
      "2019-11-20 21:20:54,679 : INFO : updating layer weights\n",
      "2019-11-20 21:20:55,795 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:20:55,796 : INFO : training model with 8 workers on 437036 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:20:56,916 : INFO : EPOCH 1 - PROGRESS: at 8.10% examples, 102287 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:58,002 : INFO : EPOCH 1 - PROGRESS: at 19.61% examples, 124616 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:20:59,080 : INFO : EPOCH 1 - PROGRESS: at 31.46% examples, 132235 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:00,161 : INFO : EPOCH 1 - PROGRESS: at 43.53% examples, 136159 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:01,244 : INFO : EPOCH 1 - PROGRESS: at 54.26% examples, 138421 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:02,317 : INFO : EPOCH 1 - PROGRESS: at 65.57% examples, 140323 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:21:03,350 : INFO : EPOCH 1 - PROGRESS: at 76.92% examples, 142302 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:04,367 : INFO : EPOCH 1 - PROGRESS: at 88.02% examples, 143252 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:05,430 : INFO : EPOCH 1 - PROGRESS: at 97.12% examples, 140726 words/s, in_qsize 7, out_qsize 1\n",
      "2019-11-20 21:21:05,431 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:21:05,433 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:21:05,458 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:21:05,492 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:21:05,505 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:21:05,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:21:05,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:21:05,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:21:05,539 : INFO : EPOCH - 1 : training on 2079307 raw words (1398798 effective words) took 9.7s, 143692 effective words/s\n",
      "2019-11-20 21:21:06,695 : INFO : EPOCH 2 - PROGRESS: at 8.10% examples, 98702 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:07,917 : INFO : EPOCH 2 - PROGRESS: at 19.72% examples, 115460 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:21:09,096 : INFO : EPOCH 2 - PROGRESS: at 31.46% examples, 121976 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:10,266 : INFO : EPOCH 2 - PROGRESS: at 43.53% examples, 125682 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:11,409 : INFO : EPOCH 2 - PROGRESS: at 54.26% examples, 128459 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:12,497 : INFO : EPOCH 2 - PROGRESS: at 65.57% examples, 131487 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:13,571 : INFO : EPOCH 2 - PROGRESS: at 76.92% examples, 133817 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:14,608 : INFO : EPOCH 2 - PROGRESS: at 85.39% examples, 131713 words/s, in_qsize 16, out_qsize 2\n",
      "2019-11-20 21:21:15,644 : INFO : EPOCH 2 - PROGRESS: at 96.49% examples, 133489 words/s, in_qsize 8, out_qsize 0\n",
      "2019-11-20 21:21:15,746 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:21:15,753 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:21:15,754 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:21:15,767 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:21:15,795 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:21:15,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:21:15,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:21:15,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:21:15,857 : INFO : EPOCH - 2 : training on 2079307 raw words (1398925 effective words) took 10.3s, 135682 effective words/s\n",
      "2019-11-20 21:21:16,988 : INFO : EPOCH 3 - PROGRESS: at 8.10% examples, 101235 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:18,149 : INFO : EPOCH 3 - PROGRESS: at 19.72% examples, 120040 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:21:19,264 : INFO : EPOCH 3 - PROGRESS: at 31.46% examples, 127476 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:20,399 : INFO : EPOCH 3 - PROGRESS: at 43.53% examples, 130910 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:21,541 : INFO : EPOCH 3 - PROGRESS: at 54.26% examples, 132717 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:22,673 : INFO : EPOCH 3 - PROGRESS: at 65.57% examples, 134299 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:23,770 : INFO : EPOCH 3 - PROGRESS: at 76.92% examples, 135904 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:24,814 : INFO : EPOCH 3 - PROGRESS: at 88.02% examples, 137187 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:25,811 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:21:25,824 : INFO : EPOCH 3 - PROGRESS: at 97.52% examples, 136782 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-20 21:21:25,826 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:21:25,854 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:21:25,875 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:21:25,910 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:21:25,941 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:21:25,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:21:26,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:21:26,037 : INFO : EPOCH - 3 : training on 2079307 raw words (1399710 effective words) took 10.2s, 137615 effective words/s\n",
      "2019-11-20 21:21:27,105 : INFO : EPOCH 4 - PROGRESS: at 8.10% examples, 107155 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:28,259 : INFO : EPOCH 4 - PROGRESS: at 19.72% examples, 123748 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:29,390 : INFO : EPOCH 4 - PROGRESS: at 31.46% examples, 129518 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:30,514 : INFO : EPOCH 4 - PROGRESS: at 43.53% examples, 132746 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:31,670 : INFO : EPOCH 4 - PROGRESS: at 54.26% examples, 133814 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:32,827 : INFO : EPOCH 4 - PROGRESS: at 65.57% examples, 134671 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:33,987 : INFO : EPOCH 4 - PROGRESS: at 76.92% examples, 135184 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:35,219 : INFO : EPOCH 4 - PROGRESS: at 88.47% examples, 134470 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:36,168 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:21:36,197 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:21:36,199 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:21:36,202 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:21:36,209 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:21:36,255 : INFO : EPOCH 4 - PROGRESS: at 99.24% examples, 135976 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:21:36,256 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:21:36,372 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:21:36,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:21:36,418 : INFO : EPOCH - 4 : training on 2079307 raw words (1399196 effective words) took 10.4s, 134887 effective words/s\n",
      "2019-11-20 21:21:37,642 : INFO : EPOCH 5 - PROGRESS: at 8.10% examples, 93458 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-20 21:21:38,798 : INFO : EPOCH 5 - PROGRESS: at 19.61% examples, 115502 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:21:39,927 : INFO : EPOCH 5 - PROGRESS: at 31.60% examples, 123744 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:41,062 : INFO : EPOCH 5 - PROGRESS: at 43.53% examples, 127976 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:42,208 : INFO : EPOCH 5 - PROGRESS: at 54.26% examples, 130250 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:43,334 : INFO : EPOCH 5 - PROGRESS: at 65.57% examples, 132313 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:44,408 : INFO : EPOCH 5 - PROGRESS: at 76.92% examples, 134571 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:45,418 : INFO : EPOCH 5 - PROGRESS: at 88.02% examples, 136476 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:21:46,426 : INFO : EPOCH 5 - PROGRESS: at 96.49% examples, 134829 words/s, in_qsize 8, out_qsize 0\n",
      "2019-11-20 21:21:46,468 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:21:46,492 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:21:46,499 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:21:46,514 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:21:46,555 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:21:46,568 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:21:46,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:21:46,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:21:46,654 : INFO : EPOCH - 5 : training on 2079307 raw words (1399059 effective words) took 10.2s, 136795 effective words/s\n",
      "2019-11-20 21:21:46,654 : INFO : training on a 10396535 raw words (6995688 effective words) took 50.9s, 137557 effective words/s\n",
      "2019-11-20 21:21:46,655 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00044.model, separately None\n",
      "2019-11-20 21:21:46,656 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00044.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:21:47,851 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:21:47,852 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00044.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:21:48,979 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:21:50,009 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00044.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 62.98871183395386\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:21:58,258 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:21:58,259 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:21:58,338 : INFO : PROGRESS: at sentence #10000, processed 417948 words, keeping 59405 word types\n",
      "2019-11-20 21:21:58,408 : INFO : PROGRESS: at sentence #20000, processed 812252 words, keeping 96328 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "45 51154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:21:58,476 : INFO : PROGRESS: at sentence #30000, processed 1215808 words, keeping 128667 word types\n",
      "2019-11-20 21:21:58,549 : INFO : PROGRESS: at sentence #40000, processed 1627974 words, keeping 157913 word types\n",
      "2019-11-20 21:21:58,629 : INFO : PROGRESS: at sentence #50000, processed 2045691 words, keeping 184401 word types\n",
      "2019-11-20 21:21:58,638 : INFO : collected 187432 word types from a corpus of 2095824 raw words and 51154 sentences\n",
      "2019-11-20 21:21:58,639 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:21:58,765 : INFO : New added 21877 unique words (10% of original 209309) and increased the count of 21877 pre-existing words (10% of original 209309)\n",
      "2019-11-20 21:21:58,911 : INFO : deleting the raw counts dictionary of 187432 items\n",
      "2019-11-20 21:21:58,915 : INFO : sample=0.001 downsamples 86 most-common words\n",
      "2019-11-20 21:21:58,916 : INFO : downsampling leaves estimated 2689548 word corpus (143.7% of prior 1872132)\n",
      "2019-11-20 21:22:00,089 : INFO : estimated required memory for 43754 words and 300 dimensions: 126886600 bytes\n",
      "2019-11-20 21:22:00,090 : INFO : updating layer weights\n",
      "2019-11-20 21:22:01,191 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:22:01,192 : INFO : training model with 8 workers on 437014 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:22:02,285 : INFO : EPOCH 1 - PROGRESS: at 7.92% examples, 104283 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:03,425 : INFO : EPOCH 1 - PROGRESS: at 19.01% examples, 122761 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:04,487 : INFO : EPOCH 1 - PROGRESS: at 30.93% examples, 131793 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:05,592 : INFO : EPOCH 1 - PROGRESS: at 42.53% examples, 134993 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:06,718 : INFO : EPOCH 1 - PROGRESS: at 53.87% examples, 136373 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-20 21:22:07,816 : INFO : EPOCH 1 - PROGRESS: at 65.13% examples, 137986 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:08,931 : INFO : EPOCH 1 - PROGRESS: at 76.75% examples, 138732 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-20 21:22:10,011 : INFO : EPOCH 1 - PROGRESS: at 87.80% examples, 139988 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:10,863 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:22:10,877 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:22:10,894 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:22:10,906 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:22:11,086 : INFO : EPOCH 1 - PROGRESS: at 98.70% examples, 140759 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:22:11,087 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:22:11,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:22:11,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:22:11,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:22:11,180 : INFO : EPOCH - 1 : training on 2095824 raw words (1411291 effective words) took 10.0s, 141408 effective words/s\n",
      "2019-11-20 21:22:12,276 : INFO : EPOCH 2 - PROGRESS: at 7.92% examples, 104154 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:13,422 : INFO : EPOCH 2 - PROGRESS: at 19.04% examples, 122403 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:14,643 : INFO : EPOCH 2 - PROGRESS: at 30.93% examples, 125506 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:15,839 : INFO : EPOCH 2 - PROGRESS: at 42.53% examples, 127567 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:17,000 : INFO : EPOCH 2 - PROGRESS: at 53.94% examples, 129515 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:18,168 : INFO : EPOCH 2 - PROGRESS: at 65.13% examples, 130889 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:19,321 : INFO : EPOCH 2 - PROGRESS: at 76.75% examples, 131953 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:20,453 : INFO : EPOCH 2 - PROGRESS: at 87.80% examples, 133128 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:22:21,303 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:22:21,349 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:22:21,357 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:22:21,365 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:22:21,516 : INFO : EPOCH 2 - PROGRESS: at 98.70% examples, 134722 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:22:21,517 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:22:21,551 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:22:21,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:22:21,585 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:22:21,585 : INFO : EPOCH - 2 : training on 2095824 raw words (1411175 effective words) took 10.4s, 135722 effective words/s\n",
      "2019-11-20 21:22:22,699 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 102483 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:23,830 : INFO : EPOCH 3 - PROGRESS: at 19.04% examples, 122283 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:24,964 : INFO : EPOCH 3 - PROGRESS: at 30.93% examples, 128637 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:26,138 : INFO : EPOCH 3 - PROGRESS: at 42.53% examples, 130516 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:27,281 : INFO : EPOCH 3 - PROGRESS: at 53.94% examples, 132364 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:28,449 : INFO : EPOCH 3 - PROGRESS: at 65.08% examples, 133224 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:29,604 : INFO : EPOCH 3 - PROGRESS: at 76.75% examples, 133932 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:30,745 : INFO : EPOCH 3 - PROGRESS: at 87.80% examples, 134805 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:31,599 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:22:31,611 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:22:31,617 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:22:31,618 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:22:31,815 : INFO : EPOCH 3 - PROGRESS: at 98.70% examples, 136154 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:22:31,816 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:22:31,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:22:31,844 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:22:31,917 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:22:31,917 : INFO : EPOCH - 3 : training on 2095824 raw words (1411428 effective words) took 10.3s, 136713 effective words/s\n",
      "2019-11-20 21:22:33,039 : INFO : EPOCH 4 - PROGRESS: at 7.92% examples, 101574 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:34,160 : INFO : EPOCH 4 - PROGRESS: at 19.04% examples, 122287 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:35,308 : INFO : EPOCH 4 - PROGRESS: at 30.93% examples, 128185 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:22:36,445 : INFO : EPOCH 4 - PROGRESS: at 42.54% examples, 131221 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:22:37,619 : INFO : EPOCH 4 - PROGRESS: at 53.80% examples, 132245 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:22:38,770 : INFO : EPOCH 4 - PROGRESS: at 65.08% examples, 133439 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:39,934 : INFO : EPOCH 4 - PROGRESS: at 76.75% examples, 133936 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:41,074 : INFO : EPOCH 4 - PROGRESS: at 87.80% examples, 134826 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:41,934 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:22:41,936 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:22:41,947 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:22:41,948 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:22:42,140 : INFO : EPOCH 4 - PROGRESS: at 98.70% examples, 136223 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:22:42,140 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:22:42,175 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:22:42,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:22:42,240 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:22:42,241 : INFO : EPOCH - 4 : training on 2095824 raw words (1411063 effective words) took 10.3s, 136789 effective words/s\n",
      "2019-11-20 21:22:43,329 : INFO : EPOCH 5 - PROGRESS: at 7.92% examples, 104817 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:44,448 : INFO : EPOCH 5 - PROGRESS: at 19.04% examples, 124202 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:45,570 : INFO : EPOCH 5 - PROGRESS: at 30.93% examples, 130495 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:22:46,757 : INFO : EPOCH 5 - PROGRESS: at 42.53% examples, 131567 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:22:47,895 : INFO : EPOCH 5 - PROGRESS: at 53.94% examples, 133352 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:22:49,037 : INFO : EPOCH 5 - PROGRESS: at 65.08% examples, 134603 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:50,186 : INFO : EPOCH 5 - PROGRESS: at 76.75% examples, 135216 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:51,322 : INFO : EPOCH 5 - PROGRESS: at 87.80% examples, 136017 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:22:52,209 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:22:52,233 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:22:52,240 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:22:52,255 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:22:52,432 : INFO : EPOCH 5 - PROGRESS: at 98.70% examples, 136697 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:22:52,433 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:22:52,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:22:52,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:22:52,517 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:22:52,517 : INFO : EPOCH - 5 : training on 2095824 raw words (1411646 effective words) took 10.3s, 137481 effective words/s\n",
      "2019-11-20 21:22:52,518 : INFO : training on a 10479120 raw words (7056603 effective words) took 51.3s, 137489 effective words/s\n",
      "2019-11-20 21:22:52,519 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00045.model, separately None\n",
      "2019-11-20 21:22:52,520 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00045.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:22:53,724 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:22:53,725 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00045.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:22:54,878 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:22:55,838 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00045.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 65.82939743995667\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:23:01,647 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:23:01,648 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:23:01,725 : INFO : PROGRESS: at sentence #10000, processed 397252 words, keeping 57056 word types\n",
      "2019-11-20 21:23:01,798 : INFO : PROGRESS: at sentence #20000, processed 810130 words, keeping 95828 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "46 51668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:23:01,866 : INFO : PROGRESS: at sentence #30000, processed 1229017 words, keeping 128446 word types\n",
      "2019-11-20 21:23:01,938 : INFO : PROGRESS: at sentence #40000, processed 1642891 words, keeping 157109 word types\n",
      "2019-11-20 21:23:02,013 : INFO : PROGRESS: at sentence #50000, processed 2050377 words, keeping 183173 word types\n",
      "2019-11-20 21:23:02,025 : INFO : collected 187447 word types from a corpus of 2115598 raw words and 51668 sentences\n",
      "2019-11-20 21:23:02,026 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:23:02,153 : INFO : New added 22097 unique words (10% of original 209544) and increased the count of 22097 pre-existing words (10% of original 209544)\n",
      "2019-11-20 21:23:02,300 : INFO : deleting the raw counts dictionary of 187447 items\n",
      "2019-11-20 21:23:02,305 : INFO : sample=0.001 downsamples 80 most-common words\n",
      "2019-11-20 21:23:02,306 : INFO : downsampling leaves estimated 2718654 word corpus (143.7% of prior 1892252)\n",
      "2019-11-20 21:23:03,465 : INFO : estimated required memory for 44194 words and 300 dimensions: 128162600 bytes\n",
      "2019-11-20 21:23:03,466 : INFO : updating layer weights\n",
      "2019-11-20 21:23:04,605 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:23:04,606 : INFO : training model with 8 workers on 437161 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:23:05,691 : INFO : EPOCH 1 - PROGRESS: at 8.28% examples, 105472 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:06,773 : INFO : EPOCH 1 - PROGRESS: at 19.81% examples, 127263 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:07,851 : INFO : EPOCH 1 - PROGRESS: at 30.91% examples, 134735 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:08,921 : INFO : EPOCH 1 - PROGRESS: at 42.15% examples, 138625 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:10,020 : INFO : EPOCH 1 - PROGRESS: at 53.30% examples, 140170 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:11,023 : INFO : EPOCH 1 - PROGRESS: at 63.11% examples, 141192 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:12,039 : INFO : EPOCH 1 - PROGRESS: at 73.01% examples, 140733 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:13,049 : INFO : EPOCH 1 - PROGRESS: at 83.84% examples, 142026 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:14,073 : INFO : EPOCH 1 - PROGRESS: at 94.37% examples, 142247 words/s, in_qsize 13, out_qsize 0\n",
      "2019-11-20 21:23:14,349 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:23:14,364 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:23:14,366 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:23:14,458 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:23:14,519 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:23:14,532 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:23:14,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:23:14,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:23:14,680 : INFO : EPOCH - 1 : training on 2115598 raw words (1426203 effective words) took 10.1s, 141680 effective words/s\n",
      "2019-11-20 21:23:15,807 : INFO : EPOCH 2 - PROGRESS: at 8.28% examples, 101651 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:16,958 : INFO : EPOCH 2 - PROGRESS: at 19.81% examples, 121045 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:18,081 : INFO : EPOCH 2 - PROGRESS: at 30.91% examples, 128508 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:19,223 : INFO : EPOCH 2 - PROGRESS: at 42.15% examples, 131657 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:20,228 : INFO : EPOCH 2 - PROGRESS: at 51.60% examples, 131940 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:21,233 : INFO : EPOCH 2 - PROGRESS: at 60.61% examples, 132136 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:22,259 : INFO : EPOCH 2 - PROGRESS: at 70.79% examples, 133583 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:23,312 : INFO : EPOCH 2 - PROGRESS: at 80.05% examples, 132732 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:24,369 : INFO : EPOCH 2 - PROGRESS: at 90.90% examples, 134154 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:24,895 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:23:24,904 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:23:24,977 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:23:25,030 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:23:25,100 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:23:25,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:23:25,180 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:23:25,215 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:23:25,216 : INFO : EPOCH - 2 : training on 2115598 raw words (1425984 effective words) took 10.5s, 135453 effective words/s\n",
      "2019-11-20 21:23:26,280 : INFO : EPOCH 3 - PROGRESS: at 8.28% examples, 107668 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:27,418 : INFO : EPOCH 3 - PROGRESS: at 19.81% examples, 125343 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:23:28,557 : INFO : EPOCH 3 - PROGRESS: at 30.91% examples, 130784 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:29,708 : INFO : EPOCH 3 - PROGRESS: at 42.15% examples, 133128 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:30,716 : INFO : EPOCH 3 - PROGRESS: at 52.86% examples, 136769 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:31,773 : INFO : EPOCH 3 - PROGRESS: at 61.36% examples, 134058 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:32,836 : INFO : EPOCH 3 - PROGRESS: at 71.65% examples, 134617 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:33,999 : INFO : EPOCH 3 - PROGRESS: at 82.73% examples, 135033 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:35,153 : INFO : EPOCH 3 - PROGRESS: at 94.37% examples, 135494 words/s, in_qsize 13, out_qsize 0\n",
      "2019-11-20 21:23:35,308 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:23:35,310 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:23:35,324 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:23:35,514 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:23:35,515 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:23:35,547 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:23:35,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:23:35,613 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:23:35,613 : INFO : EPOCH - 3 : training on 2115598 raw words (1425886 effective words) took 10.4s, 137245 effective words/s\n",
      "2019-11-20 21:23:36,687 : INFO : EPOCH 4 - PROGRESS: at 8.28% examples, 106829 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:37,806 : INFO : EPOCH 4 - PROGRESS: at 19.81% examples, 125879 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:38,921 : INFO : EPOCH 4 - PROGRESS: at 30.91% examples, 132170 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:40,090 : INFO : EPOCH 4 - PROGRESS: at 42.15% examples, 133600 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:41,105 : INFO : EPOCH 4 - PROGRESS: at 52.04% examples, 134500 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:42,141 : INFO : EPOCH 4 - PROGRESS: at 61.36% examples, 134667 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:43,155 : INFO : EPOCH 4 - PROGRESS: at 71.65% examples, 136021 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:44,195 : INFO : EPOCH 4 - PROGRESS: at 82.26% examples, 137408 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:45,213 : INFO : EPOCH 4 - PROGRESS: at 91.96% examples, 136814 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:45,645 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:23:45,660 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:23:45,718 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:23:45,818 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:23:45,828 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:23:45,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:23:45,909 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:23:45,965 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:23:45,966 : INFO : EPOCH - 4 : training on 2115598 raw words (1426061 effective words) took 10.3s, 137861 effective words/s\n",
      "2019-11-20 21:23:47,020 : INFO : EPOCH 5 - PROGRESS: at 8.28% examples, 108613 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:48,144 : INFO : EPOCH 5 - PROGRESS: at 19.81% examples, 126731 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:49,253 : INFO : EPOCH 5 - PROGRESS: at 30.91% examples, 132956 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:50,367 : INFO : EPOCH 5 - PROGRESS: at 42.15% examples, 135854 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:51,386 : INFO : EPOCH 5 - PROGRESS: at 52.01% examples, 136225 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:23:52,413 : INFO : EPOCH 5 - PROGRESS: at 60.93% examples, 135315 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:53,436 : INFO : EPOCH 5 - PROGRESS: at 71.65% examples, 137353 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:54,457 : INFO : EPOCH 5 - PROGRESS: at 82.26% examples, 138897 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:23:55,472 : INFO : EPOCH 5 - PROGRESS: at 91.03% examples, 136744 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:23:55,902 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:23:55,916 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:23:55,966 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:23:56,083 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:23:56,171 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:23:56,172 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:23:56,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:23:56,205 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:23:56,206 : INFO : EPOCH - 5 : training on 2115598 raw words (1426157 effective words) took 10.2s, 139398 effective words/s\n",
      "2019-11-20 21:23:56,206 : INFO : training on a 10577990 raw words (7130291 effective words) took 51.6s, 138185 effective words/s\n",
      "2019-11-20 21:23:56,207 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00046.model, separately None\n",
      "2019-11-20 21:23:56,208 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00046.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:23:57,411 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:23:57,412 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00046.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:23:58,570 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:23:59,574 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00046.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 63.73558712005615\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:24:05,405 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:24:05,406 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:24:05,488 : INFO : PROGRESS: at sentence #10000, processed 421076 words, keeping 60840 word types\n",
      "2019-11-20 21:24:05,555 : INFO : PROGRESS: at sentence #20000, processed 831250 words, keeping 98285 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "47 50538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:24:05,620 : INFO : PROGRESS: at sentence #30000, processed 1230041 words, keeping 130029 word types\n",
      "2019-11-20 21:24:05,695 : INFO : PROGRESS: at sentence #40000, processed 1649161 words, keeping 161172 word types\n",
      "2019-11-20 21:24:05,771 : INFO : PROGRESS: at sentence #50000, processed 2065158 words, keeping 187633 word types\n",
      "2019-11-20 21:24:05,776 : INFO : collected 189224 word types from a corpus of 2088036 raw words and 50538 sentences\n",
      "2019-11-20 21:24:05,776 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:24:05,921 : INFO : New added 21787 unique words (10% of original 211011) and increased the count of 21787 pre-existing words (10% of original 211011)\n",
      "2019-11-20 21:24:06,067 : INFO : deleting the raw counts dictionary of 189224 items\n",
      "2019-11-20 21:24:06,072 : INFO : sample=0.001 downsamples 80 most-common words\n",
      "2019-11-20 21:24:06,073 : INFO : downsampling leaves estimated 2683252 word corpus (144.1% of prior 1862317)\n",
      "2019-11-20 21:24:07,209 : INFO : estimated required memory for 43574 words and 300 dimensions: 126364600 bytes\n",
      "2019-11-20 21:24:07,210 : INFO : updating layer weights\n",
      "2019-11-20 21:24:08,288 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:24:08,289 : INFO : training model with 8 workers on 436960 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:24:09,434 : INFO : EPOCH 1 - PROGRESS: at 7.59% examples, 100009 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:24:10,632 : INFO : EPOCH 1 - PROGRESS: at 19.07% examples, 117102 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:11,796 : INFO : EPOCH 1 - PROGRESS: at 30.51% examples, 123688 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:24:13,030 : INFO : EPOCH 1 - PROGRESS: at 42.16% examples, 125219 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:14,055 : INFO : EPOCH 1 - PROGRESS: at 51.85% examples, 125963 words/s, in_qsize 16, out_qsize 2\n",
      "2019-11-20 21:24:15,239 : INFO : EPOCH 1 - PROGRESS: at 61.69% examples, 123852 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:16,314 : INFO : EPOCH 1 - PROGRESS: at 69.87% examples, 122147 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:17,466 : INFO : EPOCH 1 - PROGRESS: at 80.39% examples, 122878 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:18,494 : INFO : EPOCH 1 - PROGRESS: at 89.52% examples, 123692 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:24:19,220 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:24:19,284 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:24:19,288 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:24:19,305 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:24:19,325 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:24:19,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:24:19,498 : INFO : EPOCH 1 - PROGRESS: at 99.57% examples, 125114 words/s, in_qsize 1, out_qsize 1\n",
      "2019-11-20 21:24:19,499 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:24:19,507 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:24:19,508 : INFO : EPOCH - 1 : training on 2088036 raw words (1408225 effective words) took 11.2s, 125598 effective words/s\n",
      "2019-11-20 21:24:20,614 : INFO : EPOCH 2 - PROGRESS: at 7.59% examples, 103582 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:21,748 : INFO : EPOCH 2 - PROGRESS: at 19.07% examples, 122562 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:24:22,881 : INFO : EPOCH 2 - PROGRESS: at 30.51% examples, 128759 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:24,068 : INFO : EPOCH 2 - PROGRESS: at 42.16% examples, 130310 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:25,195 : INFO : EPOCH 2 - PROGRESS: at 53.71% examples, 132545 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:26,206 : INFO : EPOCH 2 - PROGRESS: at 64.74% examples, 135495 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:27,207 : INFO : EPOCH 2 - PROGRESS: at 72.88% examples, 133490 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:28,304 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 134361 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:29,315 : INFO : EPOCH 2 - PROGRESS: at 94.67% examples, 136300 words/s, in_qsize 11, out_qsize 0\n",
      "2019-11-20 21:24:29,601 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:24:29,618 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:24:29,620 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:24:29,662 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:24:29,685 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:24:29,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:24:29,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:24:29,879 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:24:29,880 : INFO : EPOCH - 2 : training on 2088036 raw words (1408055 effective words) took 10.4s, 135858 effective words/s\n",
      "2019-11-20 21:24:30,997 : INFO : EPOCH 3 - PROGRESS: at 7.59% examples, 102572 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:32,121 : INFO : EPOCH 3 - PROGRESS: at 19.07% examples, 122518 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:33,252 : INFO : EPOCH 3 - PROGRESS: at 30.56% examples, 128610 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:34,418 : INFO : EPOCH 3 - PROGRESS: at 42.16% examples, 130971 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:35,534 : INFO : EPOCH 3 - PROGRESS: at 53.71% examples, 133378 words/s, in_qsize 15, out_qsize 1\n",
      "2019-11-20 21:24:36,647 : INFO : EPOCH 3 - PROGRESS: at 65.16% examples, 135162 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:24:37,682 : INFO : EPOCH 3 - PROGRESS: at 76.01% examples, 136916 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:38,771 : INFO : EPOCH 3 - PROGRESS: at 85.18% examples, 135239 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:39,803 : INFO : EPOCH 3 - PROGRESS: at 95.81% examples, 136057 words/s, in_qsize 9, out_qsize 0\n",
      "2019-11-20 21:24:39,928 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:24:39,957 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:24:39,959 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:24:39,990 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:24:40,000 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:24:40,050 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:24:40,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:24:40,169 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:24:40,170 : INFO : EPOCH - 3 : training on 2088036 raw words (1408428 effective words) took 10.3s, 136981 effective words/s\n",
      "2019-11-20 21:24:41,274 : INFO : EPOCH 4 - PROGRESS: at 7.63% examples, 103500 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:42,384 : INFO : EPOCH 4 - PROGRESS: at 19.07% examples, 123957 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:43,505 : INFO : EPOCH 4 - PROGRESS: at 30.51% examples, 130109 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:44,676 : INFO : EPOCH 4 - PROGRESS: at 42.16% examples, 131817 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:45,772 : INFO : EPOCH 4 - PROGRESS: at 53.71% examples, 134518 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:46,899 : INFO : EPOCH 4 - PROGRESS: at 65.16% examples, 135889 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:47,931 : INFO : EPOCH 4 - PROGRESS: at 76.01% examples, 137581 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:48,953 : INFO : EPOCH 4 - PROGRESS: at 85.18% examples, 136858 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:50,025 : INFO : EPOCH 4 - PROGRESS: at 95.81% examples, 136945 words/s, in_qsize 9, out_qsize 0\n",
      "2019-11-20 21:24:50,097 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:24:50,154 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:24:50,157 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:24:50,172 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:24:50,230 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:24:50,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:24:50,370 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:24:50,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:24:50,374 : INFO : EPOCH - 4 : training on 2088036 raw words (1408086 effective words) took 10.2s, 138094 effective words/s\n",
      "2019-11-20 21:24:51,497 : INFO : EPOCH 5 - PROGRESS: at 7.59% examples, 101918 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:52,616 : INFO : EPOCH 5 - PROGRESS: at 19.07% examples, 122428 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:53,704 : INFO : EPOCH 5 - PROGRESS: at 30.51% examples, 130349 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:54,868 : INFO : EPOCH 5 - PROGRESS: at 42.16% examples, 132154 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:55,973 : INFO : EPOCH 5 - PROGRESS: at 53.71% examples, 134583 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:57,129 : INFO : EPOCH 5 - PROGRESS: at 65.16% examples, 135325 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:58,284 : INFO : EPOCH 5 - PROGRESS: at 76.39% examples, 135836 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:24:59,397 : INFO : EPOCH 5 - PROGRESS: at 87.59% examples, 136932 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:00,338 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:25:00,358 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:25:00,367 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:25:00,385 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:25:00,403 : INFO : EPOCH 5 - PROGRESS: at 98.67% examples, 138544 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:25:00,403 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:25:00,509 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:25:00,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:25:00,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:25:00,609 : INFO : EPOCH - 5 : training on 2088036 raw words (1407438 effective words) took 10.2s, 137621 effective words/s\n",
      "2019-11-20 21:25:00,610 : INFO : training on a 10440180 raw words (7040232 effective words) took 52.3s, 134563 effective words/s\n",
      "2019-11-20 21:25:00,610 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00047.model, separately None\n",
      "2019-11-20 21:25:00,611 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00047.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:25:01,810 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:25:01,811 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00047.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:25:02,947 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:25:03,994 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00047.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 64.42022776603699\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:25:09,665 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:25:09,665 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:25:09,742 : INFO : PROGRESS: at sentence #10000, processed 406774 words, keeping 59137 word types\n",
      "2019-11-20 21:25:09,807 : INFO : PROGRESS: at sentence #20000, processed 819322 words, keeping 98057 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "48 50196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:25:09,874 : INFO : PROGRESS: at sentence #30000, processed 1239323 words, keeping 131564 word types\n",
      "2019-11-20 21:25:09,946 : INFO : PROGRESS: at sentence #40000, processed 1644004 words, keeping 160904 word types\n",
      "2019-11-20 21:25:10,061 : INFO : PROGRESS: at sentence #50000, processed 2066377 words, keeping 188324 word types\n",
      "2019-11-20 21:25:10,064 : INFO : collected 188779 word types from a corpus of 2074787 raw words and 50196 sentences\n",
      "2019-11-20 21:25:10,065 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:25:10,190 : INFO : New added 21764 unique words (10% of original 210543) and increased the count of 21764 pre-existing words (10% of original 210543)\n",
      "2019-11-20 21:25:10,340 : INFO : deleting the raw counts dictionary of 188779 items\n",
      "2019-11-20 21:25:10,345 : INFO : sample=0.001 downsamples 84 most-common words\n",
      "2019-11-20 21:25:10,345 : INFO : downsampling leaves estimated 2660031 word corpus (143.7% of prior 1850670)\n",
      "2019-11-20 21:25:11,504 : INFO : estimated required memory for 43528 words and 300 dimensions: 126231200 bytes\n",
      "2019-11-20 21:25:11,505 : INFO : updating layer weights\n",
      "2019-11-20 21:25:12,632 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:25:12,633 : INFO : training model with 8 workers on 437011 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:25:13,725 : INFO : EPOCH 1 - PROGRESS: at 8.38% examples, 104684 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:14,813 : INFO : EPOCH 1 - PROGRESS: at 19.93% examples, 125671 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:15,866 : INFO : EPOCH 1 - PROGRESS: at 31.36% examples, 134323 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:16,933 : INFO : EPOCH 1 - PROGRESS: at 43.30% examples, 138326 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:18,016 : INFO : EPOCH 1 - PROGRESS: at 54.21% examples, 140396 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:19,110 : INFO : EPOCH 1 - PROGRESS: at 66.06% examples, 141357 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:20,210 : INFO : EPOCH 1 - PROGRESS: at 77.60% examples, 141952 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:25:21,337 : INFO : EPOCH 1 - PROGRESS: at 88.64% examples, 142071 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:22,090 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:25:22,101 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:25:22,125 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:25:22,204 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:25:22,218 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:25:22,229 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:25:22,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:25:22,411 : INFO : EPOCH 1 - PROGRESS: at 100.00% examples, 142859 words/s, in_qsize 0, out_qsize 1\n",
      "2019-11-20 21:25:22,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:25:22,413 : INFO : EPOCH - 1 : training on 2074787 raw words (1395696 effective words) took 9.8s, 142838 effective words/s\n",
      "2019-11-20 21:25:23,543 : INFO : EPOCH 2 - PROGRESS: at 8.38% examples, 101176 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:24,684 : INFO : EPOCH 2 - PROGRESS: at 19.93% examples, 120644 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:25,787 : INFO : EPOCH 2 - PROGRESS: at 31.36% examples, 128637 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:26,822 : INFO : EPOCH 2 - PROGRESS: at 42.80% examples, 133401 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:27,841 : INFO : EPOCH 2 - PROGRESS: at 51.29% examples, 130485 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:28,962 : INFO : EPOCH 2 - PROGRESS: at 61.71% examples, 131636 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:30,099 : INFO : EPOCH 2 - PROGRESS: at 73.36% examples, 133057 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:25:31,245 : INFO : EPOCH 2 - PROGRESS: at 84.88% examples, 133970 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:25:32,366 : INFO : EPOCH 2 - PROGRESS: at 96.31% examples, 135047 words/s, in_qsize 8, out_qsize 0\n",
      "2019-11-20 21:25:32,426 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:25:32,429 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:25:32,433 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:25:32,482 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:25:32,511 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:25:32,512 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:25:32,578 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:25:32,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:25:32,727 : INFO : EPOCH - 2 : training on 2074787 raw words (1396218 effective words) took 10.3s, 135462 effective words/s\n",
      "2019-11-20 21:25:33,823 : INFO : EPOCH 3 - PROGRESS: at 8.38% examples, 104462 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:34,969 : INFO : EPOCH 3 - PROGRESS: at 19.93% examples, 122272 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:36,026 : INFO : EPOCH 3 - PROGRESS: at 29.89% examples, 125595 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:25:37,045 : INFO : EPOCH 3 - PROGRESS: at 38.92% examples, 125406 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:38,097 : INFO : EPOCH 3 - PROGRESS: at 49.01% examples, 125672 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:39,121 : INFO : EPOCH 3 - PROGRESS: at 57.15% examples, 124505 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:25:40,222 : INFO : EPOCH 3 - PROGRESS: at 64.90% examples, 120384 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:41,229 : INFO : EPOCH 3 - PROGRESS: at 74.06% examples, 121088 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:42,262 : INFO : EPOCH 3 - PROGRESS: at 84.50% examples, 123423 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:25:43,281 : INFO : EPOCH 3 - PROGRESS: at 94.38% examples, 124828 words/s, in_qsize 12, out_qsize 0\n",
      "2019-11-20 21:25:43,584 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:25:43,595 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:25:43,596 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:25:43,644 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:25:43,673 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:25:43,698 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:25:43,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:25:43,889 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:25:43,890 : INFO : EPOCH - 3 : training on 2074787 raw words (1396531 effective words) took 11.2s, 125195 effective words/s\n",
      "2019-11-20 21:25:44,899 : INFO : EPOCH 4 - PROGRESS: at 7.77% examples, 106743 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:46,070 : INFO : EPOCH 4 - PROGRESS: at 16.31% examples, 101275 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:25:47,111 : INFO : EPOCH 4 - PROGRESS: at 27.33% examples, 116411 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:48,153 : INFO : EPOCH 4 - PROGRESS: at 35.14% examples, 114538 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:49,163 : INFO : EPOCH 4 - PROGRESS: at 46.71% examples, 121724 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:50,175 : INFO : EPOCH 4 - PROGRESS: at 55.62% examples, 123460 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:51,210 : INFO : EPOCH 4 - PROGRESS: at 63.20% examples, 120526 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:52,264 : INFO : EPOCH 4 - PROGRESS: at 73.36% examples, 122161 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:53,287 : INFO : EPOCH 4 - PROGRESS: at 84.02% examples, 124510 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:54,313 : INFO : EPOCH 4 - PROGRESS: at 92.94% examples, 124445 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:25:54,686 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:25:54,689 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:25:54,704 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:25:54,769 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:25:54,791 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:25:54,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:25:54,926 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:25:54,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:25:54,996 : INFO : EPOCH - 4 : training on 2074787 raw words (1396053 effective words) took 11.1s, 125810 effective words/s\n",
      "2019-11-20 21:25:56,110 : INFO : EPOCH 5 - PROGRESS: at 8.16% examples, 102405 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:25:57,190 : INFO : EPOCH 5 - PROGRESS: at 19.93% examples, 124908 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:58,310 : INFO : EPOCH 5 - PROGRESS: at 31.36% examples, 131052 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:25:59,372 : INFO : EPOCH 5 - PROGRESS: at 42.80% examples, 134487 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:00,385 : INFO : EPOCH 5 - PROGRESS: at 49.88% examples, 127719 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:01,451 : INFO : EPOCH 5 - PROGRESS: at 57.58% examples, 124374 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:02,489 : INFO : EPOCH 5 - PROGRESS: at 66.64% examples, 123104 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:26:03,588 : INFO : EPOCH 5 - PROGRESS: at 77.11% examples, 124449 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:04,682 : INFO : EPOCH 5 - PROGRESS: at 88.24% examples, 127055 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:05,545 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:26:05,556 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:26:05,562 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:26:05,621 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:26:05,645 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:26:05,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:26:05,792 : INFO : EPOCH 5 - PROGRESS: at 99.56% examples, 128837 words/s, in_qsize 1, out_qsize 1\n",
      "2019-11-20 21:26:05,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:26:05,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:26:05,837 : INFO : EPOCH - 5 : training on 2074787 raw words (1396732 effective words) took 10.8s, 128935 effective words/s\n",
      "2019-11-20 21:26:05,837 : INFO : training on a 10373935 raw words (6981230 effective words) took 53.2s, 131219 effective words/s\n",
      "2019-11-20 21:26:05,838 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00048.model, separately None\n",
      "2019-11-20 21:26:05,839 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00048.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:26:07,136 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:26:07,137 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00048.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:26:08,317 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:26:09,351 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00048.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 65.35700011253357\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:26:17,700 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:26:17,701 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:26:17,780 : INFO : PROGRESS: at sentence #10000, processed 413471 words, keeping 59132 word types\n",
      "2019-11-20 21:26:17,848 : INFO : PROGRESS: at sentence #20000, processed 830735 words, keeping 98373 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "49 50133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:26:17,918 : INFO : PROGRESS: at sentence #30000, processed 1254470 words, keeping 131987 word types\n",
      "2019-11-20 21:26:17,993 : INFO : PROGRESS: at sentence #40000, processed 1668768 words, keeping 162194 word types\n",
      "2019-11-20 21:26:18,083 : INFO : PROGRESS: at sentence #50000, processed 2093993 words, keeping 189765 word types\n",
      "2019-11-20 21:26:18,085 : INFO : collected 189928 word types from a corpus of 2097682 raw words and 50133 sentences\n",
      "2019-11-20 21:26:18,086 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:26:18,216 : INFO : New added 21884 unique words (10% of original 211812) and increased the count of 21884 pre-existing words (10% of original 211812)\n",
      "2019-11-20 21:26:18,366 : INFO : deleting the raw counts dictionary of 189928 items\n",
      "2019-11-20 21:26:18,370 : INFO : sample=0.001 downsamples 84 most-common words\n",
      "2019-11-20 21:26:18,371 : INFO : downsampling leaves estimated 2697390 word corpus (144.1% of prior 1872229)\n",
      "2019-11-20 21:26:19,547 : INFO : estimated required memory for 43768 words and 300 dimensions: 126927200 bytes\n",
      "2019-11-20 21:26:19,548 : INFO : updating layer weights\n",
      "2019-11-20 21:26:20,652 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:26:20,653 : INFO : training model with 8 workers on 436978 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:26:21,762 : INFO : EPOCH 1 - PROGRESS: at 7.83% examples, 102355 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:22,854 : INFO : EPOCH 1 - PROGRESS: at 19.55% examples, 124348 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:23,938 : INFO : EPOCH 1 - PROGRESS: at 30.91% examples, 131988 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:25,070 : INFO : EPOCH 1 - PROGRESS: at 42.56% examples, 134492 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:26:26,193 : INFO : EPOCH 1 - PROGRESS: at 53.45% examples, 136461 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:26:27,304 : INFO : EPOCH 1 - PROGRESS: at 64.53% examples, 137660 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:28,384 : INFO : EPOCH 1 - PROGRESS: at 76.12% examples, 139080 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:26:29,504 : INFO : EPOCH 1 - PROGRESS: at 86.88% examples, 139704 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:30,362 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:26:30,366 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:26:30,389 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:26:30,424 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:26:30,557 : INFO : EPOCH 1 - PROGRESS: at 98.63% examples, 141044 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:26:30,558 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:26:30,606 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:26:30,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:26:30,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:26:30,630 : INFO : EPOCH - 1 : training on 2097682 raw words (1415940 effective words) took 10.0s, 142033 effective words/s\n",
      "2019-11-20 21:26:31,750 : INFO : EPOCH 2 - PROGRESS: at 7.83% examples, 101385 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:26:32,939 : INFO : EPOCH 2 - PROGRESS: at 19.55% examples, 118424 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:34,108 : INFO : EPOCH 2 - PROGRESS: at 30.91% examples, 124589 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:35,315 : INFO : EPOCH 2 - PROGRESS: at 42.56% examples, 126809 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:36,510 : INFO : EPOCH 2 - PROGRESS: at 53.45% examples, 128562 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:26:37,687 : INFO : EPOCH 2 - PROGRESS: at 64.38% examples, 129793 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:38,785 : INFO : EPOCH 2 - PROGRESS: at 76.12% examples, 131852 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:39,968 : INFO : EPOCH 2 - PROGRESS: at 87.05% examples, 132353 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:26:40,844 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:26:40,861 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:26:40,896 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:26:40,913 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:26:41,048 : INFO : EPOCH 2 - PROGRESS: at 98.63% examples, 134083 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:26:41,049 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:26:41,105 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:26:41,133 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:26:41,135 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:26:41,136 : INFO : EPOCH - 2 : training on 2097682 raw words (1416008 effective words) took 10.5s, 134881 effective words/s\n",
      "2019-11-20 21:26:42,552 : INFO : EPOCH 3 - PROGRESS: at 7.83% examples, 80085 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:43,580 : INFO : EPOCH 3 - PROGRESS: at 18.53% examples, 106481 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:26:44,588 : INFO : EPOCH 3 - PROGRESS: at 26.51% examples, 108321 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:45,827 : INFO : EPOCH 3 - PROGRESS: at 34.79% examples, 103900 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:46,831 : INFO : EPOCH 3 - PROGRESS: at 45.44% examples, 111551 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:26:47,933 : INFO : EPOCH 3 - PROGRESS: at 53.45% examples, 111243 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:48,976 : INFO : EPOCH 3 - PROGRESS: at 63.67% examples, 115149 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:49,981 : INFO : EPOCH 3 - PROGRESS: at 72.35% examples, 116324 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:51,002 : INFO : EPOCH 3 - PROGRESS: at 81.67% examples, 117157 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:52,074 : INFO : EPOCH 3 - PROGRESS: at 90.71% examples, 117890 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:26:52,601 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:26:52,613 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:26:52,618 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:26:52,790 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:26:52,797 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:26:52,834 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:26:52,840 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:26:52,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:26:52,873 : INFO : EPOCH - 3 : training on 2097682 raw words (1416133 effective words) took 11.7s, 120734 effective words/s\n",
      "2019-11-20 21:26:53,964 : INFO : EPOCH 4 - PROGRESS: at 7.83% examples, 104257 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:55,059 : INFO : EPOCH 4 - PROGRESS: at 19.55% examples, 125227 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:56,129 : INFO : EPOCH 4 - PROGRESS: at 30.91% examples, 133208 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:57,230 : INFO : EPOCH 4 - PROGRESS: at 42.56% examples, 136367 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:58,362 : INFO : EPOCH 4 - PROGRESS: at 53.45% examples, 137801 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:26:59,575 : INFO : EPOCH 4 - PROGRESS: at 64.38% examples, 136731 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:00,741 : INFO : EPOCH 4 - PROGRESS: at 76.12% examples, 136750 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:01,960 : INFO : EPOCH 4 - PROGRESS: at 86.88% examples, 136156 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:02,911 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:27:02,935 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:27:02,950 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:27:02,992 : INFO : EPOCH 4 - PROGRESS: at 98.04% examples, 137486 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-20 21:27:02,993 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:27:03,139 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:27:03,179 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:27:03,212 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:27:03,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:27:03,220 : INFO : EPOCH - 4 : training on 2097682 raw words (1416645 effective words) took 10.3s, 137012 effective words/s\n",
      "2019-11-20 21:27:04,463 : INFO : EPOCH 5 - PROGRESS: at 7.83% examples, 91481 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:27:05,469 : INFO : EPOCH 5 - PROGRESS: at 18.54% examples, 115793 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:06,616 : INFO : EPOCH 5 - PROGRESS: at 26.99% examples, 112082 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:07,642 : INFO : EPOCH 5 - PROGRESS: at 37.45% examples, 119398 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:08,667 : INFO : EPOCH 5 - PROGRESS: at 46.28% examples, 119111 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:09,831 : INFO : EPOCH 5 - PROGRESS: at 57.29% examples, 122372 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:11,007 : INFO : EPOCH 5 - PROGRESS: at 68.18% examples, 124465 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:12,138 : INFO : EPOCH 5 - PROGRESS: at 79.90% examples, 126550 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:13,175 : INFO : EPOCH 5 - PROGRESS: at 90.26% examples, 128804 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:13,865 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:27:13,876 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:27:13,895 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:27:13,948 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:27:14,023 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:27:14,116 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:27:14,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:27:14,160 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:27:14,161 : INFO : EPOCH - 5 : training on 2097682 raw words (1415463 effective words) took 10.9s, 129469 effective words/s\n",
      "2019-11-20 21:27:14,162 : INFO : training on a 10488410 raw words (7080189 effective words) took 53.5s, 132321 effective words/s\n",
      "2019-11-20 21:27:14,163 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_ocr_qual_1_2_00049.model, separately None\n",
      "2019-11-20 21:27:14,164 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_ocr_qual_1_2_00049.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:27:15,350 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:27:15,351 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_ocr_qual_1_2_00049.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:27:16,493 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:27:17,529 : INFO : saved ./LMs/w2v_005_EM_ocr_qual_1_2_00049.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 68.17731499671936\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i_model in range(40, 50):\n",
    "    t1 = time.time()\n",
    "\n",
    "    embedding_model_ocr = copy.deepcopy(embedding_model_orig)\n",
    "    embedding_model_ocr.workers = 8\n",
    "    embedding_model_ocr.vocabulary.min_count = 5\n",
    "    embedding_model_ocr.alpha = min_alpha_yet_reached*10.\n",
    "    \n",
    "    db_sentence_sampled = db_sentence.sample(n=5095, replace=True)\n",
    "    list_sentences = db_sentence_sampled[\"ocr_sentencizer_cleaned\"].to_list()\n",
    "    print('#sentences: {}'.format(len(list_sentences)))\n",
    "    flattened_list_sentences = [val for sublist in list_sentences for val in sublist]\n",
    "    print(i_model, len(flattened_list_sentences))\n",
    "    embedding_model_ocr.build_vocab(flattened_list_sentences, update=True)\n",
    "    embedding_model_ocr.train(flattened_list_sentences, \n",
    "                              total_examples=embedding_model_ocr.corpus_count,\n",
    "                              epochs=w2v_args.epochs,  \n",
    "                              compute_loss=w2v_args.compute_loss)\n",
    "    print(\"\\n\\n[INFO] Save the model\")\n",
    "    embedding_model_ocr.save(\"./LMs/w2v_005_EM_ocr_qual_1_2_%05i.model\" % i_model)\n",
    "    print(\"total: {}\".format(time.time() - t1))\n",
    "    print(\"=================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:27:23,104 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:27:23,105 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:27:23,153 : INFO : PROGRESS: at sentence #10000, processed 246740 words, keeping 19704 word types\n",
      "2019-11-20 21:27:23,196 : INFO : PROGRESS: at sentence #20000, processed 491912 words, keeping 29488 word types\n",
      "2019-11-20 21:27:23,234 : INFO : PROGRESS: at sentence #30000, processed 735756 words, keeping 36394 word types\n",
      "2019-11-20 21:27:23,272 : INFO : PROGRESS: at sentence #40000, processed 978693 words, keeping 42296 word types\n",
      "2019-11-20 21:27:23,313 : INFO : PROGRESS: at sentence #50000, processed 1225546 words, keeping 47966 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "40 85298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:27:23,353 : INFO : PROGRESS: at sentence #60000, processed 1475520 words, keeping 52550 word types\n",
      "2019-11-20 21:27:23,393 : INFO : PROGRESS: at sentence #70000, processed 1726077 words, keeping 56843 word types\n",
      "2019-11-20 21:27:23,433 : INFO : PROGRESS: at sentence #80000, processed 1978915 words, keeping 60495 word types\n",
      "2019-11-20 21:27:23,456 : INFO : collected 62326 word types from a corpus of 2110335 raw words and 85298 sentences\n",
      "2019-11-20 21:27:23,457 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:27:23,530 : INFO : New added 18041 unique words (22% of original 80367) and increased the count of 18041 pre-existing words (22% of original 80367)\n",
      "2019-11-20 21:27:23,655 : INFO : deleting the raw counts dictionary of 62326 items\n",
      "2019-11-20 21:27:23,657 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:27:23,658 : INFO : downsampling leaves estimated 2767005 word corpus (135.7% of prior 2038742)\n",
      "2019-11-20 21:27:24,821 : INFO : estimated required memory for 36082 words and 300 dimensions: 104637800 bytes\n",
      "2019-11-20 21:27:24,822 : INFO : updating layer weights\n",
      "2019-11-20 21:27:25,683 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:27:25,684 : INFO : training model with 8 workers on 435455 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:27:26,741 : INFO : EPOCH 1 - PROGRESS: at 8.11% examples, 110096 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:27,774 : INFO : EPOCH 1 - PROGRESS: at 19.42% examples, 134040 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:28,814 : INFO : EPOCH 1 - PROGRESS: at 30.97% examples, 141590 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:29,830 : INFO : EPOCH 1 - PROGRESS: at 42.47% examples, 146148 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:30,836 : INFO : EPOCH 1 - PROGRESS: at 53.96% examples, 148994 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:31,869 : INFO : EPOCH 1 - PROGRESS: at 65.17% examples, 150400 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:32,893 : INFO : EPOCH 1 - PROGRESS: at 76.63% examples, 151467 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:33,907 : INFO : EPOCH 1 - PROGRESS: at 87.80% examples, 152566 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:34,749 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:27:34,751 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:27:34,778 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:27:34,789 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:27:34,878 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:27:34,916 : INFO : EPOCH 1 - PROGRESS: at 99.03% examples, 153859 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:27:34,916 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:27:34,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:27:34,993 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:27:34,994 : INFO : EPOCH - 1 : training on 2110335 raw words (1431845 effective words) took 9.3s, 154025 effective words/s\n",
      "2019-11-20 21:27:36,022 : INFO : EPOCH 2 - PROGRESS: at 8.11% examples, 113462 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:37,120 : INFO : EPOCH 2 - PROGRESS: at 19.42% examples, 131754 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:38,221 : INFO : EPOCH 2 - PROGRESS: at 30.97% examples, 137284 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:39,335 : INFO : EPOCH 2 - PROGRESS: at 42.47% examples, 139545 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:40,435 : INFO : EPOCH 2 - PROGRESS: at 53.96% examples, 141027 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:41,514 : INFO : EPOCH 2 - PROGRESS: at 65.17% examples, 142609 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:42,547 : INFO : EPOCH 2 - PROGRESS: at 76.63% examples, 144548 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:43,590 : INFO : EPOCH 2 - PROGRESS: at 87.80% examples, 145910 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:44,511 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:27:44,523 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:27:44,524 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:27:44,541 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:27:44,630 : INFO : EPOCH 2 - PROGRESS: at 98.54% examples, 146665 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:27:44,630 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:27:44,664 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:27:44,773 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:27:44,775 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:27:44,776 : INFO : EPOCH - 2 : training on 2110335 raw words (1431475 effective words) took 9.8s, 146554 effective words/s\n",
      "2019-11-20 21:27:45,814 : INFO : EPOCH 3 - PROGRESS: at 8.11% examples, 112098 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:46,860 : INFO : EPOCH 3 - PROGRESS: at 19.42% examples, 134268 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:27:47,918 : INFO : EPOCH 3 - PROGRESS: at 30.97% examples, 140930 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:48,979 : INFO : EPOCH 3 - PROGRESS: at 42.47% examples, 144072 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:50,030 : INFO : EPOCH 3 - PROGRESS: at 53.96% examples, 145998 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:51,093 : INFO : EPOCH 3 - PROGRESS: at 65.17% examples, 147119 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:52,151 : INFO : EPOCH 3 - PROGRESS: at 76.63% examples, 147946 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:53,224 : INFO : EPOCH 3 - PROGRESS: at 87.80% examples, 148406 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:54,160 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:27:54,170 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:27:54,173 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:27:54,188 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:27:54,268 : INFO : EPOCH 3 - PROGRESS: at 98.54% examples, 148819 words/s, in_qsize 3, out_qsize 1\n",
      "2019-11-20 21:27:54,269 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:27:54,272 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:27:54,353 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:27:54,441 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:27:54,442 : INFO : EPOCH - 3 : training on 2110335 raw words (1431091 effective words) took 9.7s, 148249 effective words/s\n",
      "2019-11-20 21:27:55,460 : INFO : EPOCH 4 - PROGRESS: at 8.11% examples, 114060 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:27:56,532 : INFO : EPOCH 4 - PROGRESS: at 19.42% examples, 133655 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:57,608 : INFO : EPOCH 4 - PROGRESS: at 30.97% examples, 139704 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:58,717 : INFO : EPOCH 4 - PROGRESS: at 42.47% examples, 141500 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:27:59,795 : INFO : EPOCH 4 - PROGRESS: at 53.97% examples, 143128 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:00,869 : INFO : EPOCH 4 - PROGRESS: at 65.17% examples, 144494 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:28:01,908 : INFO : EPOCH 4 - PROGRESS: at 76.63% examples, 146033 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:02,973 : INFO : EPOCH 4 - PROGRESS: at 87.80% examples, 146839 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:03,871 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:28:03,881 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:28:03,912 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:28:03,915 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:28:03,960 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:28:04,012 : INFO : EPOCH 4 - PROGRESS: at 99.03% examples, 148194 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:28:04,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:28:04,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:28:04,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:28:04,074 : INFO : EPOCH - 4 : training on 2110335 raw words (1430382 effective words) took 9.6s, 148650 effective words/s\n",
      "2019-11-20 21:28:05,105 : INFO : EPOCH 5 - PROGRESS: at 8.11% examples, 113078 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:28:06,166 : INFO : EPOCH 5 - PROGRESS: at 19.42% examples, 133849 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:07,236 : INFO : EPOCH 5 - PROGRESS: at 30.97% examples, 140083 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:08,309 : INFO : EPOCH 5 - PROGRESS: at 42.47% examples, 143011 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:09,362 : INFO : EPOCH 5 - PROGRESS: at 53.96% examples, 145125 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:10,463 : INFO : EPOCH 5 - PROGRESS: at 65.17% examples, 145589 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:11,508 : INFO : EPOCH 5 - PROGRESS: at 76.63% examples, 146862 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:12,575 : INFO : EPOCH 5 - PROGRESS: at 87.80% examples, 147568 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:13,448 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:28:13,481 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:28:13,490 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:28:13,505 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:28:13,568 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:28:13,617 : INFO : EPOCH 5 - PROGRESS: at 99.03% examples, 148816 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:28:13,617 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:28:13,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:28:13,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:28:13,721 : INFO : EPOCH - 5 : training on 2110335 raw words (1431555 effective words) took 9.6s, 148623 effective words/s\n",
      "2019-11-20 21:28:13,721 : INFO : training on a 10551675 raw words (7156348 effective words) took 48.0s, 148979 effective words/s\n",
      "2019-11-20 21:28:13,722 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00040.model, separately None\n",
      "2019-11-20 21:28:13,723 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00040.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:28:14,923 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:28:14,924 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00040.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:28:16,074 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:28:17,102 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00040.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 59.56198310852051\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:28:25,932 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:28:25,936 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:28:25,978 : INFO : PROGRESS: at sentence #10000, processed 246923 words, keeping 20164 word types\n",
      "2019-11-20 21:28:26,019 : INFO : PROGRESS: at sentence #20000, processed 492005 words, keeping 29296 word types\n",
      "2019-11-20 21:28:26,061 : INFO : PROGRESS: at sentence #30000, processed 737570 words, keeping 36091 word types\n",
      "2019-11-20 21:28:26,101 : INFO : PROGRESS: at sentence #40000, processed 976974 words, keeping 41682 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "41 85311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:28:26,145 : INFO : PROGRESS: at sentence #50000, processed 1218673 words, keeping 46801 word types\n",
      "2019-11-20 21:28:26,193 : INFO : PROGRESS: at sentence #60000, processed 1470059 words, keeping 51581 word types\n",
      "2019-11-20 21:28:26,237 : INFO : PROGRESS: at sentence #70000, processed 1719719 words, keeping 55988 word types\n",
      "2019-11-20 21:28:26,282 : INFO : PROGRESS: at sentence #80000, processed 1968792 words, keeping 59589 word types\n",
      "2019-11-20 21:28:26,306 : INFO : collected 61610 word types from a corpus of 2102379 raw words and 85311 sentences\n",
      "2019-11-20 21:28:26,307 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:28:26,391 : INFO : New added 17966 unique words (22% of original 79576) and increased the count of 17966 pre-existing words (22% of original 79576)\n",
      "2019-11-20 21:28:26,508 : INFO : deleting the raw counts dictionary of 61610 items\n",
      "2019-11-20 21:28:26,511 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:28:26,511 : INFO : downsampling leaves estimated 2763193 word corpus (136.0% of prior 2032265)\n",
      "2019-11-20 21:28:27,730 : INFO : estimated required memory for 35932 words and 300 dimensions: 104202800 bytes\n",
      "2019-11-20 21:28:27,732 : INFO : updating layer weights\n",
      "2019-11-20 21:28:28,628 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:28:28,629 : INFO : training model with 8 workers on 435416 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:28:29,683 : INFO : EPOCH 1 - PROGRESS: at 8.07% examples, 110625 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:28:30,753 : INFO : EPOCH 1 - PROGRESS: at 19.45% examples, 131723 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:31,787 : INFO : EPOCH 1 - PROGRESS: at 30.95% examples, 140250 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:28:32,827 : INFO : EPOCH 1 - PROGRESS: at 42.46% examples, 144343 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:33,837 : INFO : EPOCH 1 - PROGRESS: at 54.21% examples, 147615 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:34,851 : INFO : EPOCH 1 - PROGRESS: at 65.61% examples, 149765 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:35,880 : INFO : EPOCH 1 - PROGRESS: at 76.68% examples, 150855 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:36,882 : INFO : EPOCH 1 - PROGRESS: at 88.21% examples, 152314 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:37,680 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:28:37,700 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:28:37,733 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:28:37,744 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:28:37,786 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:28:37,883 : INFO : EPOCH 1 - PROGRESS: at 99.30% examples, 153316 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:28:37,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:28:37,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:28:37,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:28:37,969 : INFO : EPOCH - 1 : training on 2102379 raw words (1427924 effective words) took 9.3s, 153144 effective words/s\n",
      "2019-11-20 21:28:39,032 : INFO : EPOCH 2 - PROGRESS: at 8.07% examples, 109729 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:40,153 : INFO : EPOCH 2 - PROGRESS: at 19.45% examples, 128064 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:41,281 : INFO : EPOCH 2 - PROGRESS: at 30.89% examples, 133703 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:28:42,356 : INFO : EPOCH 2 - PROGRESS: at 42.46% examples, 138136 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:43,424 : INFO : EPOCH 2 - PROGRESS: at 54.21% examples, 140933 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:44,512 : INFO : EPOCH 2 - PROGRESS: at 65.62% examples, 142397 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:45,574 : INFO : EPOCH 2 - PROGRESS: at 76.68% examples, 143859 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:46,616 : INFO : EPOCH 2 - PROGRESS: at 88.21% examples, 145407 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:47,403 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:28:47,455 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:28:47,476 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:28:47,491 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:28:47,512 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:28:47,627 : INFO : EPOCH 2 - PROGRESS: at 99.17% examples, 146746 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:28:47,627 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:28:47,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:28:47,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:28:47,667 : INFO : EPOCH - 2 : training on 2102379 raw words (1428377 effective words) took 9.7s, 147507 effective words/s\n",
      "2019-11-20 21:28:48,720 : INFO : EPOCH 3 - PROGRESS: at 8.07% examples, 110787 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:49,782 : INFO : EPOCH 3 - PROGRESS: at 19.49% examples, 132400 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:50,843 : INFO : EPOCH 3 - PROGRESS: at 30.95% examples, 139513 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:51,939 : INFO : EPOCH 3 - PROGRESS: at 42.38% examples, 141957 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:53,018 : INFO : EPOCH 3 - PROGRESS: at 54.29% examples, 143796 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:54,096 : INFO : EPOCH 3 - PROGRESS: at 65.61% examples, 145041 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:28:55,153 : INFO : EPOCH 3 - PROGRESS: at 76.68% examples, 146209 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:56,212 : INFO : EPOCH 3 - PROGRESS: at 88.21% examples, 147179 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:56,997 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:28:57,015 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:28:57,066 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:28:57,113 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:28:57,121 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:28:57,222 : INFO : EPOCH 3 - PROGRESS: at 99.17% examples, 148357 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:28:57,223 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:28:57,247 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:28:57,277 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:28:57,278 : INFO : EPOCH - 3 : training on 2102379 raw words (1428507 effective words) took 9.6s, 148883 effective words/s\n",
      "2019-11-20 21:28:58,322 : INFO : EPOCH 4 - PROGRESS: at 8.07% examples, 111490 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:28:59,380 : INFO : EPOCH 4 - PROGRESS: at 19.45% examples, 132940 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:00,446 : INFO : EPOCH 4 - PROGRESS: at 30.95% examples, 139744 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:29:01,506 : INFO : EPOCH 4 - PROGRESS: at 42.46% examples, 143357 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:02,573 : INFO : EPOCH 4 - PROGRESS: at 54.21% examples, 145283 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:03,656 : INFO : EPOCH 4 - PROGRESS: at 65.61% examples, 146165 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:04,716 : INFO : EPOCH 4 - PROGRESS: at 76.68% examples, 147163 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:29:05,754 : INFO : EPOCH 4 - PROGRESS: at 88.21% examples, 148387 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:06,557 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:29:06,582 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:29:06,606 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:29:06,620 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:29:06,687 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:29:06,775 : INFO : EPOCH 4 - PROGRESS: at 99.17% examples, 149266 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:29:06,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:29:06,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:29:06,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:29:06,839 : INFO : EPOCH - 4 : training on 2102379 raw words (1428686 effective words) took 9.5s, 149658 effective words/s\n",
      "2019-11-20 21:29:07,860 : INFO : EPOCH 5 - PROGRESS: at 8.07% examples, 114254 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:08,907 : INFO : EPOCH 5 - PROGRESS: at 19.49% examples, 135299 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:09,978 : INFO : EPOCH 5 - PROGRESS: at 30.95% examples, 141002 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:29:11,064 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 143420 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:12,129 : INFO : EPOCH 5 - PROGRESS: at 54.21% examples, 145331 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:13,239 : INFO : EPOCH 5 - PROGRESS: at 65.62% examples, 145606 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-20 21:29:14,311 : INFO : EPOCH 5 - PROGRESS: at 76.68% examples, 146411 words/s, in_qsize 15, out_qsize 1\n",
      "2019-11-20 21:29:15,367 : INFO : EPOCH 5 - PROGRESS: at 88.21% examples, 147406 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:16,129 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:29:16,174 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:29:16,177 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:29:16,195 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:29:16,244 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:29:16,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:29:16,386 : INFO : EPOCH 5 - PROGRESS: at 99.57% examples, 149123 words/s, in_qsize 1, out_qsize 1\n",
      "2019-11-20 21:29:16,387 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:29:16,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:29:16,435 : INFO : EPOCH - 5 : training on 2102379 raw words (1428213 effective words) took 9.6s, 149057 effective words/s\n",
      "2019-11-20 21:29:16,435 : INFO : training on a 10511895 raw words (7141707 effective words) took 47.8s, 149393 effective words/s\n",
      "2019-11-20 21:29:16,437 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00041.model, separately None\n",
      "2019-11-20 21:29:16,440 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00041.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:29:17,612 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:29:17,613 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00041.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:29:18,798 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:29:19,823 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00041.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 62.72033882141113\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:29:25,844 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:29:25,845 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:29:25,891 : INFO : PROGRESS: at sentence #10000, processed 247030 words, keeping 20669 word types\n",
      "2019-11-20 21:29:25,929 : INFO : PROGRESS: at sentence #20000, processed 493771 words, keeping 29890 word types\n",
      "2019-11-20 21:29:25,967 : INFO : PROGRESS: at sentence #30000, processed 736194 words, keeping 36934 word types\n",
      "2019-11-20 21:29:26,004 : INFO : PROGRESS: at sentence #40000, processed 974279 words, keeping 42765 word types\n",
      "2019-11-20 21:29:26,045 : INFO : PROGRESS: at sentence #50000, processed 1218792 words, keeping 47783 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "42 84646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:29:26,083 : INFO : PROGRESS: at sentence #60000, processed 1464223 words, keeping 52406 word types\n",
      "2019-11-20 21:29:26,122 : INFO : PROGRESS: at sentence #70000, processed 1705041 words, keeping 56417 word types\n",
      "2019-11-20 21:29:26,161 : INFO : PROGRESS: at sentence #80000, processed 1953275 words, keeping 60117 word types\n",
      "2019-11-20 21:29:26,181 : INFO : collected 61667 word types from a corpus of 2067846 raw words and 84646 sentences\n",
      "2019-11-20 21:29:26,182 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:29:26,253 : INFO : New added 17809 unique words (22% of original 79476) and increased the count of 17809 pre-existing words (22% of original 79476)\n",
      "2019-11-20 21:29:26,372 : INFO : deleting the raw counts dictionary of 61667 items\n",
      "2019-11-20 21:29:26,374 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:29:26,374 : INFO : downsampling leaves estimated 2714751 word corpus (135.9% of prior 1997533)\n",
      "2019-11-20 21:29:27,554 : INFO : estimated required memory for 35618 words and 300 dimensions: 103292200 bytes\n",
      "2019-11-20 21:29:27,555 : INFO : updating layer weights\n",
      "2019-11-20 21:29:28,405 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:29:28,406 : INFO : training model with 8 workers on 435442 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:29:29,445 : INFO : EPOCH 1 - PROGRESS: at 7.98% examples, 112683 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:30,469 : INFO : EPOCH 1 - PROGRESS: at 19.70% examples, 135733 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:31,502 : INFO : EPOCH 1 - PROGRESS: at 30.95% examples, 143193 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:32,521 : INFO : EPOCH 1 - PROGRESS: at 42.93% examples, 147068 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:33,541 : INFO : EPOCH 1 - PROGRESS: at 54.68% examples, 149571 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:34,566 : INFO : EPOCH 1 - PROGRESS: at 66.26% examples, 151069 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:29:35,610 : INFO : EPOCH 1 - PROGRESS: at 77.78% examples, 151715 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:36,624 : INFO : EPOCH 1 - PROGRESS: at 89.54% examples, 152755 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:37,215 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:29:37,277 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:29:37,416 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:29:37,418 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:29:37,430 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:29:37,438 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:29:37,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:29:37,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:29:37,467 : INFO : EPOCH - 1 : training on 2067846 raw words (1404499 effective words) took 9.0s, 155238 effective words/s\n",
      "2019-11-20 21:29:38,545 : INFO : EPOCH 2 - PROGRESS: at 7.98% examples, 107958 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:39,689 : INFO : EPOCH 2 - PROGRESS: at 19.70% examples, 125751 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:40,827 : INFO : EPOCH 2 - PROGRESS: at 30.95% examples, 131713 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:41,936 : INFO : EPOCH 2 - PROGRESS: at 42.93% examples, 135221 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:29:43,017 : INFO : EPOCH 2 - PROGRESS: at 54.68% examples, 138232 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:44,112 : INFO : EPOCH 2 - PROGRESS: at 66.26% examples, 139926 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:45,194 : INFO : EPOCH 2 - PROGRESS: at 77.85% examples, 141298 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:46,241 : INFO : EPOCH 2 - PROGRESS: at 89.54% examples, 142984 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:46,819 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:29:46,929 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:29:46,984 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:29:47,011 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:29:47,020 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:29:47,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:29:47,045 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:29:47,058 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:29:47,059 : INFO : EPOCH - 2 : training on 2067846 raw words (1404802 effective words) took 9.6s, 146590 effective words/s\n",
      "2019-11-20 21:29:48,120 : INFO : EPOCH 3 - PROGRESS: at 7.98% examples, 110178 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:49,194 : INFO : EPOCH 3 - PROGRESS: at 19.70% examples, 131200 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:50,286 : INFO : EPOCH 3 - PROGRESS: at 30.95% examples, 137384 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:51,350 : INFO : EPOCH 3 - PROGRESS: at 42.93% examples, 141050 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:29:52,428 : INFO : EPOCH 3 - PROGRESS: at 54.68% examples, 143031 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:53,519 : INFO : EPOCH 3 - PROGRESS: at 66.26% examples, 144048 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:29:54,579 : INFO : EPOCH 3 - PROGRESS: at 77.85% examples, 145241 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:55,638 : INFO : EPOCH 3 - PROGRESS: at 89.54% examples, 146280 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:56,277 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:29:56,338 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:29:56,410 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:29:56,446 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:29:56,465 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:29:56,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:29:56,508 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:29:56,514 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:29:56,515 : INFO : EPOCH - 3 : training on 2067846 raw words (1404825 effective words) took 9.4s, 148778 effective words/s\n",
      "2019-11-20 21:29:57,612 : INFO : EPOCH 4 - PROGRESS: at 7.98% examples, 106390 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:58,727 : INFO : EPOCH 4 - PROGRESS: at 19.70% examples, 126468 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:29:59,874 : INFO : EPOCH 4 - PROGRESS: at 30.95% examples, 131763 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:30:00,981 : INFO : EPOCH 4 - PROGRESS: at 42.93% examples, 135355 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:02,082 : INFO : EPOCH 4 - PROGRESS: at 54.68% examples, 137854 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:03,178 : INFO : EPOCH 4 - PROGRESS: at 66.31% examples, 139637 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:30:04,249 : INFO : EPOCH 4 - PROGRESS: at 77.85% examples, 141222 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:30:05,289 : INFO : EPOCH 4 - PROGRESS: at 89.54% examples, 142988 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:30:05,905 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:30:05,992 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:30:06,068 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:30:06,083 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:30:06,114 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:30:06,118 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:30:06,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:30:06,148 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:30:06,149 : INFO : EPOCH - 4 : training on 2067846 raw words (1404451 effective words) took 9.6s, 145997 effective words/s\n",
      "2019-11-20 21:30:07,198 : INFO : EPOCH 5 - PROGRESS: at 7.98% examples, 111287 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:30:08,237 : INFO : EPOCH 5 - PROGRESS: at 19.70% examples, 133985 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:09,294 : INFO : EPOCH 5 - PROGRESS: at 30.95% examples, 140767 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:10,378 : INFO : EPOCH 5 - PROGRESS: at 42.93% examples, 142977 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:11,455 : INFO : EPOCH 5 - PROGRESS: at 54.68% examples, 144653 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:12,561 : INFO : EPOCH 5 - PROGRESS: at 66.31% examples, 145081 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:30:13,623 : INFO : EPOCH 5 - PROGRESS: at 77.85% examples, 146093 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:30:14,679 : INFO : EPOCH 5 - PROGRESS: at 89.54% examples, 147031 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:15,313 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:30:15,362 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:30:15,428 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:30:15,452 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:30:15,490 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:30:15,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:30:15,518 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:30:15,542 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:30:15,543 : INFO : EPOCH - 5 : training on 2067846 raw words (1403809 effective words) took 9.4s, 149645 effective words/s\n",
      "2019-11-20 21:30:15,544 : INFO : training on a 10339230 raw words (7022386 effective words) took 47.1s, 148979 effective words/s\n",
      "2019-11-20 21:30:15,545 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00042.model, separately None\n",
      "2019-11-20 21:30:15,546 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00042.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:30:16,783 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:30:16,784 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00042.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:30:17,904 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:30:18,920 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00042.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 59.09757089614868\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:30:24,657 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:30:24,658 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:30:24,707 : INFO : PROGRESS: at sentence #10000, processed 253202 words, keeping 21593 word types\n",
      "2019-11-20 21:30:24,744 : INFO : PROGRESS: at sentence #20000, processed 493084 words, keeping 30963 word types\n",
      "2019-11-20 21:30:24,781 : INFO : PROGRESS: at sentence #30000, processed 736362 words, keeping 37503 word types\n",
      "2019-11-20 21:30:24,817 : INFO : PROGRESS: at sentence #40000, processed 971415 words, keeping 42725 word types\n",
      "2019-11-20 21:30:24,855 : INFO : PROGRESS: at sentence #50000, processed 1218868 words, keeping 47769 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "43 83332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:30:24,892 : INFO : PROGRESS: at sentence #60000, processed 1461523 words, keeping 52146 word types\n",
      "2019-11-20 21:30:24,932 : INFO : PROGRESS: at sentence #70000, processed 1712116 words, keeping 56506 word types\n",
      "2019-11-20 21:30:24,970 : INFO : PROGRESS: at sentence #80000, processed 1959002 words, keeping 60507 word types\n",
      "2019-11-20 21:30:24,985 : INFO : collected 61739 word types from a corpus of 2039575 raw words and 83332 sentences\n",
      "2019-11-20 21:30:24,985 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:30:25,057 : INFO : New added 17782 unique words (22% of original 79521) and increased the count of 17782 pre-existing words (22% of original 79521)\n",
      "2019-11-20 21:30:25,175 : INFO : deleting the raw counts dictionary of 61739 items\n",
      "2019-11-20 21:30:25,176 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:30:25,177 : INFO : downsampling leaves estimated 2676280 word corpus (135.9% of prior 1968615)\n",
      "2019-11-20 21:30:26,349 : INFO : estimated required memory for 35564 words and 300 dimensions: 103135600 bytes\n",
      "2019-11-20 21:30:26,350 : INFO : updating layer weights\n",
      "2019-11-20 21:30:27,247 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:30:27,248 : INFO : training model with 8 workers on 435444 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:30:28,340 : INFO : EPOCH 1 - PROGRESS: at 8.04% examples, 106406 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:29,357 : INFO : EPOCH 1 - PROGRESS: at 19.83% examples, 131965 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:30,399 : INFO : EPOCH 1 - PROGRESS: at 31.70% examples, 140225 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:31,416 : INFO : EPOCH 1 - PROGRESS: at 43.72% examples, 145163 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:32,449 : INFO : EPOCH 1 - PROGRESS: at 55.65% examples, 147753 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:33,492 : INFO : EPOCH 1 - PROGRESS: at 67.83% examples, 150165 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:34,523 : INFO : EPOCH 1 - PROGRESS: at 79.46% examples, 151173 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:35,585 : INFO : EPOCH 1 - PROGRESS: at 91.11% examples, 151407 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:36,065 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:30:36,088 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:30:36,192 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:30:36,227 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:30:36,275 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:30:36,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:30:36,316 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:30:36,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:30:36,363 : INFO : EPOCH - 1 : training on 2039575 raw words (1385372 effective words) took 9.1s, 152210 effective words/s\n",
      "2019-11-20 21:30:37,421 : INFO : EPOCH 2 - PROGRESS: at 8.04% examples, 109271 words/s, in_qsize 15, out_qsize 2\n",
      "2019-11-20 21:30:38,491 : INFO : EPOCH 2 - PROGRESS: at 19.83% examples, 130524 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:39,578 : INFO : EPOCH 2 - PROGRESS: at 31.70% examples, 137239 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:40,717 : INFO : EPOCH 2 - PROGRESS: at 43.72% examples, 138759 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:41,788 : INFO : EPOCH 2 - PROGRESS: at 55.65% examples, 141518 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:42,837 : INFO : EPOCH 2 - PROGRESS: at 67.36% examples, 143612 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:43,912 : INFO : EPOCH 2 - PROGRESS: at 78.98% examples, 144647 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:44,975 : INFO : EPOCH 2 - PROGRESS: at 90.69% examples, 145707 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:30:45,482 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:30:45,522 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:30:45,547 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:30:45,633 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:30:45,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:30:45,696 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:30:45,705 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:30:45,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:30:45,782 : INFO : EPOCH - 2 : training on 2039575 raw words (1385198 effective words) took 9.4s, 147219 effective words/s\n",
      "2019-11-20 21:30:46,868 : INFO : EPOCH 3 - PROGRESS: at 8.04% examples, 106870 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-20 21:30:47,882 : INFO : EPOCH 3 - PROGRESS: at 19.83% examples, 132466 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:48,913 : INFO : EPOCH 3 - PROGRESS: at 31.70% examples, 141101 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:49,983 : INFO : EPOCH 3 - PROGRESS: at 43.72% examples, 143994 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:51,044 : INFO : EPOCH 3 - PROGRESS: at 55.65% examples, 145977 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:52,090 : INFO : EPOCH 3 - PROGRESS: at 67.36% examples, 147526 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:30:53,108 : INFO : EPOCH 3 - PROGRESS: at 78.52% examples, 148251 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:54,128 : INFO : EPOCH 3 - PROGRESS: at 88.13% examples, 146370 words/s, in_qsize 13, out_qsize 2\n",
      "2019-11-20 21:30:54,852 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:30:54,856 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:30:54,887 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:30:54,965 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:30:54,983 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:30:55,042 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:30:55,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:30:55,148 : INFO : EPOCH 3 - PROGRESS: at 100.00% examples, 148109 words/s, in_qsize 0, out_qsize 1\n",
      "2019-11-20 21:30:55,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:30:55,149 : INFO : EPOCH - 3 : training on 2039575 raw words (1385134 effective words) took 9.4s, 148087 effective words/s\n",
      "2019-11-20 21:30:56,205 : INFO : EPOCH 4 - PROGRESS: at 8.04% examples, 110655 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:57,231 : INFO : EPOCH 4 - PROGRESS: at 19.83% examples, 134131 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:58,298 : INFO : EPOCH 4 - PROGRESS: at 31.70% examples, 140637 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:30:59,373 : INFO : EPOCH 4 - PROGRESS: at 43.72% examples, 143444 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:00,456 : INFO : EPOCH 4 - PROGRESS: at 55.65% examples, 144949 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:01,500 : INFO : EPOCH 4 - PROGRESS: at 67.36% examples, 146666 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:02,564 : INFO : EPOCH 4 - PROGRESS: at 78.98% examples, 147536 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:03,626 : INFO : EPOCH 4 - PROGRESS: at 90.69% examples, 148228 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:04,148 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:31:04,167 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:31:04,176 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:31:04,301 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:31:04,339 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:31:04,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:31:04,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:31:04,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:31:04,444 : INFO : EPOCH - 4 : training on 2039575 raw words (1385896 effective words) took 9.3s, 149387 effective words/s\n",
      "2019-11-20 21:31:05,492 : INFO : EPOCH 5 - PROGRESS: at 8.04% examples, 110919 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:06,520 : INFO : EPOCH 5 - PROGRESS: at 19.83% examples, 134134 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:07,574 : INFO : EPOCH 5 - PROGRESS: at 31.70% examples, 141270 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:08,650 : INFO : EPOCH 5 - PROGRESS: at 43.72% examples, 143949 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:09,698 : INFO : EPOCH 5 - PROGRESS: at 55.65% examples, 146331 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:10,754 : INFO : EPOCH 5 - PROGRESS: at 67.36% examples, 147539 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:11,805 : INFO : EPOCH 5 - PROGRESS: at 78.98% examples, 148533 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:12,866 : INFO : EPOCH 5 - PROGRESS: at 90.69% examples, 149100 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:13,469 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:31:13,500 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:31:13,516 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:31:13,582 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:31:13,605 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:31:13,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:31:13,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:31:13,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:31:13,782 : INFO : EPOCH - 5 : training on 2039575 raw words (1385470 effective words) took 9.3s, 148608 effective words/s\n",
      "2019-11-20 21:31:13,782 : INFO : training on a 10197875 raw words (6927070 effective words) took 46.5s, 148862 effective words/s\n",
      "2019-11-20 21:31:13,783 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00043.model, separately None\n",
      "2019-11-20 21:31:13,784 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00043.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:31:14,960 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:31:14,960 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00043.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:31:16,110 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:31:17,137 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00043.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 58.21701192855835\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:31:22,835 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:31:22,836 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:31:22,883 : INFO : PROGRESS: at sentence #10000, processed 249917 words, keeping 20538 word types\n",
      "2019-11-20 21:31:22,922 : INFO : PROGRESS: at sentence #20000, processed 503156 words, keeping 30390 word types\n",
      "2019-11-20 21:31:22,958 : INFO : PROGRESS: at sentence #30000, processed 742935 words, keeping 37044 word types\n",
      "2019-11-20 21:31:22,994 : INFO : PROGRESS: at sentence #40000, processed 984500 words, keeping 42866 word types\n",
      "2019-11-20 21:31:23,031 : INFO : PROGRESS: at sentence #50000, processed 1235930 words, keeping 47615 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "44 83599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:31:23,069 : INFO : PROGRESS: at sentence #60000, processed 1486011 words, keeping 52125 word types\n",
      "2019-11-20 21:31:23,107 : INFO : PROGRESS: at sentence #70000, processed 1739130 words, keeping 56500 word types\n",
      "2019-11-20 21:31:23,145 : INFO : PROGRESS: at sentence #80000, processed 1988273 words, keeping 60214 word types\n",
      "2019-11-20 21:31:23,159 : INFO : collected 61470 word types from a corpus of 2076723 raw words and 83599 sentences\n",
      "2019-11-20 21:31:23,160 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:31:23,252 : INFO : New added 17791 unique words (22% of original 79261) and increased the count of 17791 pre-existing words (22% of original 79261)\n",
      "2019-11-20 21:31:23,371 : INFO : deleting the raw counts dictionary of 61470 items\n",
      "2019-11-20 21:31:23,373 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:31:23,374 : INFO : downsampling leaves estimated 2731825 word corpus (136.2% of prior 2006238)\n",
      "2019-11-20 21:31:24,552 : INFO : estimated required memory for 35582 words and 300 dimensions: 103187800 bytes\n",
      "2019-11-20 21:31:24,553 : INFO : updating layer weights\n",
      "2019-11-20 21:31:25,433 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:31:25,433 : INFO : training model with 8 workers on 435403 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:31:26,486 : INFO : EPOCH 1 - PROGRESS: at 8.15% examples, 110286 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:27,534 : INFO : EPOCH 1 - PROGRESS: at 19.59% examples, 132977 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-20 21:31:28,543 : INFO : EPOCH 1 - PROGRESS: at 31.34% examples, 142163 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:29,578 : INFO : EPOCH 1 - PROGRESS: at 43.09% examples, 145996 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:30,590 : INFO : EPOCH 1 - PROGRESS: at 54.61% examples, 148971 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:31,614 : INFO : EPOCH 1 - PROGRESS: at 66.09% examples, 150696 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:32,653 : INFO : EPOCH 1 - PROGRESS: at 77.50% examples, 151655 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:33,676 : INFO : EPOCH 1 - PROGRESS: at 88.68% examples, 152569 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:31:34,425 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:31:34,453 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:31:34,460 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:31:34,463 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:31:34,481 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:31:34,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:31:34,514 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:31:34,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:31:34,537 : INFO : EPOCH - 1 : training on 2076723 raw words (1412193 effective words) took 9.1s, 155359 effective words/s\n",
      "2019-11-20 21:31:35,586 : INFO : EPOCH 2 - PROGRESS: at 8.15% examples, 110542 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:31:36,697 : INFO : EPOCH 2 - PROGRESS: at 19.59% examples, 129263 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:37,776 : INFO : EPOCH 2 - PROGRESS: at 31.34% examples, 136413 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:38,905 : INFO : EPOCH 2 - PROGRESS: at 43.09% examples, 138476 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:39,986 : INFO : EPOCH 2 - PROGRESS: at 54.61% examples, 140944 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:41,095 : INFO : EPOCH 2 - PROGRESS: at 66.09% examples, 142002 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:31:42,134 : INFO : EPOCH 2 - PROGRESS: at 77.59% examples, 144054 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:43,218 : INFO : EPOCH 2 - PROGRESS: at 88.68% examples, 144827 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:43,936 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:31:43,998 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:31:44,002 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:31:44,021 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:31:44,053 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:31:44,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:31:44,075 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:31:44,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:31:44,101 : INFO : EPOCH - 2 : training on 2076723 raw words (1412527 effective words) took 9.6s, 147847 effective words/s\n",
      "2019-11-20 21:31:45,158 : INFO : EPOCH 3 - PROGRESS: at 8.15% examples, 110133 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:46,236 : INFO : EPOCH 3 - PROGRESS: at 19.59% examples, 131082 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:47,263 : INFO : EPOCH 3 - PROGRESS: at 31.34% examples, 139966 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:48,314 : INFO : EPOCH 3 - PROGRESS: at 43.09% examples, 143824 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:49,388 : INFO : EPOCH 3 - PROGRESS: at 54.61% examples, 145499 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:50,475 : INFO : EPOCH 3 - PROGRESS: at 66.09% examples, 146308 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:51,552 : INFO : EPOCH 3 - PROGRESS: at 77.50% examples, 147120 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:52,624 : INFO : EPOCH 3 - PROGRESS: at 88.68% examples, 147704 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:53,403 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:31:53,461 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:31:53,500 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:31:53,507 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:31:53,510 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:31:53,512 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:31:53,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:31:53,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:31:53,556 : INFO : EPOCH - 3 : training on 2076723 raw words (1413841 effective words) took 9.4s, 149759 effective words/s\n",
      "2019-11-20 21:31:54,604 : INFO : EPOCH 4 - PROGRESS: at 8.15% examples, 110910 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:55,665 : INFO : EPOCH 4 - PROGRESS: at 19.67% examples, 132409 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:56,715 : INFO : EPOCH 4 - PROGRESS: at 31.34% examples, 140039 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:57,847 : INFO : EPOCH 4 - PROGRESS: at 43.09% examples, 141143 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:31:58,935 : INFO : EPOCH 4 - PROGRESS: at 54.61% examples, 142919 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:32:00,047 : INFO : EPOCH 4 - PROGRESS: at 66.09% examples, 143637 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:32:01,122 : INFO : EPOCH 4 - PROGRESS: at 77.59% examples, 144780 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:02,217 : INFO : EPOCH 4 - PROGRESS: at 88.68% examples, 145288 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:02,942 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:32:02,975 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:32:02,982 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:32:02,990 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:32:03,023 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:32:03,031 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:32:03,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:32:03,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:32:03,053 : INFO : EPOCH - 4 : training on 2076723 raw words (1413309 effective words) took 9.5s, 149023 effective words/s\n",
      "2019-11-20 21:32:04,094 : INFO : EPOCH 5 - PROGRESS: at 8.15% examples, 111752 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:05,159 : INFO : EPOCH 5 - PROGRESS: at 19.59% examples, 132880 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:06,200 : INFO : EPOCH 5 - PROGRESS: at 31.34% examples, 140667 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:07,263 : INFO : EPOCH 5 - PROGRESS: at 43.09% examples, 143918 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:32:08,334 : INFO : EPOCH 5 - PROGRESS: at 54.61% examples, 145643 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:09,413 : INFO : EPOCH 5 - PROGRESS: at 66.09% examples, 146641 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:10,533 : INFO : EPOCH 5 - PROGRESS: at 77.50% examples, 146555 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:11,599 : INFO : EPOCH 5 - PROGRESS: at 88.68% examples, 147357 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:12,314 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:32:12,370 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:32:12,400 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:32:12,405 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:32:12,429 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:32:12,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:32:12,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:32:12,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:32:12,510 : INFO : EPOCH - 5 : training on 2076723 raw words (1414200 effective words) took 9.4s, 149744 effective words/s\n",
      "2019-11-20 21:32:12,511 : INFO : training on a 10383615 raw words (7066070 effective words) took 47.1s, 150098 effective words/s\n",
      "2019-11-20 21:32:12,512 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00044.model, separately None\n",
      "2019-11-20 21:32:12,513 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00044.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:32:13,733 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:32:13,734 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00044.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:32:14,921 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:32:15,954 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00044.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 58.81686806678772\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:32:24,157 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:32:24,158 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:32:24,204 : INFO : PROGRESS: at sentence #10000, processed 248674 words, keeping 20670 word types\n",
      "2019-11-20 21:32:24,242 : INFO : PROGRESS: at sentence #20000, processed 498535 words, keeping 30228 word types\n",
      "2019-11-20 21:32:24,278 : INFO : PROGRESS: at sentence #30000, processed 737140 words, keeping 36750 word types\n",
      "2019-11-20 21:32:24,313 : INFO : PROGRESS: at sentence #40000, processed 972249 words, keeping 42607 word types\n",
      "2019-11-20 21:32:24,350 : INFO : PROGRESS: at sentence #50000, processed 1221871 words, keeping 47865 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "45 84961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:32:24,386 : INFO : PROGRESS: at sentence #60000, processed 1464777 words, keeping 52161 word types\n",
      "2019-11-20 21:32:24,424 : INFO : PROGRESS: at sentence #70000, processed 1713100 words, keeping 56314 word types\n",
      "2019-11-20 21:32:24,461 : INFO : PROGRESS: at sentence #80000, processed 1957285 words, keeping 60226 word types\n",
      "2019-11-20 21:32:24,480 : INFO : collected 61997 word types from a corpus of 2074785 raw words and 84961 sentences\n",
      "2019-11-20 21:32:24,481 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:32:24,551 : INFO : New added 17772 unique words (22% of original 79769) and increased the count of 17772 pre-existing words (22% of original 79769)\n",
      "2019-11-20 21:32:24,669 : INFO : deleting the raw counts dictionary of 61997 items\n",
      "2019-11-20 21:32:24,670 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:32:24,671 : INFO : downsampling leaves estimated 2721221 word corpus (135.8% of prior 2003288)\n",
      "2019-11-20 21:32:25,848 : INFO : estimated required memory for 35544 words and 300 dimensions: 103077600 bytes\n",
      "2019-11-20 21:32:25,849 : INFO : updating layer weights\n",
      "2019-11-20 21:32:26,704 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:32:26,705 : INFO : training model with 8 workers on 435426 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:32:27,754 : INFO : EPOCH 1 - PROGRESS: at 8.14% examples, 110223 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:28,766 : INFO : EPOCH 1 - PROGRESS: at 19.45% examples, 135014 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:29,823 : INFO : EPOCH 1 - PROGRESS: at 30.96% examples, 141483 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:30,832 : INFO : EPOCH 1 - PROGRESS: at 42.82% examples, 146333 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:31,858 : INFO : EPOCH 1 - PROGRESS: at 54.21% examples, 148837 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:32,891 : INFO : EPOCH 1 - PROGRESS: at 65.99% examples, 150160 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:33,911 : INFO : EPOCH 1 - PROGRESS: at 77.38% examples, 151562 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:34,946 : INFO : EPOCH 1 - PROGRESS: at 88.99% examples, 152306 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:35,622 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:32:35,679 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:32:35,690 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:32:35,705 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:32:35,712 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:32:35,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:32:35,729 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:32:35,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:32:35,736 : INFO : EPOCH - 1 : training on 2074785 raw words (1408289 effective words) took 9.0s, 156113 effective words/s\n",
      "2019-11-20 21:32:36,777 : INFO : EPOCH 2 - PROGRESS: at 8.14% examples, 110896 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:37,846 : INFO : EPOCH 2 - PROGRESS: at 19.45% examples, 131825 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:38,941 : INFO : EPOCH 2 - PROGRESS: at 30.96% examples, 137621 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:40,018 : INFO : EPOCH 2 - PROGRESS: at 42.82% examples, 141118 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:41,118 : INFO : EPOCH 2 - PROGRESS: at 54.21% examples, 142550 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:42,188 : INFO : EPOCH 2 - PROGRESS: at 65.99% examples, 144033 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:32:43,260 : INFO : EPOCH 2 - PROGRESS: at 77.40% examples, 145205 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:44,302 : INFO : EPOCH 2 - PROGRESS: at 88.99% examples, 146524 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:44,987 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:32:45,076 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:32:45,117 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:32:45,134 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:32:45,176 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:32:45,228 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:32:45,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:32:45,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:32:45,236 : INFO : EPOCH - 2 : training on 2074785 raw words (1408604 effective words) took 9.5s, 148427 effective words/s\n",
      "2019-11-20 21:32:46,301 : INFO : EPOCH 3 - PROGRESS: at 8.14% examples, 108537 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:47,512 : INFO : EPOCH 3 - PROGRESS: at 19.45% examples, 122168 words/s, in_qsize 16, out_qsize 2\n",
      "2019-11-20 21:32:48,570 : INFO : EPOCH 3 - PROGRESS: at 30.96% examples, 132242 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:49,657 : INFO : EPOCH 3 - PROGRESS: at 40.81% examples, 130389 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:50,662 : INFO : EPOCH 3 - PROGRESS: at 46.83% examples, 121359 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:32:51,760 : INFO : EPOCH 3 - PROGRESS: at 54.21% examples, 117518 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:32:52,805 : INFO : EPOCH 3 - PROGRESS: at 64.95% examples, 120900 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:53,826 : INFO : EPOCH 3 - PROGRESS: at 75.10% examples, 123157 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:54,866 : INFO : EPOCH 3 - PROGRESS: at 86.01% examples, 126063 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:55,821 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:32:55,909 : INFO : EPOCH 3 - PROGRESS: at 97.09% examples, 128310 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-20 21:32:55,910 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:32:55,941 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:32:55,987 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:32:55,994 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:32:56,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:32:56,044 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:32:56,056 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:32:56,057 : INFO : EPOCH - 3 : training on 2074785 raw words (1408115 effective words) took 10.8s, 130267 effective words/s\n",
      "2019-11-20 21:32:57,143 : INFO : EPOCH 4 - PROGRESS: at 8.13% examples, 106622 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:58,305 : INFO : EPOCH 4 - PROGRESS: at 19.45% examples, 123998 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:32:59,332 : INFO : EPOCH 4 - PROGRESS: at 30.96% examples, 134878 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:00,424 : INFO : EPOCH 4 - PROGRESS: at 42.82% examples, 138487 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:33:01,547 : INFO : EPOCH 4 - PROGRESS: at 54.21% examples, 139843 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:02,620 : INFO : EPOCH 4 - PROGRESS: at 65.99% examples, 141633 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:03,690 : INFO : EPOCH 4 - PROGRESS: at 77.40% examples, 143163 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:04,778 : INFO : EPOCH 4 - PROGRESS: at 88.99% examples, 143963 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:05,474 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:33:05,515 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:33:05,573 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:33:05,577 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:33:05,612 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:33:05,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:33:05,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:33:05,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:33:05,658 : INFO : EPOCH - 4 : training on 2074785 raw words (1407695 effective words) took 9.6s, 146865 effective words/s\n",
      "2019-11-20 21:33:06,733 : INFO : EPOCH 5 - PROGRESS: at 8.13% examples, 107346 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:07,777 : INFO : EPOCH 5 - PROGRESS: at 19.45% examples, 131236 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:08,841 : INFO : EPOCH 5 - PROGRESS: at 30.96% examples, 138615 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:09,853 : INFO : EPOCH 5 - PROGRESS: at 42.82% examples, 144108 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:10,928 : INFO : EPOCH 5 - PROGRESS: at 54.21% examples, 145622 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:11,995 : INFO : EPOCH 5 - PROGRESS: at 65.99% examples, 146655 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:13,076 : INFO : EPOCH 5 - PROGRESS: at 77.40% examples, 147269 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:14,158 : INFO : EPOCH 5 - PROGRESS: at 88.99% examples, 147701 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:33:14,855 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:33:14,928 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:33:14,941 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:33:14,953 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:33:14,966 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:33:15,031 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:33:15,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:33:15,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:33:15,045 : INFO : EPOCH - 5 : training on 2074785 raw words (1408453 effective words) took 9.4s, 150220 effective words/s\n",
      "2019-11-20 21:33:15,046 : INFO : training on a 10373925 raw words (7041156 effective words) took 48.3s, 145673 effective words/s\n",
      "2019-11-20 21:33:15,047 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00045.model, separately None\n",
      "2019-11-20 21:33:15,047 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00045.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:33:16,463 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:33:16,464 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00045.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:33:17,649 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:33:18,638 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00045.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 62.68303394317627\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:33:25,009 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:33:25,010 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:33:25,053 : INFO : PROGRESS: at sentence #10000, processed 248096 words, keeping 20346 word types\n",
      "2019-11-20 21:33:25,088 : INFO : PROGRESS: at sentence #20000, processed 490427 words, keeping 29563 word types\n",
      "2019-11-20 21:33:25,124 : INFO : PROGRESS: at sentence #30000, processed 730859 words, keeping 36654 word types\n",
      "2019-11-20 21:33:25,162 : INFO : PROGRESS: at sentence #40000, processed 971451 words, keeping 42457 word types\n",
      "2019-11-20 21:33:25,200 : INFO : PROGRESS: at sentence #50000, processed 1224212 words, keeping 47783 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "46 85397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:33:25,236 : INFO : PROGRESS: at sentence #60000, processed 1464525 words, keeping 52111 word types\n",
      "2019-11-20 21:33:25,274 : INFO : PROGRESS: at sentence #70000, processed 1714680 words, keeping 56018 word types\n",
      "2019-11-20 21:33:25,311 : INFO : PROGRESS: at sentence #80000, processed 1958647 words, keeping 60198 word types\n",
      "2019-11-20 21:33:25,333 : INFO : collected 62202 word types from a corpus of 2094927 raw words and 85397 sentences\n",
      "2019-11-20 21:33:25,333 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:33:25,405 : INFO : New added 17810 unique words (22% of original 80012) and increased the count of 17810 pre-existing words (22% of original 80012)\n",
      "2019-11-20 21:33:25,521 : INFO : deleting the raw counts dictionary of 62202 items\n",
      "2019-11-20 21:33:25,522 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:33:25,523 : INFO : downsampling leaves estimated 2749744 word corpus (135.9% of prior 2023882)\n",
      "2019-11-20 21:33:26,686 : INFO : estimated required memory for 35620 words and 300 dimensions: 103298000 bytes\n",
      "2019-11-20 21:33:26,686 : INFO : updating layer weights\n",
      "2019-11-20 21:33:27,551 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:33:27,552 : INFO : training model with 8 workers on 435402 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:33:28,609 : INFO : EPOCH 1 - PROGRESS: at 7.97% examples, 110258 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:29,613 : INFO : EPOCH 1 - PROGRESS: at 19.60% examples, 135612 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:30,628 : INFO : EPOCH 1 - PROGRESS: at 31.27% examples, 143744 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:31,641 : INFO : EPOCH 1 - PROGRESS: at 42.84% examples, 147984 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:32,709 : INFO : EPOCH 1 - PROGRESS: at 54.06% examples, 148647 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:33,770 : INFO : EPOCH 1 - PROGRESS: at 66.19% examples, 150541 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:34,811 : INFO : EPOCH 1 - PROGRESS: at 77.42% examples, 151448 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:35,821 : INFO : EPOCH 1 - PROGRESS: at 88.72% examples, 152591 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:36,548 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:33:36,567 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:33:36,587 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:33:36,613 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:33:36,618 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:33:36,660 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:33:36,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:33:36,861 : INFO : EPOCH 1 - PROGRESS: at 100.00% examples, 152961 words/s, in_qsize 0, out_qsize 1\n",
      "2019-11-20 21:33:36,862 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:33:36,863 : INFO : EPOCH - 1 : training on 2094927 raw words (1422290 effective words) took 9.3s, 152937 effective words/s\n",
      "2019-11-20 21:33:37,932 : INFO : EPOCH 2 - PROGRESS: at 7.97% examples, 109512 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:39,006 : INFO : EPOCH 2 - PROGRESS: at 19.60% examples, 130684 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:40,104 : INFO : EPOCH 2 - PROGRESS: at 31.27% examples, 136560 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:41,212 : INFO : EPOCH 2 - PROGRESS: at 42.84% examples, 139256 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:42,291 : INFO : EPOCH 2 - PROGRESS: at 54.06% examples, 141383 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:43,335 : INFO : EPOCH 2 - PROGRESS: at 65.70% examples, 143731 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:44,413 : INFO : EPOCH 2 - PROGRESS: at 76.97% examples, 144804 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:45,478 : INFO : EPOCH 2 - PROGRESS: at 88.25% examples, 145739 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:46,312 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:33:46,321 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:33:46,349 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:33:46,385 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:33:46,394 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:33:46,418 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:33:46,513 : INFO : EPOCH 2 - PROGRESS: at 99.58% examples, 146942 words/s, in_qsize 1, out_qsize 1\n",
      "2019-11-20 21:33:46,514 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:33:46,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:33:46,637 : INFO : EPOCH - 2 : training on 2094927 raw words (1422563 effective words) took 9.8s, 145750 effective words/s\n",
      "2019-11-20 21:33:47,677 : INFO : EPOCH 3 - PROGRESS: at 8.46% examples, 119338 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:48,709 : INFO : EPOCH 3 - PROGRESS: at 19.60% examples, 135319 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:49,763 : INFO : EPOCH 3 - PROGRESS: at 31.27% examples, 141715 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:50,840 : INFO : EPOCH 3 - PROGRESS: at 42.84% examples, 144197 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:51,954 : INFO : EPOCH 3 - PROGRESS: at 54.06% examples, 144418 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:53,006 : INFO : EPOCH 3 - PROGRESS: at 65.70% examples, 146111 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:54,077 : INFO : EPOCH 3 - PROGRESS: at 76.97% examples, 147001 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:55,081 : INFO : EPOCH 3 - PROGRESS: at 87.73% examples, 147950 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:55,944 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:33:55,962 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:33:55,990 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:33:56,037 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:33:56,043 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:33:56,106 : INFO : EPOCH 3 - PROGRESS: at 99.16% examples, 149079 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-20 21:33:56,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:33:56,171 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:33:56,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:33:56,222 : INFO : EPOCH - 3 : training on 2094927 raw words (1422563 effective words) took 9.6s, 148663 effective words/s\n",
      "2019-11-20 21:33:57,240 : INFO : EPOCH 4 - PROGRESS: at 7.97% examples, 114620 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:58,355 : INFO : EPOCH 4 - PROGRESS: at 19.60% examples, 131078 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:33:59,409 : INFO : EPOCH 4 - PROGRESS: at 31.27% examples, 138693 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:00,520 : INFO : EPOCH 4 - PROGRESS: at 42.84% examples, 140766 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:01,643 : INFO : EPOCH 4 - PROGRESS: at 54.06% examples, 141409 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:02,720 : INFO : EPOCH 4 - PROGRESS: at 65.70% examples, 142981 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:03,792 : INFO : EPOCH 4 - PROGRESS: at 76.97% examples, 144286 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:04,835 : INFO : EPOCH 4 - PROGRESS: at 88.25% examples, 145677 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:05,601 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:34:05,635 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:34:05,659 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:34:05,690 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:34:05,700 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:34:05,710 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:34:05,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:34:05,913 : INFO : EPOCH 4 - PROGRESS: at 100.00% examples, 146937 words/s, in_qsize 0, out_qsize 1\n",
      "2019-11-20 21:34:05,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:34:05,914 : INFO : EPOCH - 4 : training on 2094927 raw words (1422351 effective words) took 9.7s, 146915 effective words/s\n",
      "2019-11-20 21:34:06,954 : INFO : EPOCH 5 - PROGRESS: at 7.97% examples, 112654 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:07,975 : INFO : EPOCH 5 - PROGRESS: at 19.60% examples, 136035 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:09,033 : INFO : EPOCH 5 - PROGRESS: at 31.27% examples, 142078 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:10,116 : INFO : EPOCH 5 - PROGRESS: at 42.84% examples, 144214 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:11,184 : INFO : EPOCH 5 - PROGRESS: at 54.06% examples, 145660 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:12,213 : INFO : EPOCH 5 - PROGRESS: at 65.70% examples, 147720 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:13,274 : INFO : EPOCH 5 - PROGRESS: at 76.97% examples, 148557 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:14,340 : INFO : EPOCH 5 - PROGRESS: at 88.25% examples, 149026 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:15,227 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:34:15,237 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:34:15,278 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:34:15,289 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:34:15,290 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:34:15,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:34:15,369 : INFO : EPOCH 5 - PROGRESS: at 99.58% examples, 149973 words/s, in_qsize 1, out_qsize 1\n",
      "2019-11-20 21:34:15,370 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:34:15,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:34:15,557 : INFO : EPOCH - 5 : training on 2094927 raw words (1422408 effective words) took 9.6s, 147737 effective words/s\n",
      "2019-11-20 21:34:15,557 : INFO : training on a 10474635 raw words (7112175 effective words) took 48.0s, 148159 effective words/s\n",
      "2019-11-20 21:34:15,558 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00046.model, separately None\n",
      "2019-11-20 21:34:15,559 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00046.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:34:16,752 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:34:16,753 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00046.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:34:17,910 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:34:18,923 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00046.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 60.28548192977905\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:34:24,682 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:34:24,682 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:34:24,726 : INFO : PROGRESS: at sentence #10000, processed 252354 words, keeping 20538 word types\n",
      "2019-11-20 21:34:24,762 : INFO : PROGRESS: at sentence #20000, processed 499219 words, keeping 30013 word types\n",
      "2019-11-20 21:34:24,797 : INFO : PROGRESS: at sentence #30000, processed 736629 words, keeping 36597 word types\n",
      "2019-11-20 21:34:24,835 : INFO : PROGRESS: at sentence #40000, processed 986524 words, keeping 42514 word types\n",
      "2019-11-20 21:34:24,872 : INFO : PROGRESS: at sentence #50000, processed 1223836 words, keeping 47706 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "47 84975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:34:24,909 : INFO : PROGRESS: at sentence #60000, processed 1474273 words, keeping 52257 word types\n",
      "2019-11-20 21:34:24,946 : INFO : PROGRESS: at sentence #70000, processed 1719084 words, keeping 56235 word types\n",
      "2019-11-20 21:34:24,982 : INFO : PROGRESS: at sentence #80000, processed 1958443 words, keeping 60076 word types\n",
      "2019-11-20 21:34:25,002 : INFO : collected 61946 word types from a corpus of 2081868 raw words and 84975 sentences\n",
      "2019-11-20 21:34:25,003 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:34:25,074 : INFO : New added 17788 unique words (22% of original 79734) and increased the count of 17788 pre-existing words (22% of original 79734)\n",
      "2019-11-20 21:34:25,195 : INFO : deleting the raw counts dictionary of 61946 items\n",
      "2019-11-20 21:34:25,197 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-11-20 21:34:25,198 : INFO : downsampling leaves estimated 2733859 word corpus (136.0% of prior 2010814)\n",
      "2019-11-20 21:34:26,369 : INFO : estimated required memory for 35576 words and 300 dimensions: 103170400 bytes\n",
      "2019-11-20 21:34:26,370 : INFO : updating layer weights\n",
      "2019-11-20 21:34:27,257 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:34:27,258 : INFO : training model with 8 workers on 435421 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:34:28,350 : INFO : EPOCH 1 - PROGRESS: at 7.92% examples, 108243 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:29,351 : INFO : EPOCH 1 - PROGRESS: at 19.28% examples, 134805 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:30,378 : INFO : EPOCH 1 - PROGRESS: at 30.99% examples, 142550 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:31,420 : INFO : EPOCH 1 - PROGRESS: at 42.36% examples, 146206 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:32,448 : INFO : EPOCH 1 - PROGRESS: at 54.15% examples, 148615 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:33,476 : INFO : EPOCH 1 - PROGRESS: at 65.66% examples, 150247 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:34:34,483 : INFO : EPOCH 1 - PROGRESS: at 76.98% examples, 151810 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:35,531 : INFO : EPOCH 1 - PROGRESS: at 88.71% examples, 152191 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:36,218 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:34:36,283 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:34:36,298 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:34:36,327 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:34:36,330 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:34:36,340 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:34:36,398 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:34:36,426 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:34:36,427 : INFO : EPOCH - 1 : training on 2081868 raw words (1414467 effective words) took 9.1s, 154869 effective words/s\n",
      "2019-11-20 21:34:37,477 : INFO : EPOCH 2 - PROGRESS: at 7.77% examples, 109730 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:38,591 : INFO : EPOCH 2 - PROGRESS: at 19.26% examples, 128837 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:39,691 : INFO : EPOCH 2 - PROGRESS: at 30.99% examples, 135300 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:40,862 : INFO : EPOCH 2 - PROGRESS: at 42.36% examples, 136476 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:41,940 : INFO : EPOCH 2 - PROGRESS: at 54.15% examples, 139336 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:43,025 : INFO : EPOCH 2 - PROGRESS: at 65.66% examples, 141104 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:44,090 : INFO : EPOCH 2 - PROGRESS: at 76.98% examples, 142729 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:45,153 : INFO : EPOCH 2 - PROGRESS: at 88.71% examples, 143974 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:45,870 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:34:45,890 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:34:45,911 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:34:45,926 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:34:45,927 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:34:45,932 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:34:45,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:34:46,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:34:46,084 : INFO : EPOCH - 2 : training on 2081868 raw words (1415670 effective words) took 9.6s, 146741 effective words/s\n",
      "2019-11-20 21:34:47,137 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 109836 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:48,205 : INFO : EPOCH 3 - PROGRESS: at 19.26% examples, 131528 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:34:49,265 : INFO : EPOCH 3 - PROGRESS: at 30.99% examples, 138826 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:50,364 : INFO : EPOCH 3 - PROGRESS: at 42.36% examples, 141403 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:51,442 : INFO : EPOCH 3 - PROGRESS: at 54.15% examples, 143371 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:52,510 : INFO : EPOCH 3 - PROGRESS: at 65.66% examples, 144848 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:53,569 : INFO : EPOCH 3 - PROGRESS: at 76.98% examples, 146096 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:54,652 : INFO : EPOCH 3 - PROGRESS: at 88.65% examples, 146598 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:55,396 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:34:55,437 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:34:55,440 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:34:55,456 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:34:55,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:34:55,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:34:55,497 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:34:55,592 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:34:55,593 : INFO : EPOCH - 3 : training on 2081868 raw words (1415084 effective words) took 9.5s, 149001 effective words/s\n",
      "2019-11-20 21:34:56,605 : INFO : EPOCH 4 - PROGRESS: at 7.92% examples, 114199 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:57,657 : INFO : EPOCH 4 - PROGRESS: at 19.28% examples, 135010 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:58,700 : INFO : EPOCH 4 - PROGRESS: at 30.99% examples, 142024 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:34:59,785 : INFO : EPOCH 4 - PROGRESS: at 42.36% examples, 144256 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:00,856 : INFO : EPOCH 4 - PROGRESS: at 54.15% examples, 145810 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:01,937 : INFO : EPOCH 4 - PROGRESS: at 65.66% examples, 146667 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:02,993 : INFO : EPOCH 4 - PROGRESS: at 76.98% examples, 147738 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:04,068 : INFO : EPOCH 4 - PROGRESS: at 88.65% examples, 148168 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:04,774 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:35:04,822 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:35:04,825 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:35:04,858 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:35:04,872 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:35:04,887 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:35:04,916 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:35:04,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:35:04,986 : INFO : EPOCH - 4 : training on 2081868 raw words (1414822 effective words) took 9.4s, 150795 effective words/s\n",
      "2019-11-20 21:35:06,025 : INFO : EPOCH 5 - PROGRESS: at 7.92% examples, 111160 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:07,072 : INFO : EPOCH 5 - PROGRESS: at 19.28% examples, 133643 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:08,106 : INFO : EPOCH 5 - PROGRESS: at 30.99% examples, 141397 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:09,196 : INFO : EPOCH 5 - PROGRESS: at 42.36% examples, 143657 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:10,298 : INFO : EPOCH 5 - PROGRESS: at 54.15% examples, 144475 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:11,368 : INFO : EPOCH 5 - PROGRESS: at 65.66% examples, 145825 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:12,451 : INFO : EPOCH 5 - PROGRESS: at 76.98% examples, 146463 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:13,531 : INFO : EPOCH 5 - PROGRESS: at 88.71% examples, 146970 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:14,242 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:35:14,254 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:35:14,268 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:35:14,297 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:35:14,302 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:35:14,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:35:14,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:35:14,453 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:35:14,454 : INFO : EPOCH - 5 : training on 2081868 raw words (1415307 effective words) took 9.5s, 149639 effective words/s\n",
      "2019-11-20 21:35:14,455 : INFO : training on a 10409340 raw words (7075350 effective words) took 47.2s, 149915 effective words/s\n",
      "2019-11-20 21:35:14,456 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00047.model, separately None\n",
      "2019-11-20 21:35:14,456 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00047.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:35:15,663 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:35:15,664 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00047.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:35:16,818 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:35:17,841 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00047.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 58.91831135749817\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:35:26,528 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:35:26,529 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:35:26,577 : INFO : PROGRESS: at sentence #10000, processed 237306 words, keeping 19697 word types\n",
      "2019-11-20 21:35:26,617 : INFO : PROGRESS: at sentence #20000, processed 485754 words, keeping 28984 word types\n",
      "2019-11-20 21:35:26,655 : INFO : PROGRESS: at sentence #30000, processed 724902 words, keeping 35719 word types\n",
      "2019-11-20 21:35:26,693 : INFO : PROGRESS: at sentence #40000, processed 968618 words, keeping 41933 word types\n",
      "2019-11-20 21:35:26,732 : INFO : PROGRESS: at sentence #50000, processed 1210746 words, keeping 47029 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "48 84130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:35:26,772 : INFO : PROGRESS: at sentence #60000, processed 1456998 words, keeping 51668 word types\n",
      "2019-11-20 21:35:26,811 : INFO : PROGRESS: at sentence #70000, processed 1701067 words, keeping 55910 word types\n",
      "2019-11-20 21:35:26,850 : INFO : PROGRESS: at sentence #80000, processed 1944261 words, keeping 59892 word types\n",
      "2019-11-20 21:35:26,867 : INFO : collected 61359 word types from a corpus of 2042211 raw words and 84130 sentences\n",
      "2019-11-20 21:35:26,868 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:35:26,939 : INFO : New added 17709 unique words (22% of original 79068) and increased the count of 17709 pre-existing words (22% of original 79068)\n",
      "2019-11-20 21:35:27,054 : INFO : deleting the raw counts dictionary of 61359 items\n",
      "2019-11-20 21:35:27,056 : INFO : sample=0.001 downsamples 70 most-common words\n",
      "2019-11-20 21:35:27,057 : INFO : downsampling leaves estimated 2682424 word corpus (136.0% of prior 1972121)\n",
      "2019-11-20 21:35:28,229 : INFO : estimated required memory for 35418 words and 300 dimensions: 102712200 bytes\n",
      "2019-11-20 21:35:28,230 : INFO : updating layer weights\n",
      "2019-11-20 21:35:29,096 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:35:29,097 : INFO : training model with 8 workers on 435425 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:35:30,137 : INFO : EPOCH 1 - PROGRESS: at 8.45% examples, 111531 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:35:31,169 : INFO : EPOCH 1 - PROGRESS: at 20.21% examples, 134984 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:32,186 : INFO : EPOCH 1 - PROGRESS: at 31.75% examples, 143283 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:33,214 : INFO : EPOCH 1 - PROGRESS: at 43.77% examples, 146962 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:34,233 : INFO : EPOCH 1 - PROGRESS: at 55.30% examples, 149525 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:35,234 : INFO : EPOCH 1 - PROGRESS: at 66.98% examples, 151621 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:36,235 : INFO : EPOCH 1 - PROGRESS: at 76.97% examples, 150278 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:37,250 : INFO : EPOCH 1 - PROGRESS: at 88.43% examples, 150729 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:37,964 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:35:37,975 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:35:37,992 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:35:38,129 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:35:38,148 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:35:38,187 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:35:38,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:35:38,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:35:38,231 : INFO : EPOCH - 1 : training on 2042211 raw words (1388164 effective words) took 9.1s, 152161 effective words/s\n",
      "2019-11-20 21:35:39,276 : INFO : EPOCH 2 - PROGRESS: at 8.45% examples, 111448 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:40,400 : INFO : EPOCH 2 - PROGRESS: at 20.21% examples, 129217 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:35:41,615 : INFO : EPOCH 2 - PROGRESS: at 31.75% examples, 131010 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:42,705 : INFO : EPOCH 2 - PROGRESS: at 43.77% examples, 135485 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:43,785 : INFO : EPOCH 2 - PROGRESS: at 55.41% examples, 138447 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:44,879 : INFO : EPOCH 2 - PROGRESS: at 66.98% examples, 140167 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:45,934 : INFO : EPOCH 2 - PROGRESS: at 78.61% examples, 142045 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:46,975 : INFO : EPOCH 2 - PROGRESS: at 90.39% examples, 143787 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:47,540 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:35:47,546 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:35:47,569 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:35:47,653 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:35:47,676 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:35:47,743 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:35:47,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:35:47,758 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:35:47,759 : INFO : EPOCH - 2 : training on 2042211 raw words (1389196 effective words) took 9.5s, 146031 effective words/s\n",
      "2019-11-20 21:35:48,831 : INFO : EPOCH 3 - PROGRESS: at 8.45% examples, 108008 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:35:49,920 : INFO : EPOCH 3 - PROGRESS: at 20.21% examples, 129253 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:35:50,934 : INFO : EPOCH 3 - PROGRESS: at 31.75% examples, 139368 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:51,989 : INFO : EPOCH 3 - PROGRESS: at 43.77% examples, 142983 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:53,079 : INFO : EPOCH 3 - PROGRESS: at 55.41% examples, 144240 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:54,158 : INFO : EPOCH 3 - PROGRESS: at 66.98% examples, 145330 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:55,201 : INFO : EPOCH 3 - PROGRESS: at 78.61% examples, 146806 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:56,267 : INFO : EPOCH 3 - PROGRESS: at 90.39% examples, 147555 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:56,764 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:35:56,805 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:35:56,835 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:35:56,952 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:35:56,971 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:35:57,017 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:35:57,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:35:57,035 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:35:57,036 : INFO : EPOCH - 3 : training on 2042211 raw words (1387898 effective words) took 9.3s, 149771 effective words/s\n",
      "2019-11-20 21:35:58,143 : INFO : EPOCH 4 - PROGRESS: at 8.45% examples, 104962 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:35:59,207 : INFO : EPOCH 4 - PROGRESS: at 20.21% examples, 128882 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:00,258 : INFO : EPOCH 4 - PROGRESS: at 31.75% examples, 137483 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:01,348 : INFO : EPOCH 4 - PROGRESS: at 43.70% examples, 140478 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:02,438 : INFO : EPOCH 4 - PROGRESS: at 55.41% examples, 142278 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:03,507 : INFO : EPOCH 4 - PROGRESS: at 66.98% examples, 143926 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:04,597 : INFO : EPOCH 4 - PROGRESS: at 78.61% examples, 144691 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:36:05,680 : INFO : EPOCH 4 - PROGRESS: at 90.39% examples, 145421 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:06,156 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:36:06,193 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:36:06,221 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:36:06,341 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:36:06,356 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:36:06,371 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:36:06,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:36:06,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:36:06,431 : INFO : EPOCH - 4 : training on 2042211 raw words (1388982 effective words) took 9.4s, 148040 effective words/s\n",
      "2019-11-20 21:36:07,472 : INFO : EPOCH 5 - PROGRESS: at 8.45% examples, 111998 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:08,530 : INFO : EPOCH 5 - PROGRESS: at 20.21% examples, 133520 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:09,573 : INFO : EPOCH 5 - PROGRESS: at 31.80% examples, 141074 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:10,656 : INFO : EPOCH 5 - PROGRESS: at 43.70% examples, 143447 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:11,733 : INFO : EPOCH 5 - PROGRESS: at 55.41% examples, 144937 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:12,805 : INFO : EPOCH 5 - PROGRESS: at 66.98% examples, 146080 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:13,848 : INFO : EPOCH 5 - PROGRESS: at 78.61% examples, 147422 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:36:14,910 : INFO : EPOCH 5 - PROGRESS: at 90.39% examples, 148184 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:15,430 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:36:15,474 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:36:15,476 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:36:15,602 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:36:15,603 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:36:15,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:36:15,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:36:15,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:36:15,683 : INFO : EPOCH - 5 : training on 2042211 raw words (1387911 effective words) took 9.2s, 150231 effective words/s\n",
      "2019-11-20 21:36:15,684 : INFO : training on a 10211055 raw words (6942151 effective words) took 46.6s, 149020 effective words/s\n",
      "2019-11-20 21:36:15,685 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00048.model, separately None\n",
      "2019-11-20 21:36:15,686 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00048.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:36:16,903 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:36:16,904 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00048.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:36:18,048 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:36:19,098 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00048.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 61.256438970565796\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:36:24,978 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:36:24,979 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:36:25,027 : INFO : PROGRESS: at sentence #10000, processed 241111 words, keeping 20488 word types\n",
      "2019-11-20 21:36:25,067 : INFO : PROGRESS: at sentence #20000, processed 490314 words, keeping 29635 word types\n",
      "2019-11-20 21:36:25,105 : INFO : PROGRESS: at sentence #30000, processed 737926 words, keeping 36805 word types\n",
      "2019-11-20 21:36:25,144 : INFO : PROGRESS: at sentence #40000, processed 979697 words, keeping 42743 word types\n",
      "2019-11-20 21:36:25,188 : INFO : PROGRESS: at sentence #50000, processed 1221900 words, keeping 47585 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences: 5095\n",
      "49 85568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:36:25,226 : INFO : PROGRESS: at sentence #60000, processed 1466132 words, keeping 52097 word types\n",
      "2019-11-20 21:36:25,264 : INFO : PROGRESS: at sentence #70000, processed 1707034 words, keeping 55857 word types\n",
      "2019-11-20 21:36:25,301 : INFO : PROGRESS: at sentence #80000, processed 1947547 words, keeping 59729 word types\n",
      "2019-11-20 21:36:25,324 : INFO : collected 61802 word types from a corpus of 2085441 raw words and 85568 sentences\n",
      "2019-11-20 21:36:25,325 : INFO : Updating model with new vocabulary\n",
      "2019-11-20 21:36:25,396 : INFO : New added 17857 unique words (22% of original 79659) and increased the count of 17857 pre-existing words (22% of original 79659)\n",
      "2019-11-20 21:36:25,511 : INFO : deleting the raw counts dictionary of 61802 items\n",
      "2019-11-20 21:36:25,513 : INFO : sample=0.001 downsamples 70 most-common words\n",
      "2019-11-20 21:36:25,514 : INFO : downsampling leaves estimated 2735732 word corpus (135.8% of prior 2014870)\n",
      "2019-11-20 21:36:26,678 : INFO : estimated required memory for 35714 words and 300 dimensions: 103570600 bytes\n",
      "2019-11-20 21:36:26,679 : INFO : updating layer weights\n",
      "2019-11-20 21:36:27,558 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-11-20 21:36:27,559 : INFO : training model with 8 workers on 435473 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
      "2019-11-20 21:36:28,606 : INFO : EPOCH 1 - PROGRESS: at 8.23% examples, 110692 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:29,641 : INFO : EPOCH 1 - PROGRESS: at 19.61% examples, 133719 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:30,687 : INFO : EPOCH 1 - PROGRESS: at 30.75% examples, 141007 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:31,769 : INFO : EPOCH 1 - PROGRESS: at 42.30% examples, 143367 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:36:32,792 : INFO : EPOCH 1 - PROGRESS: at 54.08% examples, 146443 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:33,840 : INFO : EPOCH 1 - PROGRESS: at 65.86% examples, 149032 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:34,873 : INFO : EPOCH 1 - PROGRESS: at 78.01% examples, 151155 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:36:35,890 : INFO : EPOCH 1 - PROGRESS: at 89.64% examples, 152161 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:36,565 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:36:36,577 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:36:36,594 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:36:36,606 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:36:36,623 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:36:36,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:36:36,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:36:36,889 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:36:36,889 : INFO : EPOCH - 1 : training on 2085441 raw words (1415497 effective words) took 9.3s, 151876 effective words/s\n",
      "2019-11-20 21:36:37,964 : INFO : EPOCH 2 - PROGRESS: at 8.26% examples, 108229 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:39,063 : INFO : EPOCH 2 - PROGRESS: at 19.66% examples, 128305 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:36:40,194 : INFO : EPOCH 2 - PROGRESS: at 30.75% examples, 133530 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:41,308 : INFO : EPOCH 2 - PROGRESS: at 42.24% examples, 136649 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:42,392 : INFO : EPOCH 2 - PROGRESS: at 54.08% examples, 139312 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:43,460 : INFO : EPOCH 2 - PROGRESS: at 65.36% examples, 141442 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:44,531 : INFO : EPOCH 2 - PROGRESS: at 77.05% examples, 142936 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:45,596 : INFO : EPOCH 2 - PROGRESS: at 88.61% examples, 144091 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:46,345 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:36:46,371 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:36:46,379 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:36:46,408 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:36:46,414 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:36:46,442 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:36:46,491 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:36:46,656 : INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 145134 words/s, in_qsize 0, out_qsize 1\n",
      "2019-11-20 21:36:46,656 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:36:46,657 : INFO : EPOCH - 2 : training on 2085441 raw words (1415267 effective words) took 9.8s, 145113 effective words/s\n",
      "2019-11-20 21:36:47,685 : INFO : EPOCH 3 - PROGRESS: at 8.23% examples, 112722 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:48,747 : INFO : EPOCH 3 - PROGRESS: at 19.66% examples, 133153 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:49,807 : INFO : EPOCH 3 - PROGRESS: at 30.75% examples, 139906 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:50,903 : INFO : EPOCH 3 - PROGRESS: at 42.24% examples, 142053 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-20 21:36:51,965 : INFO : EPOCH 3 - PROGRESS: at 54.02% examples, 144253 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:53,060 : INFO : EPOCH 3 - PROGRESS: at 65.36% examples, 144983 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:54,136 : INFO : EPOCH 3 - PROGRESS: at 77.05% examples, 145863 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:55,194 : INFO : EPOCH 3 - PROGRESS: at 88.61% examples, 146800 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:55,958 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:36:55,976 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:36:55,983 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:36:55,999 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:36:56,026 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:36:56,037 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:36:56,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:36:56,261 : INFO : EPOCH 3 - PROGRESS: at 100.00% examples, 147442 words/s, in_qsize 0, out_qsize 1\n",
      "2019-11-20 21:36:56,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:36:56,263 : INFO : EPOCH - 3 : training on 2085441 raw words (1414706 effective words) took 9.6s, 147420 effective words/s\n",
      "2019-11-20 21:36:57,291 : INFO : EPOCH 4 - PROGRESS: at 8.23% examples, 112788 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:58,338 : INFO : EPOCH 4 - PROGRESS: at 19.66% examples, 134090 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:36:59,380 : INFO : EPOCH 4 - PROGRESS: at 30.75% examples, 141401 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:00,461 : INFO : EPOCH 4 - PROGRESS: at 42.24% examples, 143678 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:01,543 : INFO : EPOCH 4 - PROGRESS: at 54.02% examples, 145071 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:02,660 : INFO : EPOCH 4 - PROGRESS: at 65.36% examples, 145165 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:03,808 : INFO : EPOCH 4 - PROGRESS: at 76.55% examples, 143777 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:04,994 : INFO : EPOCH 4 - PROGRESS: at 88.03% examples, 142876 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-20 21:37:05,930 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:37:05,932 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:37:05,939 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:37:05,947 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:37:05,985 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:37:05,986 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:37:06,138 : INFO : EPOCH 4 - PROGRESS: at 99.49% examples, 142813 words/s, in_qsize 1, out_qsize 1\n",
      "2019-11-20 21:37:06,139 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:37:06,202 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:37:06,203 : INFO : EPOCH - 4 : training on 2085441 raw words (1415785 effective words) took 9.9s, 142567 effective words/s\n",
      "2019-11-20 21:37:07,401 : INFO : EPOCH 5 - PROGRESS: at 8.22% examples, 96598 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:08,463 : INFO : EPOCH 5 - PROGRESS: at 19.66% examples, 123156 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:09,514 : INFO : EPOCH 5 - PROGRESS: at 30.75% examples, 133163 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:10,631 : INFO : EPOCH 5 - PROGRESS: at 42.24% examples, 136258 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:11,713 : INFO : EPOCH 5 - PROGRESS: at 54.08% examples, 139049 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:12,772 : INFO : EPOCH 5 - PROGRESS: at 65.36% examples, 141346 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:13,840 : INFO : EPOCH 5 - PROGRESS: at 77.05% examples, 142927 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:14,917 : INFO : EPOCH 5 - PROGRESS: at 88.61% examples, 143893 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-20 21:37:15,701 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-20 21:37:15,704 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-20 21:37:15,736 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-20 21:37:15,750 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-20 21:37:15,772 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:37:15,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:37:15,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:37:15,968 : INFO : EPOCH 5 - PROGRESS: at 100.00% examples, 145083 words/s, in_qsize 0, out_qsize 1\n",
      "2019-11-20 21:37:15,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:37:15,969 : INFO : EPOCH - 5 : training on 2085441 raw words (1415229 effective words) took 9.8s, 145061 effective words/s\n",
      "2019-11-20 21:37:15,970 : INFO : training on a 10427205 raw words (7076484 effective words) took 48.4s, 146178 effective words/s\n",
      "2019-11-20 21:37:15,971 : INFO : saving Word2Vec object under ./LMs/w2v_005_EM_corr_qual_1_2_00049.model, separately None\n",
      "2019-11-20 21:37:15,972 : INFO : storing np array 'vectors' to ./LMs/w2v_005_EM_corr_qual_1_2_00049.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:37:17,173 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:37:17,173 : INFO : storing np array 'syn1neg' to ./LMs/w2v_005_EM_corr_qual_1_2_00049.model.trainables.syn1neg.npy\n",
      "2019-11-20 21:37:18,313 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:37:19,350 : INFO : saved ./LMs/w2v_005_EM_corr_qual_1_2_00049.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 60.251914978027344\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i_model in range(40, 50):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    embedding_model_corrected = copy.deepcopy(embedding_model_orig)\n",
    "    embedding_model_corrected.workers = 8\n",
    "    embedding_model_corrected.vocabulary.min_count = 5\n",
    "    embedding_model_corrected.alpha = min_alpha_yet_reached*10.\n",
    "        \n",
    "    db_sentence_sampled = db_sentence.sample(n=5095, replace=True)\n",
    "    list_sentences = db_sentence_sampled[\"corrected_sentencizer_cleaned\"].to_list()\n",
    "    print('#sentences: {}'.format(len(list_sentences)))\n",
    "    flattened_list_sentences = [val for sublist in list_sentences for val in sublist]\n",
    "    print(i_model, len(flattened_list_sentences))\n",
    "    embedding_model_corrected.build_vocab(flattened_list_sentences, update=True)\n",
    "    embedding_model_corrected.train(flattened_list_sentences, \n",
    "                                    total_examples=embedding_model_corrected.corpus_count,\n",
    "                                    epochs=w2v_args.epochs,  \n",
    "                                    compute_loss=w2v_args.compute_loss)\n",
    "    \n",
    "    print(\"\\n\\n[INFO] Save the model\")\n",
    "    embedding_model_corrected.save(\"./LMs/w2v_005_EM_corr_qual_1_2_%05i.model\" % i_model)\n",
    "    print(\"total: {}\".format(time.time() - t1))\n",
    "    print(\"=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
